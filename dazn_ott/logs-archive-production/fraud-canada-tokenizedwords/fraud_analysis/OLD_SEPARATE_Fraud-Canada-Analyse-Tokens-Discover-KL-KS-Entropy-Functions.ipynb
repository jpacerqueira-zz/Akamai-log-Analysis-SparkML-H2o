{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- @metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- @timestamp: string (nullable = true)\n",
      " |-- __logz_account_id: string (nullable = true)\n",
      " |-- __logz_received_timestamp: string (nullable = true)\n",
      " |-- __logzio_X-B3-Sampled: string (nullable = true)\n",
      " |-- __logzio_X-B3-SpanId: string (nullable = true)\n",
      " |-- __logzio_X-B3-TraceId: string (nullable = true)\n",
      " |-- __logzio_id: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messagecut: string (nullable = true)\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- message: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngrams_85: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- ngramscounts_85: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngrams_85: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- ngramscounts_85: vector (nullable = true)\n",
      " |-- features_85: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- awsRegion: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- correlationId: string (nullable = true)\n",
      " |-- function_version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- hostname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- invoked_function_arn: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- level: long (nullable = true)\n",
      " |-- logGroup: string (nullable = true)\n",
      " |-- logStream: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messageType: string (nullable = true)\n",
      " |-- msg: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- owner: string (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- token: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- awsRegion: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- correlationId: string (nullable = true)\n",
      " |-- function_version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- hostname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- invoked_function_arn: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- level: long (nullable = true)\n",
      " |-- logGroup: string (nullable = true)\n",
      " |-- logStream: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messageType: string (nullable = true)\n",
      " |-- msg: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- owner: string (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- token: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- awsRegion: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- correlationId: string (nullable = true)\n",
      " |-- function_version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- hostname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- invoked_function_arn: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- level: long (nullable = true)\n",
      " |-- logGroup: string (nullable = true)\n",
      " |-- logStream: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messageType: string (nullable = true)\n",
      " |-- msg: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- owner: string (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- token: string (nullable = true)\n",
      " |-- messagecut: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messagecut: string (nullable = true)\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- message: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngrams_85: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- ngramscounts_85: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngrams_85: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- ngramscounts_85: vector (nullable = true)\n",
      " |-- features_85: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_85: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "Calculation of standard_fraud_ngram - Start!\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      "\n",
      "Value Print: standard_fraud_ngram=\n",
      "                                        hash_message\n",
      "0  448092e7fe30372a0b0d2718b7e31c70003cafb3c662f9...\n",
      "Calculation of standard_fraud_ngram - Done!\n",
      "Preparation of Data Done!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "#\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "#\n",
    "#import org.apache.spark.ml.feature.NGram\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from collections import Counter\n",
    "#\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from pyspark.ml.feature import NGram, CountVectorizer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "#\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "#\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "#\n",
    "#\n",
    "#\n",
    "# Ugly workarround to increase spark.kryoserializer.buffer.max\n",
    "# Only way in session to Run :\n",
    "#        - treeAggregate at RowMatrix.scala:122 \n",
    "#        - first at PCA.scala:43\n",
    "#\n",
    "sc = pyspark.SparkContext()\n",
    "conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','2047mb'),('spark.driver.memory','23g'),('spark.driver.maxResultSize','21g')])\n",
    "sc.stop()\n",
    "sc = pyspark.SparkContext(conf=conf,appName=\"Notebook-FraudCanada-Model-NGrams-CountVectorizer-KL-KS-Entropy-Model-CleanData\")\n",
    "sqlContext = SQLContext(sc)\n",
    "#\n",
    "#\n",
    "# Arguments\n",
    "#\n",
    "#import argparse\n",
    "## Parse date_of execution\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"--datev1\", help=\"Execution Date\")\n",
    "#args = parser.parse_args()\n",
    "#if args.datev1:\n",
    "#    processdate = args.datev1\n",
    "# GENERAL PREPARATION SCRIPT\n",
    "#\n",
    "#  Date in format YYYYMMDD\n",
    "#process_date = processdate\n",
    "#if not process_date:\n",
    "#    process_date = \"20181231\"\n",
    "#\n",
    "process_date=\"20190122\"\n",
    "#\n",
    "input_file1_playback_fraud=\"hdfs:///data/staged/ott_dazn/fraud-canada-tokenizedwords/dt=*/*.json\"\n",
    "output_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-canada-tokenizedwords-ngrams-85-90/dt=\"+process_date\n",
    "#\n",
    "input_file2_playback_not_fraud=\"hdfs:///data/staged/ott_dazn/logs-archive-production/parquet/dt=\"+process_date+\"/*.parquet\"\n",
    "output_file2=\"hdfs:///data/staged/ott_dazn/advanced-model-data/not-fraud-canada-tokenizedwords/dt=\"+process_date\n",
    "#\n",
    "input_file3=\"hdfs:///data/staged/ott_dazn/advanced-model-data/not-fraud-canada-tokenizedwords/dt=\"+process_date+\"/*.*\"\n",
    "output_file3=\"hdfs:///data/staged/ott_dazn/advanced-model-data/not-fraud-canada-tokenizedwords-ngrams-85-90/dt=\"+process_date\n",
    "#\n",
    "input_file4=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-canada-tokenizedwords-ngrams-85-90/dt=\"+process_date+\"/*.*\"\n",
    "input_file5=\"hdfs:///data/staged/ott_dazn/not-fraud-canada-tokenizedwords-ngrams-85-90/dt=\"+process_date+\"/*.*\"\n",
    "#\n",
    "output_most_frequent_df=\"hdfs:///data/staged/ott_dazn/advanced-model-data/output_most_frequent_fraud_hash_message/dt=\"+process_date\n",
    "#\n",
    "# FILTER FRAUD AND LABEL \n",
    "# Join with Internal Curation Data in urltopredict staged folder\n",
    "from pyspark.sql import functions as F\n",
    "#\n",
    "# hash the message de-duplicate those records\n",
    "urlpredict_internalfraud_file=sqlContext.read.json(input_file1_playback_fraud)\n",
    "urlpredict_internalfraud_file.printSchema()\n",
    "#\n",
    "urlpredict_internalfraud_df=urlpredict_internalfraud_file\\\n",
    ".filter(\"message IS NOT NULL\").filter(\"words IS NOT NULL\")\\\n",
    ".withColumn('fraud_label',lit(1).cast('int'))\\\n",
    ".withColumn('hash_message',F.sha2(col('message'),512)).groupby(col('hash_message'))\\\n",
    ".agg(F.first(col('fraud_label')).alias('fraud_label'),F.first(col('words')).alias('words'),F.first(col('message')).alias('message'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "urlpredict_internalfraud_df.printSchema()\n",
    "#\n",
    "df_words = urlpredict_internalfraud_df.filter(\"message IS NOT NULL\").select(col('fraud_label'),col('hash_message'),col('words'))\n",
    "#\n",
    "## Register Generic Functions\n",
    "# -----------------------------------------------------------------------------\n",
    "# Build ngrams 85 90 n=6 \n",
    "# support : https://stackoverflow.com/questions/51473703/pyspark-ml-ngrams-countvectorizer-sorted-based-on-count-weights\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_ngrams_part(inputCol=\"words\", n=6):\n",
    "    ngrams = [ \n",
    "        NGram(n=i, inputCol=\"words\", outputCol=\"ngrams_{0}\".format(i)) \n",
    "        for i in range(85, n + 1) ]\n",
    "    vectorizers = [ \n",
    "        CountVectorizer(inputCol=\"ngrams_{0}\".format(i), outputCol=\"ngramscounts_{0}\".format(i)) \n",
    "        for i in range(85, n + 1) ]\n",
    "    return Pipeline(stages=ngrams + vectorizers)\n",
    "#    assembler = [VectorAssembler( inputCols=[\"ngramscounts_{0}\".format(i) for i in range(1, n + 1)], outputCol=\"features\" )]\n",
    "#    return Pipeline(stages=ngrams + DenseVector(SparseVector(vectorizers).toArray()))\n",
    "#\n",
    "# \n",
    "# -----------------------------------------------------------------------------\n",
    "#ngram = build_ngrams_part().fit(df_words)\n",
    "#ngramDataFrame = ngram.transform(df_words)\n",
    "#ngramDataFrame.coalesce(1).write.json(output_file1)\n",
    "#\n",
    "ngram = NGram(n=85, inputCol=\"words\", outputCol=\"ngrams_85\")\n",
    "countvector = CountVectorizer(inputCol=\"ngrams_85\", outputCol=\"ngramscounts_85\")\n",
    "# fit a CountVectorizerModel from the corpus.\n",
    "countvModel = CountVectorizer(inputCol=\"words\", outputCol=\"features_85\", vocabSize=85, minDF=2.0)\n",
    "# fit a PCA Dimensionality reduction into 6/2=3 components from ngramscounts_85 ## Too Heavy 1st PCA\n",
    "pcaNgrams = PCA(k=3, inputCol=\"ngramscounts_85\", outputCol=\"pcaweightngrams\")\n",
    "# fit a PCA Dimensionality reduction into 85/17=5 components from words\n",
    "pcaWords = PCA(k=5, inputCol=\"features_85\", outputCol=\"pcaweightwords\")  ## Too Heavy 2nd PCA\n",
    "#\n",
    "ngram_fraud_DF = ngram.transform(df_words)\n",
    "ngram_vc_fraud_DF = countvector.fit(ngram_fraud_DF).transform(ngram_fraud_DF)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "ngram_vc_fraud_DF.printSchema()\n",
    "#\n",
    "#modelPCA_ngram_fraud_DF = pcaNgrams.fit(ngram_vc_fraud_DF).transform(ngram_vc_fraud_DF)\\\n",
    "#.persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "#modelPCA_ngram_fraud_DF.printSchema()\n",
    "#\n",
    "result_ngrams_words_fraud_DF = countvModel.fit(ngram_vc_fraud_DF).transform(ngram_vc_fraud_DF)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "result_ngrams_words_fraud_DF.printSchema()\n",
    "#\n",
    "result_ngrams_words_fraud_DF.coalesce(1).write.json(output_file1)\n",
    "#\n",
    "#  FILTER Non-Fraud AND LABEL\n",
    "#\n",
    "df2= sqlContext.read.parquet(input_file2_playback_not_fraud)\n",
    "df2.printSchema()\n",
    "#\n",
    "df3 = df2.filter(\" (message LIKE '%\\\"Url\\\":\\\"https://isl-ca.dazn.com/misl/v2/Playback%') AND (message LIKE '%,\\\"Response\\\":{\\\"StatusCode\\\":200,\\\"ReasonPhrase\\\":\\\"OK\\\",%') AND ( ( (message LIKE '%&Format=MPEG-DASH&%' OR message LIKE '%&Format=M3U&%') ) OR (message NOT LIKE '%\\\"User-Agent\\\":\\\"Mozilla/5.0,(Macintosh; Intel Mac OS X 10_12_6),AppleWebKit/605.1.15,(KHTML, like Gecko),Version/11.1.2,Safari/605.1.15\\\"},%')   )  \")\n",
    "df3.printSchema()\n",
    "df4 = df3.withColumn(\"messagecut\", expr(\"substring(message, locate('|Livesport.WebApi.Controllers.Playback.PlaybackV2Controller|',message)+60 , length(message)-1)\"))\n",
    "#\n",
    "# val regexTokenizer = new RegexTokenizer().setInputCol(\"messagecut\").setOutputCol(\"words\").setPattern(\"\\\\w+|\").setGaps(false)\n",
    "#\n",
    "regexTokenizer = RegexTokenizer(minTokenLength=1, gaps=False, pattern='\\\\w+|', inputCol=\"messagecut\", outputCol=\"words\", toLowercase=True)\n",
    "#\n",
    "tokenized = regexTokenizer.transform(df4)\n",
    "tokenized.printSchema()\n",
    "tokenized.coalesce(1).write.json(output_file2)\n",
    "# Tokenize NON-Fraud-LABEL\n",
    "# hash the message de-duplicate those records\n",
    "notfraud_file=sqlContext.read.json(input_file3)\n",
    "notfraud_file.printSchema()\n",
    "#\n",
    "notfraud_df=notfraud_file\\\n",
    ".filter(\"message IS NOT NULL\").filter(\"words IS NOT NULL\")\\\n",
    ".withColumn('fraud_label',lit(0).cast('int'))\\\n",
    ".withColumn('hash_message',F.sha2(col('message'),512)).groupby(col('hash_message'))\\\n",
    ".agg(F.first(col('fraud_label')).alias('fraud_label'),F.first(col('words')).alias('words'),F.first(col('message')).alias('message'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "notfraud_df.printSchema()\n",
    "#\n",
    "df_notfraud_words = notfraud_df.filter(\"message IS NOT NULL\").select(col('fraud_label'),col('hash_message'),col('words'))\n",
    "#\n",
    "##\n",
    "## Register Generic Functions\n",
    "# -----------------------------------------------------------------------------\n",
    "# Build ngrams 85 90 n=6 \n",
    "# support : https://stackoverflow.com/questions/51473703/pyspark-ml-ngrams-countvectorizer-sorted-based-on-count-weights\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_ngrams_part(inputCol=\"words\", n=6):\n",
    "    ngrams = [ \n",
    "        NGram(n=i, inputCol=\"words\", outputCol=\"ngrams_{0}\".format(i)) \n",
    "        for i in range(85, n + 1) ]\n",
    "    vectorizers = [ \n",
    "        CountVectorizer(inputCol=\"ngrams_{0}\".format(i), outputCol=\"ngramscounts_{0}\".format(i)) \n",
    "        for i in range(85, n + 1) ]\n",
    "    return Pipeline(stages=ngrams + vectorizers)\n",
    "#    assembler = [VectorAssembler(inputCols=[\"ngramscounts_{0}\".format(i) for i in range(1, n + 1)], outputCol=\"features\" )]\n",
    "#    return Pipeline(stages=ngrams + DenseVector(SparseVector(vectorizers).toArray()))\n",
    "#\n",
    "#\n",
    "# \n",
    "# -----------------------------------------------------------------------------\n",
    "#ngram = build_ngrams_part().fit(df_notfraud_words)\n",
    "#ngram_notfraud_DataFrame = ngram.transform(df_notfraud_words)\n",
    "#ngram_notfraud_DataFrame.coalesce(1).write.json(output_file3)\n",
    "#\n",
    "ngram = NGram(n=85, inputCol=\"words\", outputCol=\"ngrams_85\")\n",
    "countvector = CountVectorizer(inputCol=\"ngrams_85\", outputCol=\"ngramscounts_85\")\n",
    "# fit a CountVectorizerModel from the corpus.\n",
    "countvModel = CountVectorizer(inputCol=\"words\", outputCol=\"features_85\", vocabSize=85, minDF=2.0)\n",
    "# fit a PCA Dimensionality reduction into 6/2=3 components from ngramscounts_85 ## Too Heavy 1st PCA\n",
    "pcaNgrams = PCA(k=3, inputCol=\"ngramscounts_85\", outputCol=\"pcaweightngrams\")\n",
    "# fit a PCA Dimensionality reduction into 85/17=5 components from words ## Too Heavy 2nd PCA\n",
    "pcaWords = PCA(k=5, inputCol=\"features_85\", outputCol=\"pcaweightwords\")\n",
    "#\n",
    "ngram_notfraud_DF = ngram.transform(df_notfraud_words)\n",
    "ngram_vc_notfraud_DF = countvector.fit(ngram_notfraud_DF).transform(ngram_notfraud_DF)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "ngram_vc_notfraud_DF.printSchema()\n",
    "#\n",
    "#modelPCA_ngram_notfraud_DF = pcaNgrams.fit(ngram_vc_notfraud_DF).transform(ngram_notfraud_DF)\\\n",
    "#.persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "#modelPCA_ngram_notfraud_DF.printSchema()\n",
    "#\n",
    "result_ngrams_words_notfraud_DF = countvModel.fit(ngram_vc_notfraud_DF).transform(ngram_vc_notfraud_DF)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "result_ngrams_words_notfraud_DF.printSchema()\n",
    "#\n",
    "result_ngrams_words_notfraud_DF.coalesce(1).write.json(output_file3)\n",
    "#\n",
    "#  CALCULATE KL,KS COEF. Label Data\n",
    "ngram8590_fraud=sqlContext.read.json(input_file4)\n",
    "ngram8590_fraud.printSchema()\n",
    "#\n",
    "print(\"Calculation of standard_fraud_ngram - Start!\")\n",
    "#\n",
    "# Obtain the most frequent word on each position \n",
    "# Compose the standard_fraud_ngram from the most common positions\n",
    "#Â Calculate the standard_fraud_ngram\n",
    "#\n",
    "# https://stackoverflow.com/questions/35218882/find-maximum-row-per-group-in-spark-dataframe \n",
    "# Using struct ordering:\n",
    "#from pyspark.sql.functions import struct\n",
    "#\n",
    "#(cnts\n",
    "#  .groupBy(\"id_sa\")\n",
    "#  .agg(F.max(struct(col(\"cnt\"), col(\"id_sb\"))).alias(\"max\"))\n",
    "#  .select(col(\"id_sa\"), col(\"max.id_sb\")))\n",
    "#\n",
    "#Py4JJavaError: An error occurred while calling o3400.select.\n",
    "#: org.apache.spark.sql.AnalysisException: cannot resolve '`ngrams`' given input columns: [mostfrequent];;\n",
    "#'Project ['ngrams, mostfrequent#8033.count AS count#8037L]\n",
    "#+- AnalysisBarrier\n",
    "#      +- Aggregate [max(named_struct(count, count#8029L)) AS mostfrequent#8033]\n",
    "#         +- Aggregate [ngrams#8016], [ngrams#8016, count(1) AS count#8029L]\n",
    "#            +- Relation[fraud_label#8013L,hash_message#8014,message#8015,ngrams#8016,words#8017] json\n",
    "#\n",
    "####### OLD  ######\n",
    "#.groupby(col('hash_message'))\\\n",
    "#.agg(F.first(col('features_85')).alias('features_85'),\\\n",
    "#     F.first(col('fraud_label')).alias('fraud_label'),\\\n",
    "#     F.first(col('ngrams_85')).alias('ngrams_85'),\\\n",
    "#     F.first(col('ngramscounts_85')).alias('ngramscounts_85'),F.first(col('words')).alias('words'))\n",
    "####################\n",
    "#\n",
    "most_frequent_df=ngram8590_fraud\\\n",
    ".withColumn(\"value_sum\",F.explode(\"ngramscounts_85.values\"))\\\n",
    ".groupBy(\"hash_message\").agg(F.sum(\"value_sum\").alias('count'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "most_frequent_df.printSchema()\n",
    "#\n",
    "most_frequent_df.coalesce(1).write.json(output_most_frequent_df)\n",
    "#\n",
    "# The most Frequent would the the max\n",
    "standard_fraud_ngram=most_frequent_df.orderBy(col('count').desc()).select(col('hash_message')).limit(1).toPandas()\n",
    "#\n",
    "print(\"Value Print: standard_fraud_ngram=\")\n",
    "print(standard_fraud_ngram)\n",
    "#\n",
    "print(\"Calculation of standard_fraud_ngram - Done!\")\n",
    "#\n",
    "sc.stop()\n",
    "#\n",
    "print(\"Preparation of Data Done!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>1 day 20 hours 32 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.1</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>2 months and 29 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_siemanalyst_f03p4d</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>4.908 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.4 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         1 day 20 hours 32 mins\n",
       "H2O cluster timezone:       UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.1\n",
       "H2O cluster version age:    2 months and 29 days\n",
       "H2O cluster name:           H2O_from_python_siemanalyst_f03p4d\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    4.908 Gb\n",
       "H2O cluster total cores:    12\n",
       "H2O cluster allowed cores:  12\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.4 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value UDF : standard_fraud_ngram=\n",
      "865fc00f8a94dd1c467c39753bfb2b18626f2827db85a05654caf048e657b6856afad3fef87873197e7f92e0ff760c8f04cd5484c910a037476643addfdb5c31\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_85: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_85: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "#\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "#\n",
    "#import org.apache.spark.ml.feature.NGram\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from collections import Counter\n",
    "#\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from pyspark.ml.feature import NGram, CountVectorizer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "#\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "#\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "#\n",
    "# FUNCTIONS\n",
    "# \n",
    "##\n",
    "## Register Generic UDF Functions\n",
    "# -----------------------------------------------------------------------------\n",
    "# KL : Kullback-Leibler Divergence\n",
    "# KS : Kolmogorov-Smirnov ( Sample sizes can be different)\n",
    "# -----------------------------------------------------------------------------    \n",
    "## NGRAM KL from URL TO Default NGRAM KL\n",
    "def func_kl_ngram_msg(var1,var_match):\n",
    "    def KL(P,Q):\n",
    "        epsilon = 0.00001\n",
    "        P = P+epsilon\n",
    "        Q = Q+epsilon\n",
    "        divergence = np.sum(P*np.log(P/Q))\n",
    "        return np.asscalar(divergence)\n",
    "    ##Making sure the analysis ignore uri and focus on typical message site names.\n",
    "    cleanvar=var1.strip('http://').strip('https://').strip('www.')\n",
    "    len_var1=len(cleanvar)\n",
    "    idx_var1=cleanvar.split(\"/\")[0]\n",
    "    list_values1 = list(cleanvar)\n",
    "    list_of_ord_values1 = [ord(char) for char in list_values1]\n",
    "    values1 = np.asarray(list_of_ord_values1)\n",
    "    # URLS with at least 4166 characters\n",
    "    ## TODO : Complete this list with common non-Malware/phishing sites used in internal webtraffic\n",
    "    list_values2 = var_match\n",
    "    ## Making sure the analysis start on the same webdomain name\n",
    "    idx_var2 = list_values2.find(idx_var1)\n",
    "    start_values2 = list_values2[idx_var2:(idx_var2+len_var1)]\n",
    "    list_values2 = list(start_values2+list_values2)\n",
    "    list_values2 = list_values2[:len_var1]\n",
    "    list_of_ord_values2 = [ord(char) for char in list_values2]\n",
    "    values2 = np.asarray(list_of_ord_values2)\n",
    "    print(list_values1,list_values2)\n",
    "    print(values1,values2)\n",
    "    return KL(values1,values2)\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "## NGRAM \"Kolmogorov-Smirnov test KS pvalue= ks_2samp function8.\n",
    "def func_ks_ngram_msg(var1,var_match):\n",
    "    ##Making sure the analysis ignore uri and focus on typical message names.\n",
    "    cleanvar=var1.strip('http://').strip('https://').strip('www.')\n",
    "    len_var1=len(cleanvar)\n",
    "    idx_var1=cleanvar.split(\"/\")[0]\n",
    "    list_values1 = list(cleanvar)\n",
    "    list_of_ord_values1 = [ord(char) for char in list_values1]\n",
    "    values1 = np.asarray(list_of_ord_values1)\n",
    "    values1= np.sort(values1)\n",
    "    # URLS with at least 4166 characters\n",
    "    ## TODO : Complete this list with common non-Malware/phishing sites used in internal webtraffic\n",
    "    list_values2 = var_match\n",
    "    # Making sure the analysis start on the same webdomain name\n",
    "    idx_var2 = list_values2.find(idx_var1)\n",
    "    start_values2 = list_values2[idx_var2:(idx_var2+len_var1)]\n",
    "    list_values2 = list(start_values2+list_values2)\n",
    "    list_values2 = list_values2[:len_var1]\n",
    "    list_of_ord_values2 = [ord(char) for char in list_values2]\n",
    "    values2 = np.asarray(list_of_ord_values2)\n",
    "    values2=np.sort(values2)\n",
    "    (Darray,pvalue)=stats.ks_2samp(values1, values2)\n",
    "    return np.asscalar(pvalue)\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "## URL Entropy TO phishing URL function17.\n",
    "def func_entropy_msg(var1,var2):\n",
    "    ##Making sure the analysis ignore uri and focus on typical message names.\n",
    "    cleanvar=var1.strip('http://').strip('https://').strip('www.')\n",
    "    len_var1=len(cleanvar)\n",
    "    idx_var1=cleanvar.split(\"/\")[0]\n",
    "    list_values1 = list(cleanvar)\n",
    "    list_of_ord_values1 = [ord(char) for char in list_values1]\n",
    "    values1 = np.asarray(list_of_ord_values1)\n",
    "    # URLS with Up to 4166 characters\n",
    "    list_values2 = var2\n",
    "    ## Making sure the analysis start on the same webdomain name\n",
    "    idx_var2 = list_values2.find(idx_var1)\n",
    "    start_values2 = list_values2[idx_var2:(idx_var2+len_var1)]\n",
    "    list_values2 = list(start_values2+list_values2)\n",
    "    list_values2 = list_values2[:len_var1]\n",
    "    list_of_ord_values2 = [ord(char) for char in list_values2]\n",
    "    values2 = np.asarray(list_of_ord_values2)\n",
    "    pvalue=stats.entropy(values1, values2)\n",
    "    scalar_pvalue=np.asscalar(pvalue)\n",
    "    return scalar_pvalue\n",
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "func_kl_ngram_msg_udf = udf(func_kl_ngram_msg, FloatType())\n",
    "func_ks_ngram_msg_udf = udf(func_ks_ngram_msg, FloatType())\n",
    "func_entropy_msg_udf = udf(func_entropy_msg, FloatType())\n",
    "#\n",
    "# Arguments\n",
    "#\n",
    "import argparse\n",
    "## Parse date_of execution\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"--datev1\", help=\"Execution Date\")\n",
    "#args = parser.parse_args()\n",
    "#if args.datev1:\n",
    "#    processdate = args.datev1\n",
    "# GENERAL PREPARATION SCRIPT\n",
    "#\n",
    "#  Date in format YYYYMMDD\n",
    "#process_date = processdate\n",
    "#if not process_date:\n",
    "#    process_date = \"20181231\"\n",
    "#\n",
    "process_date=\"20190122\"\n",
    "#\n",
    "#\n",
    "sc = pyspark.SparkContext()\n",
    "conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','2047mb'),('spark.driver.memory','23g'),('spark.driver.maxResultSize','21g')])\n",
    "sc.stop()\n",
    "sc = pyspark.SparkContext(conf=conf,appName=\"Notebook-FraudCanada-Model-NGrams-CountVectorizer-KL-KS-Entropy-Model-Discovery\")\n",
    "sqlContext = SQLContext(sc)\n",
    "#\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "#\n",
    "import subprocess\n",
    "subprocess.run('unset http_proxy', shell=True)\n",
    "#\n",
    "# Start an H2O virtual cluster that uses 6 gigs of RAM and 6 cores\n",
    "h2o.init(ip=\"localhost\",port=54321,max_mem_size = \"6g\", nthreads = 6) \n",
    "#\n",
    "# Clean up the cluster just in case\n",
    "h2o.remove_all()\n",
    "#\n",
    "input_most_frequent_df=\"hdfs:///data/staged/ott_dazn/advanced-model-data/output_most_frequent_fraud_hash_message/dt=\"+process_date\n",
    "#\n",
    "input_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-canada-tokenizedwords-ngrams-85-90/dt=\"+process_date\n",
    "output_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/label-fraud-data-model/dt=\"+process_date\n",
    "#\n",
    "input_file2=\"hdfs:///data/staged/ott_dazn/advanced-model-data/not-fraud-canada-tokenizedwords-ngrams-85-90/dt=\"+process_date\n",
    "output_file2=\"hdfs:///data/staged/ott_dazn/advanced-model-data/label-not-fraud-data-model/dt=\"+process_date\n",
    "#\n",
    "#\n",
    "# The most Frequent would the the max\n",
    "pd.options.display.max_colwidth = 512\n",
    "standard_fraud_ngram=sqlContext.read.json(input_most_frequent_df)\\\n",
    ".orderBy(col('count').desc()).select(col('hash_message')).limit(1).toPandas()['hash_message'][0]\n",
    "print(\"Value UDF : standard_fraud_ngram=\")\n",
    "print(standard_fraud_ngram)\n",
    "#\n",
    "#\n",
    "ngram8590_fraud=sqlContext.read.json(input_file1)\n",
    "ngram8590_fraud.printSchema()\n",
    "#\n",
    "drop_phish_cols=['message']\n",
    "#\n",
    "fraud_label_read_df=ngram8590_fraud\\\n",
    ".filter(\"hash_message is not NULL\")\\\n",
    ".drop(*drop_phish_cols)\\\n",
    ".withColumn('kl_hash_message',func_kl_ngram_msg_udf(col('hash_message'),lit(standard_fraud_ngram).cast('string') ).cast('double'))\\\n",
    ".withColumn('ks_hash_message',func_ks_ngram_msg_udf(col('hash_message'),lit(standard_fraud_ngram).cast('string')).cast('double'))\\\n",
    ".withColumn('entropy_hash_message',func_entropy_msg_udf(col('hash_message'),lit(standard_fraud_ngram).cast('string')).cast('double'))\n",
    "#\n",
    "fraud_label_read_df.coalesce(1).write.json(output_file1)\n",
    "#\n",
    "ngram8590_not_fraud=sqlContext.read.json(input_file2)\n",
    "ngram8590_not_fraud.printSchema()\n",
    "#\n",
    "not_fraud_label_read_df=ngram8590_not_fraud\\\n",
    ".filter(\"hash_message is not NULL\")\\\n",
    ".drop(*drop_phish_cols)\\\n",
    ".withColumn('kl_hash_message',func_kl_ngram_msg_udf(col('hash_message'),lit(standard_fraud_ngram).cast('string')).cast('double'))\\\n",
    ".withColumn('ks_hash_message',func_ks_ngram_msg_udf(col('hash_message'),lit(standard_fraud_ngram).cast('string') ).cast('double'))\\\n",
    ".withColumn('entropy_hash_message',func_entropy_msg_udf(col('hash_message'),lit(standard_fraud_ngram).cast('string')).cast('double'))\n",
    "#\n",
    "not_fraud_label_read_df.coalesce(1).write.json(output_file2)\n",
    "#\n",
    "#\n",
    "#  TRAINING PROCESS\n",
    "#\n",
    "print(\"Start Training Model NGrams Vectors KS KL Entropty\")\n",
    "#\n",
    "# Horrible code :: close your eyes, is ugly\n",
    "#\n",
    "fraud_label_read_df=sqlContext.read.json(output_file1).\\\n",
    "select(col('hash_message').cast('string'), col('fraud_label').cast('int'),\\\n",
    "       col('kl_hash_message').cast('double'), col('ks_hash_message').cast('double'),\\\n",
    "       col('entropy_hash_message').cast('double'), col('features_85.size').cast('int'),\\\n",
    "       col('features_85.type').cast('int'),\\\n",
    "       substring_index(col('features_85.indexes'),',',0).cast('double').alias('features_85_indexes_1'),\\\n",
    "       substring_index(col('features_85.indexes'),',',1).cast('double').alias('features_85_indexes_2'),\\\n",
    "       substring_index(col('features_85.indexes'),',',2).cast('double').alias('features_85_indexes_4'),\\\n",
    "       substring_index(col('features_85.indexes'),',',3).cast('double').alias('features_85_indexes_4'),\\\n",
    "       substring_index(col('features_85.indexes'),',',4).cast('double').alias('features_85_indexes_5'),\\\n",
    "       substring_index(col('features_85.indexes'),',',5).cast('double').alias('features_85_indexes_6'),\\\n",
    "       substring_index(col('features_85.indexes'),',',6).cast('double').alias('features_85_indexes_7'),\\\n",
    "       substring_index(col('features_85.indexes'),',',7).cast('double').alias('features_85_indexes_8'),\\\n",
    "       substring_index(col('features_85.indexes'),',',8).cast('double').alias('features_85_indexes_9'),\\\n",
    "       substring_index(col('features_85.indexes'),',',9).cast('double').alias('features_85_indexes_10'),\\\n",
    "       substring_index(col('features_85.indexes'),',',10).cast('double').alias('features_85_indexes_11'),\\\n",
    "       substring_index(col('features_85.indexes'),',',11).cast('double').alias('features_85_indexes_12'),\\\n",
    "       substring_index(col('features_85.indexes'),',',12).cast('double').alias('features_85_indexes_13'),\\\n",
    "       substring_index(col('features_85.indexes'),',',13).cast('double').alias('features_85_indexes_14'),\\\n",
    "       substring_index(col('features_85.indexes'),',',14).cast('double').alias('features_85_indexes_15'),\\\n",
    "       substring_index(col('features_85.indexes'),',',15).cast('double').alias('features_85_indexes_16'),\\\n",
    "       substring_index(col('features_85.indexes'),',',16).cast('double').alias('features_85_indexes_17'),\\\n",
    "       substring_index(col('features_85.indexes'),',',17).cast('double').alias('features_85_indexes_18'),\\\n",
    "       substring_index(col('features_85.indexes'),',',18).cast('double').alias('features_85_indexes_19'),\\\n",
    "       substring_index(col('features_85.indexes'),',',19).cast('double').alias('features_85_indexes_20'),\\\n",
    "       substring_index(col('features_85.indexes'),',',20).cast('double').alias('features_85_indexes_21'),\\\n",
    "       substring_index(col('features_85.indexes'),',',21).cast('double').alias('features_85_indexes_22'),\\\n",
    "       substring_index(col('features_85.indexes'),',',22).cast('double').alias('features_85_indexes_23'),\\\n",
    "       substring_index(col('features_85.indexes'),',',23).cast('double').alias('features_85_indexes_24'),\\\n",
    "       substring_index(col('features_85.indexes'),',',24).cast('double').alias('features_85_indexes_25'),\\\n",
    "       substring_index(col('features_85.indexes'),',',25).cast('double').alias('features_85_indexes_26'),\\\n",
    "       substring_index(col('features_85.indexes'),',',26).cast('double').alias('features_85_indexes_27'),\\\n",
    "       substring_index(col('features_85.indexes'),',',27).cast('double').alias('features_85_indexes_28'),\\\n",
    "       substring_index(col('features_85.indexes'),',',28).cast('double').alias('features_85_indexes_29'),\\\n",
    "       substring_index(col('features_85.indexes'),',',29).cast('double').alias('features_85_indexes_30'),\\\n",
    "       substring_index(col('features_85.indexes'),',',30).cast('double').alias('features_85_indexes_31'),\\\n",
    "       substring_index(col('features_85.indexes'),',',31).cast('double').alias('features_85_indexes_32'),\\\n",
    "       substring_index(col('features_85.indexes'),',',32).cast('double').alias('features_85_indexes_33'),\\\n",
    "       substring_index(col('features_85.indexes'),',',33).cast('double').alias('features_85_indexes_34'),\\\n",
    "       substring_index(col('features_85.indexes'),',',34).cast('double').alias('features_85_indexes_35'),\\\n",
    "       substring_index(col('features_85.indexes'),',',35).cast('double').alias('features_85_indexes_36'),\\\n",
    "       substring_index(col('features_85.indexes'),',',36).cast('double').alias('features_85_indexes_37'),\\\n",
    "       substring_index(col('features_85.indexes'),',',37).cast('double').alias('features_85_indexes_38'),\\\n",
    "       substring_index(col('features_85.indexes'),',',38).cast('double').alias('features_85_indexes_39'),\\\n",
    "       substring_index(col('features_85.indexes'),',',39).cast('double').alias('features_85_indexes_40'),\\\n",
    "       substring_index(col('features_85.indexes'),',',40).cast('double').alias('features_85_indexes_41'),\\\n",
    "       substring_index(col('features_85.indexes'),',',41).cast('double').alias('features_85_indexes_42'),\\\n",
    "       substring_index(col('features_85.indexes'),',',42).cast('double').alias('features_85_indexes_43'),\\\n",
    "       substring_index(col('features_85.indexes'),',',43).cast('double').alias('features_85_indexes_44'),\\\n",
    "       substring_index(col('features_85.indexes'),',',44).cast('double').alias('features_85_indexes_45'),\\\n",
    "       substring_index(col('features_85.indexes'),',',45).cast('double').alias('features_85_indexes_46'),\\\n",
    "       substring_index(col('features_85.indexes'),',',46).cast('double').alias('features_85_indexes_47'),\\\n",
    "       substring_index(col('features_85.indexes'),',',47).cast('double').alias('features_85_indexes_48'),\\\n",
    "       substring_index(col('features_85.indexes'),',',48).cast('double').alias('features_85_indexes_49'),\\\n",
    "       substring_index(col('features_85.indexes'),',',49).cast('double').alias('features_85_indexes_50'),\\\n",
    "       substring_index(col('features_85.indexes'),',',50).cast('double').alias('features_85_indexes_51'),\\\n",
    "       substring_index(col('features_85.indexes'),',',51).cast('double').alias('features_85_indexes_52'),\\\n",
    "       substring_index(col('features_85.indexes'),',',52).cast('double').alias('features_85_indexes_53'),\\\n",
    "       substring_index(col('features_85.indexes'),',',53).cast('double').alias('features_85_indexes_54'),\\\n",
    "       substring_index(col('features_85.indexes'),',',54).cast('double').alias('features_85_indexes_55'),\\\n",
    "       substring_index(col('features_85.indexes'),',',55).cast('double').alias('features_85_indexes_56'),\\\n",
    "       substring_index(col('features_85.indexes'),',',56).cast('double').alias('features_85_indexes_57'),\\\n",
    "       substring_index(col('features_85.indexes'),',',57).cast('double').alias('features_85_indexes_58'),\\\n",
    "       substring_index(col('features_85.indexes'),',',58).cast('double').alias('features_85_indexes_59'),\\\n",
    "       substring_index(col('features_85.indexes'),',',59).cast('double').alias('features_85_indexes_60'),\\\n",
    "       substring_index(col('features_85.indexes'),',',60).cast('double').alias('features_85_indexes_61'),\\\n",
    "       substring_index(col('features_85.indexes'),',',61).cast('double').alias('features_85_indexes_62'),\\\n",
    "       substring_index(col('features_85.indexes'),',',62).cast('double').alias('features_85_indexes_63'),\\\n",
    "       substring_index(col('features_85.indexes'),',',63).cast('double').alias('features_85_indexes_64'),\\\n",
    "       substring_index(col('features_85.indexes'),',',64).cast('double').alias('features_85_indexes_65'),\\\n",
    "       substring_index(col('features_85.indexes'),',',65).cast('double').alias('features_85_indexes_66'),\\\n",
    "       substring_index(col('features_85.indexes'),',',66).cast('double').alias('features_85_indexes_67'),\\\n",
    "       substring_index(col('features_85.indexes'),',',67).cast('double').alias('features_85_indexes_68'),\\\n",
    "       substring_index(col('features_85.indexes'),',',68).cast('double').alias('features_85_indexes_69'),\\\n",
    "       substring_index(col('features_85.indexes'),',',69).cast('double').alias('features_85_indexes_70'),\\\n",
    "       substring_index(col('features_85.indexes'),',',70).cast('double').alias('features_85_indexes_71'),\\\n",
    "       substring_index(col('features_85.indexes'),',',71).cast('double').alias('features_85_indexes_72'),\\\n",
    "       substring_index(col('features_85.indexes'),',',72).cast('double').alias('features_85_indexes_73'),\\\n",
    "       substring_index(col('features_85.indexes'),',',73).cast('double').alias('features_85_indexes_74'),\\\n",
    "       substring_index(col('features_85.indexes'),',',74).cast('double').alias('features_85_indexes_75'),\\\n",
    "       substring_index(col('features_85.indexes'),',',75).cast('double').alias('features_85_indexes_76'),\\\n",
    "       substring_index(col('features_85.indexes'),',',76).cast('double').alias('features_85_indexes_77'),\\\n",
    "       substring_index(col('features_85.indexes'),',',77).cast('double').alias('features_85_indexes_78'),\\\n",
    "       substring_index(col('features_85.indexes'),',',78).cast('double').alias('features_85_indexes_70'),\\\n",
    "       substring_index(col('features_85.indexes'),',',79).cast('double').alias('features_85_indexes_80'),\\\n",
    "       substring_index(col('features_85.indexes'),',',80).cast('double').alias('features_85_indexes_82'),\\\n",
    "       substring_index(col('features_85.indexes'),',',81).cast('double').alias('features_85_indexes_82'),\\\n",
    "       substring_index(col('features_85.indexes'),',',82).cast('double').alias('features_85_indexes_83'),\\\n",
    "       substring_index(col('features_85.indexes'),',',83).cast('double').alias('features_85_indexes_84'),\\\n",
    "       substring_index(col('features_85.indexes'),',',84).cast('double').alias('features_85_indexes_85'),\\\n",
    "       substring_index(col('features_85.values'),',',0).cast('double').alias('features_85_values_1'),\\\n",
    "       substring_index(col('features_85.values'),',',0).cast('double').alias('features_85_values_1'),\\\n",
    "       substring_index(col('features_85.values'),',',1).cast('double').alias('features_85_values_2'),\\\n",
    "       substring_index(col('features_85.values'),',',2).cast('double').alias('features_85_values_4'),\\\n",
    "       substring_index(col('features_85.values'),',',3).cast('double').alias('features_85_values_4'),\\\n",
    "       substring_index(col('features_85.values'),',',4).cast('double').alias('features_85_values_5'),\\\n",
    "       substring_index(col('features_85.values'),',',5).cast('double').alias('features_85_values_6'),\\\n",
    "       substring_index(col('features_85.values'),',',6).cast('double').alias('features_85_values_7'),\\\n",
    "       substring_index(col('features_85.values'),',',7).cast('double').alias('features_85_values_8'),\\\n",
    "       substring_index(col('features_85.values'),',',8).cast('double').alias('features_85_values_9'),\\\n",
    "       substring_index(col('features_85.values'),',',9).cast('double').alias('features_85_values_10'),\\\n",
    "       substring_index(col('features_85.values'),',',10).cast('double').alias('features_85_values_11'),\\\n",
    "       substring_index(col('features_85.values'),',',11).cast('double').alias('features_85_values_12'),\\\n",
    "       substring_index(col('features_85.values'),',',12).cast('double').alias('features_85_values_13'),\\\n",
    "       substring_index(col('features_85.values'),',',13).cast('double').alias('features_85_values_14'),\\\n",
    "       substring_index(col('features_85.values'),',',14).cast('double').alias('features_85_values_15'),\\\n",
    "       substring_index(col('features_85.values'),',',15).cast('double').alias('features_85_values_16'),\\\n",
    "       substring_index(col('features_85.values'),',',16).cast('double').alias('features_85_values_17'),\\\n",
    "       substring_index(col('features_85.values'),',',17).cast('double').alias('features_85_values_18'),\\\n",
    "       substring_index(col('features_85.values'),',',18).cast('double').alias('features_85_values_19'),\\\n",
    "       substring_index(col('features_85.values'),',',19).cast('double').alias('features_85_values_20'),\\\n",
    "       substring_index(col('features_85.values'),',',20).cast('double').alias('features_85_values_21'),\\\n",
    "       substring_index(col('features_85.values'),',',21).cast('double').alias('features_85_values_22'),\\\n",
    "       substring_index(col('features_85.values'),',',22).cast('double').alias('features_85_values_23'),\\\n",
    "       substring_index(col('features_85.values'),',',23).cast('double').alias('features_85_values_24'),\\\n",
    "       substring_index(col('features_85.values'),',',24).cast('double').alias('features_85_values_25'),\\\n",
    "       substring_index(col('features_85.values'),',',25).cast('double').alias('features_85_values_26'),\\\n",
    "       substring_index(col('features_85.values'),',',26).cast('double').alias('features_85_values_27'),\\\n",
    "       substring_index(col('features_85.values'),',',27).cast('double').alias('features_85_values_28'),\\\n",
    "       substring_index(col('features_85.values'),',',28).cast('double').alias('features_85_values_29'),\\\n",
    "       substring_index(col('features_85.values'),',',29).cast('double').alias('features_85_values_30'),\\\n",
    "       substring_index(col('features_85.values'),',',30).cast('double').alias('features_85_values_31'),\\\n",
    "       substring_index(col('features_85.values'),',',31).cast('double').alias('features_85_values_32'),\\\n",
    "       substring_index(col('features_85.values'),',',32).cast('double').alias('features_85_values_33'),\\\n",
    "       substring_index(col('features_85.values'),',',33).cast('double').alias('features_85_values_34'),\\\n",
    "       substring_index(col('features_85.values'),',',34).cast('double').alias('features_85_values_35'),\\\n",
    "       substring_index(col('features_85.values'),',',35).cast('double').alias('features_85_values_36'),\\\n",
    "       substring_index(col('features_85.values'),',',36).cast('double').alias('features_85_values_37'),\\\n",
    "       substring_index(col('features_85.values'),',',37).cast('double').alias('features_85_values_38'),\\\n",
    "       substring_index(col('features_85.values'),',',38).cast('double').alias('features_85_values_39'),\\\n",
    "       substring_index(col('features_85.values'),',',39).cast('double').alias('features_85_values_40'),\\\n",
    "       substring_index(col('features_85.values'),',',40).cast('double').alias('features_85_values_41'),\\\n",
    "       substring_index(col('features_85.values'),',',41).cast('double').alias('features_85_values_42'),\\\n",
    "       substring_index(col('features_85.values'),',',42).cast('double').alias('features_85_values_43'),\\\n",
    "       substring_index(col('features_85.values'),',',43).cast('double').alias('features_85_values_44'),\\\n",
    "       substring_index(col('features_85.values'),',',44).cast('double').alias('features_85_values_45'),\\\n",
    "       substring_index(col('features_85.values'),',',45).cast('double').alias('features_85_values_46'),\\\n",
    "       substring_index(col('features_85.values'),',',46).cast('double').alias('features_85_values_47'),\\\n",
    "       substring_index(col('features_85.values'),',',47).cast('double').alias('features_85_values_48'),\\\n",
    "       substring_index(col('features_85.values'),',',48).cast('double').alias('features_85_values_49'),\\\n",
    "       substring_index(col('features_85.values'),',',49).cast('double').alias('features_85_values_50'),\\\n",
    "       substring_index(col('features_85.values'),',',50).cast('double').alias('features_85_values_51'),\\\n",
    "       substring_index(col('features_85.values'),',',51).cast('double').alias('features_85_values_52'),\\\n",
    "       substring_index(col('features_85.values'),',',52).cast('double').alias('features_85_values_53'),\\\n",
    "       substring_index(col('features_85.values'),',',53).cast('double').alias('features_85_values_54'),\\\n",
    "       substring_index(col('features_85.values'),',',54).cast('double').alias('features_85_values_55'),\\\n",
    "       substring_index(col('features_85.values'),',',55).cast('double').alias('features_85_values_56'),\\\n",
    "       substring_index(col('features_85.values'),',',56).cast('double').alias('features_85_values_57'),\\\n",
    "       substring_index(col('features_85.values'),',',57).cast('double').alias('features_85_values_58'),\\\n",
    "       substring_index(col('features_85.values'),',',58).cast('double').alias('features_85_values_59'),\\\n",
    "       substring_index(col('features_85.values'),',',59).cast('double').alias('features_85_values_60'),\\\n",
    "       substring_index(col('features_85.values'),',',60).cast('double').alias('features_85_values_61'),\\\n",
    "       substring_index(col('features_85.values'),',',61).cast('double').alias('features_85_values_62'),\\\n",
    "       substring_index(col('features_85.values'),',',62).cast('double').alias('features_85_values_63'),\\\n",
    "       substring_index(col('features_85.values'),',',63).cast('double').alias('features_85_values_64'),\\\n",
    "       substring_index(col('features_85.values'),',',64).cast('double').alias('features_85_values_65'),\\\n",
    "       substring_index(col('features_85.values'),',',65).cast('double').alias('features_85_values_66'),\\\n",
    "       substring_index(col('features_85.values'),',',66).cast('double').alias('features_85_values_67'),\\\n",
    "       substring_index(col('features_85.values'),',',67).cast('double').alias('features_85_values_68'),\\\n",
    "       substring_index(col('features_85.values'),',',68).cast('double').alias('features_85_values_69'),\\\n",
    "       substring_index(col('features_85.values'),',',69).cast('double').alias('features_85_values_70'),\\\n",
    "       substring_index(col('features_85.values'),',',70).cast('double').alias('features_85_values_71'),\\\n",
    "       substring_index(col('features_85.values'),',',71).cast('double').alias('features_85_values_72'),\\\n",
    "       substring_index(col('features_85.values'),',',72).cast('double').alias('features_85_values_73'),\\\n",
    "       substring_index(col('features_85.values'),',',73).cast('double').alias('features_85_values_74'),\\\n",
    "       substring_index(col('features_85.values'),',',74).cast('double').alias('features_85_values_75'),\\\n",
    "       substring_index(col('features_85.values'),',',75).cast('double').alias('features_85_values_76'),\\\n",
    "       substring_index(col('features_85.values'),',',76).cast('double').alias('features_85_values_77'),\\\n",
    "       substring_index(col('features_85.values'),',',77).cast('double').alias('features_85_values_78'),\\\n",
    "       substring_index(col('features_85.values'),',',78).cast('double').alias('features_85_values_70'),\\\n",
    "       substring_index(col('features_85.values'),',',79).cast('double').alias('features_85_values_80'),\\\n",
    "       substring_index(col('features_85.values'),',',80).cast('double').alias('features_85_values_82'),\\\n",
    "       substring_index(col('features_85.values'),',',81).cast('double').alias('features_85_values_82'),\\\n",
    "       substring_index(col('features_85.values'),',',82).cast('double').alias('features_85_values_83'),\\\n",
    "       substring_index(col('features_85.values'),',',83).cast('double').alias('features_85_values_84'),\\\n",
    "       substring_index(col('features_85.values'),',',84).cast('double').alias('features_85_values_85'),\\\n",
    "       col('ngramscounts_85.size').cast('int'), col('ngramscounts_85.type').cast('int'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',0).cast('double').alias('ngramscounts_85_indexes_1'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',1).cast('double').alias('ngramscounts_85_indexes_2'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',2).cast('double').alias('ngramscounts_85_indexes_3'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',3).cast('double').alias('ngramscounts_85_indexes_4'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',4).cast('double').alias('ngramscounts_85_indexes_5'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',5).cast('double').alias('ngramscounts_85_indexes_6'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',6).cast('double').alias('ngramscounts_85_indexes_7'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',7).cast('double').alias('ngramscounts_85_indexes_8'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',0).cast('double').alias('ngramscounts_85values_1'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',1).cast('double').alias('ngramscounts_85values_2'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',2).cast('double').alias('ngramscounts_85values_3'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',3).cast('double').alias('ngramscounts_85values_4'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',4).cast('double').alias('ngramscounts_85values_5'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',5).cast('double').alias('ngramscounts_85values_6'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',6).cast('double').alias('ngramscounts_85values_7'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',7).cast('double').alias('ngramscounts_85values_8'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "#\n",
    "fraud_label_train_pd=fraud_label_read_df.toPandas()\n",
    "fraud_label_test_pd=fraud_label_train_pd.toPandas().tail(500)                                                                        \n",
    "fraud_label_train=h2o.H2OFrame(fraud_label_train_pd)\n",
    "fraud_label_test=h2o.H2OFrame(fraud_label_test_pd)\n",
    "#\n",
    "# Horrible code :: close your eyes, is ugly\n",
    "#\n",
    "not_fraud_label_read_df=sqlContext.read.json(output_file2).\\\n",
    "select(col('hash_message').cast('string'), col('fraud_label').cast('int'),\\\n",
    "       col('kl_hash_message').cast('double'), col('ks_hash_message').cast('double'),\\\n",
    "       col('entropy_hash_message').cast('double'), col('features_85.size').cast('int'),\\\n",
    "       col('features_85.type').cast('int'),\\\n",
    "       substring_index(col('features_85.indexes'),',',0).cast('double').alias('features_85_indexes_1'),\\\n",
    "       substring_index(col('features_85.indexes'),',',1).cast('double').alias('features_85_indexes_2'),\\\n",
    "       substring_index(col('features_85.indexes'),',',2).cast('double').alias('features_85_indexes_4'),\\\n",
    "       substring_index(col('features_85.indexes'),',',3).cast('double').alias('features_85_indexes_4'),\\\n",
    "       substring_index(col('features_85.indexes'),',',4).cast('double').alias('features_85_indexes_5'),\\\n",
    "       substring_index(col('features_85.indexes'),',',5).cast('double').alias('features_85_indexes_6'),\\\n",
    "       substring_index(col('features_85.indexes'),',',6).cast('double').alias('features_85_indexes_7'),\\\n",
    "       substring_index(col('features_85.indexes'),',',7).cast('double').alias('features_85_indexes_8'),\\\n",
    "       substring_index(col('features_85.indexes'),',',8).cast('double').alias('features_85_indexes_9'),\\\n",
    "       substring_index(col('features_85.indexes'),',',9).cast('double').alias('features_85_indexes_10'),\\\n",
    "       substring_index(col('features_85.indexes'),',',10).cast('double').alias('features_85_indexes_11'),\\\n",
    "       substring_index(col('features_85.indexes'),',',11).cast('double').alias('features_85_indexes_12'),\\\n",
    "       substring_index(col('features_85.indexes'),',',12).cast('double').alias('features_85_indexes_13'),\\\n",
    "       substring_index(col('features_85.indexes'),',',13).cast('double').alias('features_85_indexes_14'),\\\n",
    "       substring_index(col('features_85.indexes'),',',14).cast('double').alias('features_85_indexes_15'),\\\n",
    "       substring_index(col('features_85.indexes'),',',15).cast('double').alias('features_85_indexes_16'),\\\n",
    "       substring_index(col('features_85.indexes'),',',16).cast('double').alias('features_85_indexes_17'),\\\n",
    "       substring_index(col('features_85.indexes'),',',17).cast('double').alias('features_85_indexes_18'),\\\n",
    "       substring_index(col('features_85.indexes'),',',18).cast('double').alias('features_85_indexes_19'),\\\n",
    "       substring_index(col('features_85.indexes'),',',19).cast('double').alias('features_85_indexes_20'),\\\n",
    "       substring_index(col('features_85.indexes'),',',20).cast('double').alias('features_85_indexes_21'),\\\n",
    "       substring_index(col('features_85.indexes'),',',21).cast('double').alias('features_85_indexes_22'),\\\n",
    "       substring_index(col('features_85.indexes'),',',22).cast('double').alias('features_85_indexes_23'),\\\n",
    "       substring_index(col('features_85.indexes'),',',23).cast('double').alias('features_85_indexes_24'),\\\n",
    "       substring_index(col('features_85.indexes'),',',24).cast('double').alias('features_85_indexes_25'),\\\n",
    "       substring_index(col('features_85.indexes'),',',25).cast('double').alias('features_85_indexes_26'),\\\n",
    "       substring_index(col('features_85.indexes'),',',26).cast('double').alias('features_85_indexes_27'),\\\n",
    "       substring_index(col('features_85.indexes'),',',27).cast('double').alias('features_85_indexes_28'),\\\n",
    "       substring_index(col('features_85.indexes'),',',28).cast('double').alias('features_85_indexes_29'),\\\n",
    "       substring_index(col('features_85.indexes'),',',29).cast('double').alias('features_85_indexes_30'),\\\n",
    "       substring_index(col('features_85.indexes'),',',30).cast('double').alias('features_85_indexes_31'),\\\n",
    "       substring_index(col('features_85.indexes'),',',31).cast('double').alias('features_85_indexes_32'),\\\n",
    "       substring_index(col('features_85.indexes'),',',32).cast('double').alias('features_85_indexes_33'),\\\n",
    "       substring_index(col('features_85.indexes'),',',33).cast('double').alias('features_85_indexes_34'),\\\n",
    "       substring_index(col('features_85.indexes'),',',34).cast('double').alias('features_85_indexes_35'),\\\n",
    "       substring_index(col('features_85.indexes'),',',35).cast('double').alias('features_85_indexes_36'),\\\n",
    "       substring_index(col('features_85.indexes'),',',36).cast('double').alias('features_85_indexes_37'),\\\n",
    "       substring_index(col('features_85.indexes'),',',37).cast('double').alias('features_85_indexes_38'),\\\n",
    "       substring_index(col('features_85.indexes'),',',38).cast('double').alias('features_85_indexes_39'),\\\n",
    "       substring_index(col('features_85.indexes'),',',39).cast('double').alias('features_85_indexes_40'),\\\n",
    "       substring_index(col('features_85.indexes'),',',40).cast('double').alias('features_85_indexes_41'),\\\n",
    "       substring_index(col('features_85.indexes'),',',41).cast('double').alias('features_85_indexes_42'),\\\n",
    "       substring_index(col('features_85.indexes'),',',42).cast('double').alias('features_85_indexes_43'),\\\n",
    "       substring_index(col('features_85.indexes'),',',43).cast('double').alias('features_85_indexes_44'),\\\n",
    "       substring_index(col('features_85.indexes'),',',44).cast('double').alias('features_85_indexes_45'),\\\n",
    "       substring_index(col('features_85.indexes'),',',45).cast('double').alias('features_85_indexes_46'),\\\n",
    "       substring_index(col('features_85.indexes'),',',46).cast('double').alias('features_85_indexes_47'),\\\n",
    "       substring_index(col('features_85.indexes'),',',47).cast('double').alias('features_85_indexes_48'),\\\n",
    "       substring_index(col('features_85.indexes'),',',48).cast('double').alias('features_85_indexes_49'),\\\n",
    "       substring_index(col('features_85.indexes'),',',49).cast('double').alias('features_85_indexes_50'),\\\n",
    "       substring_index(col('features_85.indexes'),',',50).cast('double').alias('features_85_indexes_51'),\\\n",
    "       substring_index(col('features_85.indexes'),',',51).cast('double').alias('features_85_indexes_52'),\\\n",
    "       substring_index(col('features_85.indexes'),',',52).cast('double').alias('features_85_indexes_53'),\\\n",
    "       substring_index(col('features_85.indexes'),',',53).cast('double').alias('features_85_indexes_54'),\\\n",
    "       substring_index(col('features_85.indexes'),',',54).cast('double').alias('features_85_indexes_55'),\\\n",
    "       substring_index(col('features_85.indexes'),',',55).cast('double').alias('features_85_indexes_56'),\\\n",
    "       substring_index(col('features_85.indexes'),',',56).cast('double').alias('features_85_indexes_57'),\\\n",
    "       substring_index(col('features_85.indexes'),',',57).cast('double').alias('features_85_indexes_58'),\\\n",
    "       substring_index(col('features_85.indexes'),',',58).cast('double').alias('features_85_indexes_59'),\\\n",
    "       substring_index(col('features_85.indexes'),',',59).cast('double').alias('features_85_indexes_60'),\\\n",
    "       substring_index(col('features_85.indexes'),',',60).cast('double').alias('features_85_indexes_61'),\\\n",
    "       substring_index(col('features_85.indexes'),',',61).cast('double').alias('features_85_indexes_62'),\\\n",
    "       substring_index(col('features_85.indexes'),',',62).cast('double').alias('features_85_indexes_63'),\\\n",
    "       substring_index(col('features_85.indexes'),',',63).cast('double').alias('features_85_indexes_64'),\\\n",
    "       substring_index(col('features_85.indexes'),',',64).cast('double').alias('features_85_indexes_65'),\\\n",
    "       substring_index(col('features_85.indexes'),',',65).cast('double').alias('features_85_indexes_66'),\\\n",
    "       substring_index(col('features_85.indexes'),',',66).cast('double').alias('features_85_indexes_67'),\\\n",
    "       substring_index(col('features_85.indexes'),',',67).cast('double').alias('features_85_indexes_68'),\\\n",
    "       substring_index(col('features_85.indexes'),',',68).cast('double').alias('features_85_indexes_69'),\\\n",
    "       substring_index(col('features_85.indexes'),',',69).cast('double').alias('features_85_indexes_70'),\\\n",
    "       substring_index(col('features_85.indexes'),',',70).cast('double').alias('features_85_indexes_71'),\\\n",
    "       substring_index(col('features_85.indexes'),',',71).cast('double').alias('features_85_indexes_72'),\\\n",
    "       substring_index(col('features_85.indexes'),',',72).cast('double').alias('features_85_indexes_73'),\\\n",
    "       substring_index(col('features_85.indexes'),',',73).cast('double').alias('features_85_indexes_74'),\\\n",
    "       substring_index(col('features_85.indexes'),',',74).cast('double').alias('features_85_indexes_75'),\\\n",
    "       substring_index(col('features_85.indexes'),',',75).cast('double').alias('features_85_indexes_76'),\\\n",
    "       substring_index(col('features_85.indexes'),',',76).cast('double').alias('features_85_indexes_77'),\\\n",
    "       substring_index(col('features_85.indexes'),',',77).cast('double').alias('features_85_indexes_78'),\\\n",
    "       substring_index(col('features_85.indexes'),',',78).cast('double').alias('features_85_indexes_70'),\\\n",
    "       substring_index(col('features_85.indexes'),',',79).cast('double').alias('features_85_indexes_80'),\\\n",
    "       substring_index(col('features_85.indexes'),',',80).cast('double').alias('features_85_indexes_82'),\\\n",
    "       substring_index(col('features_85.indexes'),',',81).cast('double').alias('features_85_indexes_82'),\\\n",
    "       substring_index(col('features_85.indexes'),',',82).cast('double').alias('features_85_indexes_83'),\\\n",
    "       substring_index(col('features_85.indexes'),',',83).cast('double').alias('features_85_indexes_84'),\\\n",
    "       substring_index(col('features_85.indexes'),',',84).cast('double').alias('features_85_indexes_85'),\\\n",
    "       substring_index(col('features_85.values'),',',0).cast('double').alias('features_85_values_1'),\\\n",
    "       substring_index(col('features_85.values'),',',0).cast('double').alias('features_85_values_1'),\\\n",
    "       substring_index(col('features_85.values'),',',1).cast('double').alias('features_85_values_2'),\\\n",
    "       substring_index(col('features_85.values'),',',2).cast('double').alias('features_85_values_4'),\\\n",
    "       substring_index(col('features_85.values'),',',3).cast('double').alias('features_85_values_4'),\\\n",
    "       substring_index(col('features_85.values'),',',4).cast('double').alias('features_85_values_5'),\\\n",
    "       substring_index(col('features_85.values'),',',5).cast('double').alias('features_85_values_6'),\\\n",
    "       substring_index(col('features_85.values'),',',6).cast('double').alias('features_85_values_7'),\\\n",
    "       substring_index(col('features_85.values'),',',7).cast('double').alias('features_85_values_8'),\\\n",
    "       substring_index(col('features_85.values'),',',8).cast('double').alias('features_85_values_9'),\\\n",
    "       substring_index(col('features_85.values'),',',9).cast('double').alias('features_85_values_10'),\\\n",
    "       substring_index(col('features_85.values'),',',10).cast('double').alias('features_85_values_11'),\\\n",
    "       substring_index(col('features_85.values'),',',11).cast('double').alias('features_85_values_12'),\\\n",
    "       substring_index(col('features_85.values'),',',12).cast('double').alias('features_85_values_13'),\\\n",
    "       substring_index(col('features_85.values'),',',13).cast('double').alias('features_85_values_14'),\\\n",
    "       substring_index(col('features_85.values'),',',14).cast('double').alias('features_85_values_15'),\\\n",
    "       substring_index(col('features_85.values'),',',15).cast('double').alias('features_85_values_16'),\\\n",
    "       substring_index(col('features_85.values'),',',16).cast('double').alias('features_85_values_17'),\\\n",
    "       substring_index(col('features_85.values'),',',17).cast('double').alias('features_85_values_18'),\\\n",
    "       substring_index(col('features_85.values'),',',18).cast('double').alias('features_85_values_19'),\\\n",
    "       substring_index(col('features_85.values'),',',19).cast('double').alias('features_85_values_20'),\\\n",
    "       substring_index(col('features_85.values'),',',20).cast('double').alias('features_85_values_21'),\\\n",
    "       substring_index(col('features_85.values'),',',21).cast('double').alias('features_85_values_22'),\\\n",
    "       substring_index(col('features_85.values'),',',22).cast('double').alias('features_85_values_23'),\\\n",
    "       substring_index(col('features_85.values'),',',23).cast('double').alias('features_85_values_24'),\\\n",
    "       substring_index(col('features_85.values'),',',24).cast('double').alias('features_85_values_25'),\\\n",
    "       substring_index(col('features_85.values'),',',25).cast('double').alias('features_85_values_26'),\\\n",
    "       substring_index(col('features_85.values'),',',26).cast('double').alias('features_85_values_27'),\\\n",
    "       substring_index(col('features_85.values'),',',27).cast('double').alias('features_85_values_28'),\\\n",
    "       substring_index(col('features_85.values'),',',28).cast('double').alias('features_85_values_29'),\\\n",
    "       substring_index(col('features_85.values'),',',29).cast('double').alias('features_85_values_30'),\\\n",
    "       substring_index(col('features_85.values'),',',30).cast('double').alias('features_85_values_31'),\\\n",
    "       substring_index(col('features_85.values'),',',31).cast('double').alias('features_85_values_32'),\\\n",
    "       substring_index(col('features_85.values'),',',32).cast('double').alias('features_85_values_33'),\\\n",
    "       substring_index(col('features_85.values'),',',33).cast('double').alias('features_85_values_34'),\\\n",
    "       substring_index(col('features_85.values'),',',34).cast('double').alias('features_85_values_35'),\\\n",
    "       substring_index(col('features_85.values'),',',35).cast('double').alias('features_85_values_36'),\\\n",
    "       substring_index(col('features_85.values'),',',36).cast('double').alias('features_85_values_37'),\\\n",
    "       substring_index(col('features_85.values'),',',37).cast('double').alias('features_85_values_38'),\\\n",
    "       substring_index(col('features_85.values'),',',38).cast('double').alias('features_85_values_39'),\\\n",
    "       substring_index(col('features_85.values'),',',39).cast('double').alias('features_85_values_40'),\\\n",
    "       substring_index(col('features_85.values'),',',40).cast('double').alias('features_85_values_41'),\\\n",
    "       substring_index(col('features_85.values'),',',41).cast('double').alias('features_85_values_42'),\\\n",
    "       substring_index(col('features_85.values'),',',42).cast('double').alias('features_85_values_43'),\\\n",
    "       substring_index(col('features_85.values'),',',43).cast('double').alias('features_85_values_44'),\\\n",
    "       substring_index(col('features_85.values'),',',44).cast('double').alias('features_85_values_45'),\\\n",
    "       substring_index(col('features_85.values'),',',45).cast('double').alias('features_85_values_46'),\\\n",
    "       substring_index(col('features_85.values'),',',46).cast('double').alias('features_85_values_47'),\\\n",
    "       substring_index(col('features_85.values'),',',47).cast('double').alias('features_85_values_48'),\\\n",
    "       substring_index(col('features_85.values'),',',48).cast('double').alias('features_85_values_49'),\\\n",
    "       substring_index(col('features_85.values'),',',49).cast('double').alias('features_85_values_50'),\\\n",
    "       substring_index(col('features_85.values'),',',50).cast('double').alias('features_85_values_51'),\\\n",
    "       substring_index(col('features_85.values'),',',51).cast('double').alias('features_85_values_52'),\\\n",
    "       substring_index(col('features_85.values'),',',52).cast('double').alias('features_85_values_53'),\\\n",
    "       substring_index(col('features_85.values'),',',53).cast('double').alias('features_85_values_54'),\\\n",
    "       substring_index(col('features_85.values'),',',54).cast('double').alias('features_85_values_55'),\\\n",
    "       substring_index(col('features_85.values'),',',55).cast('double').alias('features_85_values_56'),\\\n",
    "       substring_index(col('features_85.values'),',',56).cast('double').alias('features_85_values_57'),\\\n",
    "       substring_index(col('features_85.values'),',',57).cast('double').alias('features_85_values_58'),\\\n",
    "       substring_index(col('features_85.values'),',',58).cast('double').alias('features_85_values_59'),\\\n",
    "       substring_index(col('features_85.values'),',',59).cast('double').alias('features_85_values_60'),\\\n",
    "       substring_index(col('features_85.values'),',',60).cast('double').alias('features_85_values_61'),\\\n",
    "       substring_index(col('features_85.values'),',',61).cast('double').alias('features_85_values_62'),\\\n",
    "       substring_index(col('features_85.values'),',',62).cast('double').alias('features_85_values_63'),\\\n",
    "       substring_index(col('features_85.values'),',',63).cast('double').alias('features_85_values_64'),\\\n",
    "       substring_index(col('features_85.values'),',',64).cast('double').alias('features_85_values_65'),\\\n",
    "       substring_index(col('features_85.values'),',',65).cast('double').alias('features_85_values_66'),\\\n",
    "       substring_index(col('features_85.values'),',',66).cast('double').alias('features_85_values_67'),\\\n",
    "       substring_index(col('features_85.values'),',',67).cast('double').alias('features_85_values_68'),\\\n",
    "       substring_index(col('features_85.values'),',',68).cast('double').alias('features_85_values_69'),\\\n",
    "       substring_index(col('features_85.values'),',',69).cast('double').alias('features_85_values_70'),\\\n",
    "       substring_index(col('features_85.values'),',',70).cast('double').alias('features_85_values_71'),\\\n",
    "       substring_index(col('features_85.values'),',',71).cast('double').alias('features_85_values_72'),\\\n",
    "       substring_index(col('features_85.values'),',',72).cast('double').alias('features_85_values_73'),\\\n",
    "       substring_index(col('features_85.values'),',',73).cast('double').alias('features_85_values_74'),\\\n",
    "       substring_index(col('features_85.values'),',',74).cast('double').alias('features_85_values_75'),\\\n",
    "       substring_index(col('features_85.values'),',',75).cast('double').alias('features_85_values_76'),\\\n",
    "       substring_index(col('features_85.values'),',',76).cast('double').alias('features_85_values_77'),\\\n",
    "       substring_index(col('features_85.values'),',',77).cast('double').alias('features_85_values_78'),\\\n",
    "       substring_index(col('features_85.values'),',',78).cast('double').alias('features_85_values_70'),\\\n",
    "       substring_index(col('features_85.values'),',',79).cast('double').alias('features_85_values_80'),\\\n",
    "       substring_index(col('features_85.values'),',',80).cast('double').alias('features_85_values_82'),\\\n",
    "       substring_index(col('features_85.values'),',',81).cast('double').alias('features_85_values_82'),\\\n",
    "       substring_index(col('features_85.values'),',',82).cast('double').alias('features_85_values_83'),\\\n",
    "       substring_index(col('features_85.values'),',',83).cast('double').alias('features_85_values_84'),\\\n",
    "       substring_index(col('features_85.values'),',',84).cast('double').alias('features_85_values_85'),\\\n",
    "       col('ngramscounts_85.size').cast('int'), col('ngramscounts_85.type').cast('int'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',0).cast('double').alias('ngramscounts_85_indexes_1'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',1).cast('double').alias('ngramscounts_85_indexes_2'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',2).cast('double').alias('ngramscounts_85_indexes_3'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',3).cast('double').alias('ngramscounts_85_indexes_4'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',4).cast('double').alias('ngramscounts_85_indexes_5'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',5).cast('double').alias('ngramscounts_85_indexes_6'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',6).cast('double').alias('ngramscounts_85_indexes_7'),\\\n",
    "       substring_index(col('ngramscounts_85.indexes'),',',7).cast('double').alias('ngramscounts_85_indexes_8'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',0).cast('double').alias('ngramscounts_85values_1'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',1).cast('double').alias('ngramscounts_85values_2'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',2).cast('double').alias('ngramscounts_85values_3'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',3).cast('double').alias('ngramscounts_85values_4'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',4).cast('double').alias('ngramscounts_85values_5'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',5).cast('double').alias('ngramscounts_85values_6'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',6).cast('double').alias('ngramscounts_85values_7'),\\\n",
    "       substring_index(col('ngramscounts_85.values'),',',7).cast('double').alias('ngramscounts_85values_8'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "#\n",
    "# Train just with the first 25000 random hash_message\n",
    "#\n",
    "not_fraud_label_train_pd=not_fraud_label_read_df.toPandas().head(25000)  \n",
    "not_fraud_label_test_pd=not_fraud_label_train_pd.toPandas().head(500)\n",
    "not_fraud_label_train=h2o.H2OFrame(not_fraud_label_train_pd)\n",
    "not_fraud_label_test=h2o.H2OFrame(not_fraud_label_test_pd)\n",
    "#\n",
    "#\n",
    "###### TRAINING PROCESS ############\n",
    "# RBIND \"Merge\" all of 3 internal ccrawl and phishtank with rbind .\n",
    "# function merge() doesn't work if both H2O/dataframes have same variables\n",
    "#\n",
    "train = fraud_label_train.rbind(not_fraud_label_train)\n",
    "test = fraud_label_test.rbind(not_fraud_label_test)\n",
    "#\n",
    "#\n",
    "print(\"train\")\n",
    "print(train.head(10))\n",
    "print(\"test\")\n",
    "print(test.head(10))\n",
    "#\n",
    "# Identify predictors and response\n",
    "x = train.columns\n",
    "#\n",
    "#Â Fraud Label to be learned in the model from the atrributes of the ngram85 learned words\n",
    "#\n",
    "y= 'fraud_label'\n",
    "x.remove(y)\n",
    "#\n",
    "# For binary classification, response should be a factor\n",
    "#train[y] = train[y].asfactor()\n",
    "#test[y] = test[y].asfactor()\n",
    "#\n",
    "# http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html\n",
    "#Â Balance Classes to compensate unbalanced data\n",
    "# Run AutoML for 25 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=25, seed=19, exclude_algos=[\"DRF\",\"GLM\"])\n",
    "aml.train(x=x, y=y, training_frame=train)\n",
    "#\n",
    "sc.stop()\n",
    "#\n",
    "print(\"Model NGrams Vectors Data Done!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
