{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- awsRegion: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- correlationId: string (nullable = true)\n",
      " |-- function_version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- hostname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- invoked_function_arn: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- level: long (nullable = true)\n",
      " |-- logGroup: string (nullable = true)\n",
      " |-- logStream: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messageType: string (nullable = true)\n",
      " |-- msg: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- owner: string (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- token: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- awsRegion: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- correlationId: string (nullable = true)\n",
      " |-- function_version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- hostname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- invoked_function_arn: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- level: long (nullable = true)\n",
      " |-- logGroup: string (nullable = true)\n",
      " |-- logStream: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messageType: string (nullable = true)\n",
      " |-- msg: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- owner: string (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- token: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- awsRegion: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- correlationId: string (nullable = true)\n",
      " |-- function_version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- hostname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- invoked_function_arn: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- level: long (nullable = true)\n",
      " |-- logGroup: string (nullable = true)\n",
      " |-- logStream: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messageType: string (nullable = true)\n",
      " |-- msg: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- owner: string (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- token: string (nullable = true)\n",
      " |-- messagecut: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messagecut: string (nullable = true)\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- message: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- @metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- @timestamp: string (nullable = true)\n",
      " |-- __logz_account_id: string (nullable = true)\n",
      " |-- __logz_received_timestamp: string (nullable = true)\n",
      " |-- __logzio_X-B3-Sampled: string (nullable = true)\n",
      " |-- __logzio_X-B3-SpanId: string (nullable = true)\n",
      " |-- __logzio_X-B3-TraceId: string (nullable = true)\n",
      " |-- __logzio_id: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messagecut: string (nullable = true)\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- message: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngrams_7: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- ngramscounts_7: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngrams_7: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- ngramscounts_7: vector (nullable = true)\n",
      " |-- features_85: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_7: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_7: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "Calculation of standard_fraud_ngram - Start!\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Print: standard_fraud_ngram=\n",
      "                                        hash_message\n",
      "0  8ddb1c2d52ccffc9d4e980fa9ba306758c87e9fa8f9626...\n",
      "Calculation of standard_fraud_ngram - Done!\n",
      "Preparation of Data Done!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "#\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "#\n",
    "#import org.apache.spark.ml.feature.NGram\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from collections import Counter\n",
    "#\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from pyspark.ml.feature import NGram, CountVectorizer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "#\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "#\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "#\n",
    "#\n",
    "#\n",
    "# Ugly workarround to increase spark.kryoserializer.buffer.max\n",
    "# Only way in session to Run :\n",
    "#        - treeAggregate at RowMatrix.scala:122 \n",
    "#        - first at PCA.scala:43\n",
    "#\n",
    "sc = pyspark.SparkContext()\n",
    "#conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','2047mb'),('spark.driver.memory','23g'),('spark.driver.maxResultSize','21g')])\n",
    "conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','512mb')])\n",
    "sc.stop()\n",
    "sc = pyspark.SparkContext(conf=conf,appName=\"Notebook-FraudCanada-Model-NGrams-CountVectorizer-KL-KS-Entropy-Model-CleanData\")\n",
    "sqlContext = SQLContext(sc)\n",
    "#\n",
    "#\n",
    "# Arguments\n",
    "#\n",
    "#import argparse\n",
    "## Parse date_of execution\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"--datev1\", help=\"Execution Date\")\n",
    "#args = parser.parse_args()\n",
    "#if args.datev1:\n",
    "#    processdate = args.datev1\n",
    "# GENERAL PREPARATION SCRIPT\n",
    "#\n",
    "#  Date in format YYYYMMDD\n",
    "#process_date = processdate\n",
    "#if not process_date:\n",
    "#    process_date = \"20181231\"\n",
    "#\n",
    "process_date=\"20190122\"\n",
    "#\n",
    "input_file1_playback_fraud=\"hdfs:///data/staged/ott_dazn/fraud-canada-tokenizedwords/dt=*/*.json\"\n",
    "output_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-7-features-85/dt=\"+process_date\n",
    "#\n",
    "input_file2_playback_not_fraud=\"hdfs:///data/staged/ott_dazn/logs-archive-production/parquet/dt=\"+process_date+\"/*.parquet\"\n",
    "output_file2=\"hdfs:///data/staged/ott_dazn/advanced-model-data/not-fraud-canada-tokenizedwords/dt=\"+process_date\n",
    "input_file3=output_file2\n",
    "#\n",
    "input_file4=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-7-features-85/dt=\"+process_date+\"/*.*\"\n",
    "#\n",
    "output_most_frequent_df=\"hdfs:///data/staged/ott_dazn/advanced-model-data/the-most-frequent-fraud-hash_message/dt=\"+process_date\n",
    "#\n",
    "#  FILTER Non-Fraud AND LABEL\n",
    "from pyspark.sql import functions as F\n",
    "#\n",
    "#\n",
    "df2= sqlContext.read.parquet(input_file2_playback_not_fraud)\n",
    "df2.printSchema()\n",
    "#\n",
    "df3 = df2.filter(\" (message LIKE '%\\\"Url\\\":\\\"https://isl-ca.dazn.com/misl/v2/Playback%') AND (message LIKE '%,\\\"Response\\\":{\\\"StatusCode\\\":200,\\\"ReasonPhrase\\\":\\\"OK\\\",%') AND ( ( (message LIKE '%&Format=MPEG-DASH&%' OR message LIKE '%&Format=M3U&%') ) OR (message NOT LIKE '%\\\"User-Agent\\\":\\\"Mozilla/5.0,(Macintosh; Intel Mac OS X 10_12_6),AppleWebKit/605.1.75,(KHTML, like Gecko),Version/11.1.2,Safari/605.1.75\\\"},%')   )  \")\n",
    "df3.printSchema()\n",
    "df4 = df3.withColumn(\"messagecut\", expr(\"substring(message, locate('|Livesport.WebApi.Controllers.Playback.PlaybackV2Controller|',message)+60 , length(message)-1)\"))\n",
    "#\n",
    "# val regexTokenizer = new RegexTokenizer().setInputCol(\"messagecut\").setOutputCol(\"words\").setPattern(\"\\\\w+|\").setGaps(false)\n",
    "#\n",
    "regexTokenizer = RegexTokenizer(minTokenLength=1, gaps=False, pattern='\\\\w+|', inputCol=\"messagecut\", outputCol=\"words\", toLowercase=True)\n",
    "#\n",
    "tokenized = regexTokenizer.transform(df4)\n",
    "tokenized.printSchema()\n",
    "tokenized.coalesce(1).write.json(output_file2)\n",
    "# Tokenize NON-Fraud-LABEL\n",
    "# hash the message de-duplicate those records\n",
    "notfraud_file=sqlContext.read.json(input_file3)\n",
    "notfraud_file.printSchema()\n",
    "#\n",
    "notfraud_df=notfraud_file\\\n",
    ".filter(\"message IS NOT NULL\").filter(\"words IS NOT NULL\")\\\n",
    ".withColumn('fraud_label',lit(0).cast('int'))\\\n",
    ".withColumn('hash_message',F.sha2(col('message'),512)).groupby(col('hash_message'))\\\n",
    ".agg(F.first(col('fraud_label')).alias('fraud_label'),F.first(col('words')).alias('words'),F.first(col('message')).alias('message'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "notfraud_df.printSchema()\n",
    "#\n",
    "df_notfraud_words = notfraud_df.filter(\"message IS NOT NULL\").select(col('fraud_label'),col('hash_message'),col('words'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "df_notfraud_words.printSchema()\n",
    "#\n",
    "# FILTER FRAUD AND LABEL \n",
    "# Join with Internal Curation Data in urltopredict staged folder\n",
    "# hash the message de-duplicate those records\n",
    "fraud_file=sqlContext.read.json(input_file1_playback_fraud)\n",
    "fraud_file.printSchema()\n",
    "#\n",
    "fraud_df=fraud_file\\\n",
    ".filter(\"message IS NOT NULL\").filter(\"words IS NOT NULL\")\\\n",
    ".withColumn('fraud_label',lit(1).cast('int'))\\\n",
    ".withColumn('hash_message',F.sha2(col('message'),512)).groupby(col('hash_message'))\\\n",
    ".agg(F.first(col('fraud_label')).alias('fraud_label'),F.first(col('words')).alias('words'),F.first(col('message')).alias('message'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "fraud_df.printSchema()\n",
    "#\n",
    "df_words = fraud_df.filter(\"message IS NOT NULL\").select(col('fraud_label'),col('hash_message'),col('words'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "df_words.printSchema()\n",
    "#\n",
    "result_fraud_nofraud_words = df_words.union(df_notfraud_words)\n",
    "## Register Generic Functions\n",
    "# -----------------------------------------------------------------------------\n",
    "# Build ngrams 75 90 n=6 \n",
    "# support : https://stackoverflow.com/questions/51473703/pyspark-ml-ngrams-countvectorizer-sorted-based-on-count-weights\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_ngrams_part(inputCol=\"words\", n=6):\n",
    "    ngrams = [ \n",
    "        NGram(n=i, inputCol=\"words\", outputCol=\"ngrams_{0}\".format(i)) \n",
    "        for i in range(7, n + 1) ]\n",
    "    vectorizers = [ \n",
    "        CountVectorizer(inputCol=\"ngrams_{0}\".format(i), outputCol=\"ngramscounts_{0}\".format(i)) \n",
    "        for i in range(7, n + 1) ]\n",
    "    return Pipeline(stages=ngrams + vectorizers)\n",
    "#    assembler = [VectorAssembler( inputCols=[\"ngramscounts_{0}\".format(i) for i in range(1, n + 1)], outputCol=\"features\" )]\n",
    "#    return Pipeline(stages=ngrams + DenseVector(SparseVector(vectorizers).toArray()))\n",
    "#\n",
    "# \n",
    "# -----------------------------------------------------------------------------\n",
    "#ngram = build_ngrams_part().fit(df_words)\n",
    "#ngramDataFrame = ngram.transform(df_words)\n",
    "#ngramDataFrame.coalesce(1).write.json(output_file1)\n",
    "#\n",
    "ngram = NGram(n=7, inputCol=\"words\", outputCol=\"ngrams_7\")\n",
    "countvector = CountVectorizer(inputCol=\"ngrams_7\", outputCol=\"ngramscounts_7\")\n",
    "# fit a CountVectorizerModel from the corpus.\n",
    "countvModel = CountVectorizer(inputCol=\"words\", outputCol=\"features_85\", vocabSize=85, minDF=2.0)\n",
    "# fit a PCA Dimensionality reduction into 85/7=12.x components from ngramscounts_7 ## Too Heavy 1st PCA\n",
    "pcaNgrams = PCA(k=5, inputCol=\"ngramscounts_7\", outputCol=\"pcaweightngrams\")\n",
    "# fit a PCA Dimensionality reduction into 85/7=12.x components from words\n",
    "pcaWords = PCA(k=5, inputCol=\"features_85\", outputCol=\"pcaweightwords\")  ## Too Heavy 2nd PCA\n",
    "#\n",
    "ngram_fraud_DF = ngram.transform(result_fraud_nofraud_words)\n",
    "ngram_vc_fraud_DF = countvector.fit(ngram_fraud_DF).transform(ngram_fraud_DF)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "ngram_vc_fraud_DF.printSchema()\n",
    "#\n",
    "#modelPCA_ngram_fraud_DF = pcaNgrams.fit(ngram_vc_fraud_DF).transform(ngram_vc_fraud_DF)\\\n",
    "#.persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "#modelPCA_ngram_fraud_DF.printSchema()\n",
    "#\n",
    "#result_ngrams_words_fraud_DF = countvModel.fit(modelPCA_ngram_fraud_DF).transform(modelPCA_ngram_fraud_DF)\\\n",
    "result_ngrams_words_fraud_DF = countvModel.fit(ngram_vc_fraud_DF).transform(ngram_vc_fraud_DF)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "result_ngrams_words_fraud_DF.printSchema()\n",
    "#\n",
    "result_ngrams_words_fraud_DF.coalesce(1).write.json(output_file1)\n",
    "#\n",
    "#  CALCULATE KL,KS COEF. Label Data\n",
    "ngram7_fraud=sqlContext.read.json(input_file4).filter(\"fraud_label=0\" )\n",
    "ngram7_fraud.printSchema()\n",
    "#\n",
    "print(\"Calculation of standard_fraud_ngram - Start!\")\n",
    "#\n",
    "# Obtain the most frequent word on each position \n",
    "# Compose the standard_fraud_ngram from the most common positions\n",
    "# Calculate the standard_fraud_ngram\n",
    "#\n",
    "# https://stackoverflow.com/questions/35218882/find-maximum-row-per-group-in-spark-dataframe \n",
    "# Using struct ordering:\n",
    "#from pyspark.sql.functions import struct\n",
    "#\n",
    "#(cnts\n",
    "#  .groupBy(\"id_sa\")\n",
    "#  .agg(F.max(struct(col(\"cnt\"), col(\"id_sb\"))).alias(\"max\"))\n",
    "#  .select(col(\"id_sa\"), col(\"max.id_sb\")))\n",
    "#\n",
    "#Py4JJavaError: An error occurred while calling o3400.select.\n",
    "#: org.apache.spark.sql.AnalysisException: cannot resolve '`ngrams`' given input columns: [mostfrequent];;\n",
    "#'Project ['ngrams, mostfrequent#8033.count AS count#8037L]\n",
    "#+- AnalysisBarrier\n",
    "#      +- Aggregate [max(named_struct(count, count#8029L)) AS mostfrequent#8033]\n",
    "#         +- Aggregate [ngrams#8016], [ngrams#8016, count(1) AS count#8029L]\n",
    "#            +- Relation[fraud_label#8013L,hash_message#8014,message#8075,ngrams#8016,words#8017] json\n",
    "#\n",
    "####### OLD  ######\n",
    "#.groupby(col('hash_message'))\\\n",
    "#.agg(F.first(col('features_75')).alias('features_75'),\\\n",
    "#     F.first(col('fraud_label')).alias('fraud_label'),\\\n",
    "#     F.first(col('ngrams_75')).alias('ngrams_75'),\\\n",
    "#     F.first(col('ngramscounts_75')).alias('ngramscounts_75'),F.first(col('words')).alias('words'))\n",
    "####################\n",
    "#\n",
    "most_frequent_df=ngram7_fraud\\\n",
    ".withColumn(\"value_sum\",F.explode(\"ngramscounts_7.values\"))\\\n",
    ".groupBy(\"hash_message\").agg(F.sum(\"value_sum\").alias('count'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "most_frequent_df.printSchema()\n",
    "#\n",
    "most_frequent_df.coalesce(1).write.json(output_most_frequent_df)\n",
    "#\n",
    "# The most Frequent would the the max\n",
    "standard_fraud_ngram=most_frequent_df.orderBy(col('count').desc()).select(col('hash_message')).limit(1).toPandas()\n",
    "#\n",
    "print(\"Value Print: standard_fraud_ngram=\")\n",
    "print(standard_fraud_ngram)\n",
    "#\n",
    "print(\"Calculation of standard_fraud_ngram - Done!\")\n",
    "#\n",
    "sc.stop()\n",
    "#\n",
    "print(\"Preparation of Data Done!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value UDF : standard_fraud_ngram=\n",
      "0d3f40b98f94ffdc7b9f2037b9ec57c791a2213029d1fc972cc615226de2169cfc268480d4d8cb92d61590f7bb86f06180c7120121ab20312200e80328c3ff08\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_7: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_7: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_7: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_7: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- fraud_master_hash: string (nullable = false)\n",
      "\n",
      "Value UDF : standard_words=\n",
      "0d3f40b98f94ffdc7b9f2037b9ec57c791a2213029d1fc972cc615226de2169cfc268480d4d8cb92d61590f7bb86f06180c7120121ab20312200e80328c3ff08\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_7: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_7: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngramscounts_7: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words_conc: string (nullable = false)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- entropy_words: double (nullable = true)\n",
      "\n",
      "Model Data KL,KS, Entropy Done! NGrams Vectors Data Done!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "#\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "#\n",
    "#import org.apache.spark.ml.feature.NGram\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from collections import Counter\n",
    "#\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from pyspark.ml.feature import NGram, CountVectorizer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "#\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "#\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "#\n",
    "#  FILTER with PySpark SQL Functions F.\n",
    "from pyspark.sql import functions as F\n",
    "# FUNCTIONS\n",
    "# \n",
    "##\n",
    "## Register Generic UDF Functions\n",
    "# -----------------------------------------------------------------------------\n",
    "# KL : Kullback-Leibler Divergence\n",
    "# KS : Kolmogorov-Smirnov ( Sample sizes can be different)\n",
    "# -----------------------------------------------------------------------------    \n",
    "## NGRAM hash_mesage KL from URL TO Default NGRAM KL\n",
    "def func_kl_ngram_msg(var1,var_match):\n",
    "    ##Making sure the analysis of has_message SHA_512 is linear.\n",
    "    ##Making sure the analysis is over the words list on same size\n",
    "    def KL(P,Q):\n",
    "        epsilon = 0.00001\n",
    "        P = P+epsilon\n",
    "        Q = Q+epsilon\n",
    "        divergence = np.sum(P*np.log(P/Q))\n",
    "        return np.asscalar(divergence)\n",
    "    ##Making sure the analysis ignore trash\n",
    "    cleanvar=var1.strip('http://').strip('https://').strip('www.')\n",
    "    len_var1=len(cleanvar)\n",
    "    idx_var1=cleanvar[:4]# Use \"root1\" as baseline #cleanvar.split(\"/\")[0]#cleanvar[:8]\n",
    "    list_values1 = list(cleanvar)\n",
    "    list_of_ord_values1 = [ord(char) for char in list_values1]\n",
    "    values1 = np.asarray(list_of_ord_values1)\n",
    "    # URLS with at least 4166 characters\n",
    "    ## TODO : Complete this list with common Malware/phishing sites used in internal webtraffic\n",
    "    list_values2 = var_match\n",
    "    list_values2 += var_match\n",
    "    ## Making sure the analysis start on the same webdomain name\n",
    "    idx_var2 = list_values2.find(idx_var1)\n",
    "    start_values2 = list_values2[idx_var2:(idx_var2+len_var1)]\n",
    "    list_values2 = list(start_values2+list_values2)\n",
    "    list_values2 = list_values2[:len_var1]\n",
    "    list_of_ord_values2 = [ord(char) for char in list_values2]\n",
    "    values2 = np.asarray(list_of_ord_values2)\n",
    "    return KL(values1,values2)\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "## NGRAM hash_message \"Kolmogorov-Smirnov test KS pvalue= ks_2samp function8.\n",
    "def func_ks_ngram_msg(var1,var_match):\n",
    "    ##Making sure the analysis of has_message SHA_512 is linear.\n",
    "    ##Making sure the analysis is over the words list on same size\n",
    "    cleanvar=var1.strip('http://').strip('https://').strip('www.')\n",
    "    len_var1=len(cleanvar)\n",
    "    idx_var1=cleanvar[:4]# Use \"root1\" as baseline #cleanvar.split(\"/\")[0]#cleanvar[:8]\n",
    "    list_values1 = list(cleanvar)\n",
    "    list_of_ord_values1 = [ord(char) for char in list_values1]\n",
    "    values1 = np.asarray(list_of_ord_values1)\n",
    "    values1= np.sort(values1)\n",
    "    # URLS with up to least 4166 characters\n",
    "    list_values2 = var_match\n",
    "    list_values2 += var_match\n",
    "    ## Making sure the analysis start on the same messgae\n",
    "    idx_var2 = list_values2.find(idx_var1)\n",
    "    start_values2 = list_values2[idx_var2:(idx_var2+len_var1)]\n",
    "    list_values2 = list(start_values2+list_values2)\n",
    "    list_values2 = list_values2[:len_var1]\n",
    "    list_of_ord_values2 = [ord(char) for char in list_values2]\n",
    "    values2 = np.asarray(list_of_ord_values2)\n",
    "    values2=np.sort(values2)\n",
    "    (Darray,pvalue)=stats.ks_2samp(values1, values2)\n",
    "    return np.asscalar(pvalue)\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "## Entropy TO hash_message function3.\n",
    "def func_entropy_ngram_msg(var1,var_match):\n",
    "    ##Making sure the analysis of has_message SHA_512 is linear.\n",
    "    ##Making sure the analysis is over the words list ignore size\n",
    "    #\n",
    "    cleanvar=var1.strip('http://').strip('https://').strip('www.')\n",
    "    len_var1=len(cleanvar)\n",
    "    idx_var1=cleanvar[:4]# Use \"root1\" as baseline #cleanvar.split(\"/\")[0]#cleanvar[:8]\n",
    "    list_values1 = list(cleanvar)\n",
    "    list_of_ord_values1 = [ord(char) for char in list_values1]\n",
    "    values1 = np.asarray(list_of_ord_values1)\n",
    "    # URLS with at least 4166 characters\n",
    "    ## TODO : Complete this list with an NGRAM search\n",
    "    list_values2 = var_match\n",
    "    list_values2 += var_match\n",
    "    ## Making sure the analysis start on point\n",
    "    idx_var2 = list_values2.find(idx_var1)\n",
    "    start_values2 = list_values2[idx_var2:(idx_var2+len_var1)]\n",
    "    list_values2 = list(start_values2+list_values2)\n",
    "    list_values2 = list_values2[:len_var1]\n",
    "    list_of_ord_values2 = [ord(char) for char in list_values2]\n",
    "    values2 = np.asarray(list_of_ord_values2)\n",
    "    pvalue=stats.entropy(values1, values2)\n",
    "    scalar_pvalue=np.asscalar(pvalue)\n",
    "    return scalar_pvalue\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "func_kl_ngram_msg_udf = udf(func_kl_ngram_msg, FloatType())\n",
    "func_ks_ngram_msg_udf = udf(func_ks_ngram_msg, FloatType())\n",
    "func_entropy_ngram_msg_udf = udf(func_entropy_ngram_msg, FloatType())\n",
    "#\n",
    "# Arguments\n",
    "#\n",
    "import argparse\n",
    "## Parse date_of execution\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"--datev1\", help=\"Execution Date\")\n",
    "#args = parser.parse_args()\n",
    "#if args.datev1:\n",
    "#    processdate = args.datev1\n",
    "# GENERAL PREPARATION SCRIPT\n",
    "#\n",
    "#  Date in format YYYYMMDD\n",
    "#process_date = processdate\n",
    "#if not process_date:\n",
    "#    process_date = \"20181231\"\n",
    "#\n",
    "process_date=\"20190122\"\n",
    "#\n",
    "#\n",
    "sc = pyspark.SparkContext()\n",
    "#conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','2047mb'),('spark.driver.memory','23g'),('spark.driver.maxResultSize','21g')])\n",
    "conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','512mb')])\n",
    "sc.stop()\n",
    "sc.stop()\n",
    "sc = pyspark.SparkContext(conf=conf,appName=\"Notebook-FraudCanada-Model-NGrams-CountVectorizer-KL-KS-Entropy-Model-Labeling\")\n",
    "sqlContext = SQLContext(sc)\n",
    "#\n",
    "#\n",
    "input_most_frequent_df=\"hdfs:///data/staged/ott_dazn/advanced-model-data/the-most-frequent-fraud-hash_message/dt=\"+process_date\n",
    "input_fraud=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-7-features-85/dt=\"+process_date\n",
    "#\n",
    "input_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-7-features-85/dt=\"+process_date\n",
    "output_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/label-fraud-notfraud-data-model/dt=\"+process_date\n",
    "preserve_training_output_file=\"hdfs:///data/staged/ott_dazn/advanced-model-data/preserve-training-output-automl-clean/dt=\"+process_date\n",
    "#\n",
    "# The most Frequent would the ones with the max frequency of NGrams85 tokens\n",
    "pd.options.display.max_colwidth = 512\n",
    "#\n",
    "standard_fraud_ngram=sqlContext.read.json(input_most_frequent_df)\\\n",
    ".orderBy(col('count').desc()).select(col('hash_message')).limit(1).toPandas()['hash_message'][0]\n",
    "print(\"Value UDF : standard_fraud_ngram=\")\n",
    "print(standard_fraud_ngram)\n",
    "#\n",
    "# Select Tokens/words form the max frequency of NGrams85 tokens hash_message\n",
    "standard_fraud_ngram_words=sqlContext.read.json(input_fraud)\n",
    "standard_fraud_ngram_words.printSchema()\n",
    "#\n",
    "standard_words_search=standard_fraud_ngram_words\\\n",
    ".withColumn('fraud_master_hash',lit(standard_fraud_ngram).cast('string'))\\\n",
    ".filter(\" hash_message=fraud_master_hash \")\n",
    "standard_words_search.printSchema()\n",
    "#\n",
    "standard_words=standard_words_search\\\n",
    ".withColumn('words_conc',F.concat_ws('',col('words')).cast('string'))\\\n",
    ".select(col('words_conc')).limit(1).toPandas()['words_conc'][0] \n",
    "# Working now! \n",
    "# Needs to be bigger than message twice should be tested!\n",
    "#   Py4JJavaError: An error occurred while calling z:org.apache.spark.sql.functions.lit.\n",
    "#      : java.lang.RuntimeException: Unsupported literal type class java.util.HashMap \n",
    "# {0=root15c466c8e6e8f9d17adb73426cd55c70f72b9f18e39e3455c9043a18b86b122b6requestmethodgeturlhttpsislcadazncommislv2playbackassetidfg5oon8sl71n1nfwuegbo8npgeventidarticleidfg5oon8sl71n1nfwuegbo8npgformatmpegdashplayeriddaznf3874e050812a853securetruelanguagecodeenlatitudenulllongitudenullplatformandroidtvmanufacturernvidiamodelnullmtalanguagecodeenclientip50100225179headersuseragentmozilla50linuxandroid800shieldandroidtvbuildopr6170623010wvapplewebkit53736khtmllikegeckoversion40chrome710357899mobilesafari53736fev1420typeinresponsestatuscode200reasonphraseokduration47jwtvieweridc2ebc25d8085deviceid993bf365c72c4b0b9168c2ebc25d8085f3874e050812a853userstatusactivepaid}\n",
    "#\n",
    "print(\"Value UDF : standard_words=\")\n",
    "print(standard_fraud_ngram)\n",
    "#\n",
    "ngram7_fraud=sqlContext.read.json(input_file1)\n",
    "ngram7_fraud.printSchema()\n",
    "#\n",
    "drop_phish_cols=['words','ngrams_7']\n",
    "#\n",
    "fraud_label_read_df=ngram7_fraud.filter(\"hash_message is not NULL\")\\\n",
    ".withColumn('words_conc',F.concat_ws('',col('words')).cast('string'))\\\n",
    "    .drop(*drop_phish_cols)\\\n",
    "    .withColumn('kl_words',func_kl_ngram_msg_udf(col('words_conc'),lit(standard_words).cast('string')).cast('double'))\\\n",
    "    .withColumn('ks_words',func_ks_ngram_msg_udf(col('words_conc'),lit(standard_words).cast('string')).cast('double'))\\\n",
    "    .withColumn('entropy_words',func_entropy_ngram_msg_udf(col('words_conc'),lit(standard_words).cast('string')).cast('double'))\\\n",
    "    .persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "fraud_label_read_df.printSchema()\n",
    "#\n",
    "fraud_label_read_df.coalesce(1).write.json(output_file1)\n",
    "#\n",
    "fraud_label_read_df.unpersist()\n",
    "#\n",
    "sc.stop()\n",
    "#\n",
    "print(\"Model Data KL,KS, Entropy Done! NGrams Vectors Data Done!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>7 days 23 hours 18 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.1</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>3 months and 4 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_siemanalyst_f03p4d</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>4.732 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.4 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         7 days 23 hours 18 mins\n",
       "H2O cluster timezone:       UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.1\n",
       "H2O cluster version age:    3 months and 4 days\n",
       "H2O cluster name:           H2O_from_python_siemanalyst_f03p4d\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    4.732 Gb\n",
       "H2O cluster total cores:    12\n",
       "H2O cluster allowed cores:  12\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.4 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training Model NGrams Vectors KS KL Entropty\n",
      "root\n",
      " |-- entropy_words: double (nullable = true)\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- ngramscounts_7: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words_conc: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- entropy_words: double (nullable = true)\n",
      " |-- features85_type: long (nullable = true)\n",
      " |-- features85_size: long (nullable = true)\n",
      " |-- features85_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- features85_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- ngramscounts7_type: long (nullable = true)\n",
      " |-- ngramscounts7_size: long (nullable = true)\n",
      " |-- ngramscounts7_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- ngramscounts7_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- entropy_words: double (nullable = true)\n",
      " |-- features85_type: long (nullable = true)\n",
      " |-- features85_size: long (nullable = true)\n",
      " |-- features85_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- features85_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- ngramscounts7_type: long (nullable = true)\n",
      " |-- ngramscounts7_size: long (nullable = true)\n",
      " |-- ngramscounts7_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- ngramscounts7_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- entropy_words: double (nullable = true)\n",
      " |-- features85_type: long (nullable = true)\n",
      " |-- features85_size: long (nullable = true)\n",
      " |-- features85_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- features85_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- ngramscounts7_type: long (nullable = true)\n",
      " |-- ngramscounts7_size: long (nullable = true)\n",
      " |-- ngramscounts7_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- ngramscounts7_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>hash_message                                                                                                                    </th><th style=\"text-align: right;\">  fraud_label</th><th style=\"text-align: right;\">  kl_words</th><th style=\"text-align: right;\">  ks_words</th><th style=\"text-align: right;\">  entropy_words</th><th style=\"text-align: right;\">  features85_type</th><th style=\"text-align: right;\">  features85_size</th><th style=\"text-align: right;\">  ngramscounts7_type</th><th style=\"text-align: right;\">  ngramscounts7_size</th><th>features85_list_indices  </th><th>features85_list_values  </th><th>ngramscounts7_list_indices  </th><th>ngramscounts7_list_values  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>589ff83a30fa5d82563f0051bbd9f638d3dc7f102f8c78ab137c17b859e740de35348417e0deb2037cd0188c243c674100eb57f97450c4b942c9d3a1ef86a07b</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   5121.78</td><td style=\"text-align: right;\">  0.386449</td><td style=\"text-align: right;\">      0.0775856</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    251    252    253\n",
       "    271    272    312    313    365    366    367    368    369    370\n",
       "    372    373    374    375    376    421    422    423    424    425\n",
       "    426    427    428    532   1571   1572   1573   2191  11120  32829\n",
       "  35576  37068  51952 119101 129064 152122 153250 164794 175213 183033\n",
       " 186242 201741 224421 238588 259672]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>865fc00f8a94dd1c467c39753bfb2b18626f2827db85a05654caf048e657b6856afad3fef87873197e7f92e0ff760c8f04cd5484c910a037476643addfdb5c31</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   3572.81</td><td style=\"text-align: right;\">  0.999849</td><td style=\"text-align: right;\">      0.067809 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    118    119    120    177    178    179    180    181    182    204\n",
       "    271    272    312    313    365    366    367    368    369    370\n",
       "    372    373    374    375    376    421    422    423    424    425\n",
       "    426    427    428   1861   2230   2233   2234   2235   2243   2244\n",
       "   3891   7550   7571   7600   7674  14441  67052  83797 152373 155708\n",
       " 158659 159474 175973 183005 184980 186211 187030 188782 196015 199169\n",
       " 199626 200056]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>a659ae2c8efbde6eb990b90acae3e02f644e44cd1a3a9aa6490632209641eb5714bb4b740ddcbe95e50b5cd319a8725634ffea38ae633fd6ab1f7114ad8c17bd</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4872.41</td><td style=\"text-align: right;\">  0.629505</td><td style=\"text-align: right;\">      0.0770424</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   2210   2212   2213   2766   3349  12663  12732  13137  35371  40445\n",
       "  63248 160374 163934 167319 170979 176627 185968 187302 207482 215154\n",
       " 242580 254804]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>d6d7bcd45dfa2fb6487352a532359f3f64afe250dacb422898ed9854af8992866bff17dac83f36763b46f2db2e0442fdf23fafdd58628636ca3395b6ef019a16</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4971.4 </td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.0765636</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   1409   1411   1413   2218   7166  10778  10969  10974  15342  28341\n",
       "  29276  66279  66595  68252  78062 111684 113098 113516 119462 121057\n",
       " 125868 129046 130194 137990 150551 150859]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>da23c7d6b5dd13228bb9b8e5d3287463ca7b12fbc8a5c068ce2cf4ca3e7e89ca6990a4abfc69dcedd538ee916f64a8d5d0440d1ad309c9604efc9ad4074a81ed</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4871.22</td><td style=\"text-align: right;\">  0.784173</td><td style=\"text-align: right;\">      0.0793658</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    118    119    120    177    178    179    180    181    182    204\n",
       "    234    271    272    312    313    365    366    367    368    369\n",
       "    370    372    373    374    375    376    421    422    423    424\n",
       "    425    426    427    428   3042   3046   3077   3084   7166   8059\n",
       "   8094   8370  16914  17771  25245  25350  25471  26079  26856  27476\n",
       "  27506  89583  90454  93388  96240  97551  97803  99368 104348]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>980071f323752c9f7e987d2f657d244851b601c46ef50b2cd053d69ee9c3a7b413730fff5a68bea2dd9ada49d410f0c0f8165ad2a9096c2c419668df2b829de3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4761.19</td><td style=\"text-align: right;\">  0.679739</td><td style=\"text-align: right;\">      0.0770313</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 38 39 40 41 42 43 44 45 46 47 48\n",
       " 49 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "    588    589    590    990   1571   1572   1573   1813   3385  54750\n",
       "  63934 108396 134505 150356 156504 160046 164074 172543 184330 185036\n",
       " 203108 204988 207776 219974 224760 227729 251427]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>e38e2712270ef1f79716537aa2816eaab104a20e17c94df57b49b787cda6f8e96794acf70b302c9708e9573dda18e402c7e996ea14e537e736001b12070d7542</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4871.09</td><td style=\"text-align: right;\">  0.679739</td><td style=\"text-align: right;\">      0.0751454</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   1464   1468   1470   2377   3698   4191   4201   4216   7993  29538\n",
       "  31603 108794 110094 120213 133311 134383 136510 145291 149087 151081\n",
       " 154755 171878 173525 178505 181503 184913 189087 196194 202237]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>26f328150124298822fc4a0be849251c3d3545dcb2495c71dc92a60d1629ea641ec4d24c7004a3d579df61f5ba7197ffe6e88e3efaee93d226270372ee87d4b2</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4980.78</td><td style=\"text-align: right;\">  0.52636 </td><td style=\"text-align: right;\">      0.0788552</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    118    119    120    177    178    179    180    181    182    204\n",
       "    234    271    272    312    313    365    366    367    368    369\n",
       "    370    372    373    374    375    376    421    422    423    424\n",
       "    425    426    427    428   1409   1411   1413   1813   2364   4990\n",
       "   5008   5010  24711  24781  25711  25882  26069  26190  26285  26724\n",
       "  48517  72318 231749 232265 238880 242356]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>2b8a2419e7f2c6fecb549146c3d66ab9cae9839005d8f848d39313e49b34d22c18c6eb7e20b3b0c5291d4ad0f7f2b329423816423f62a40a7dae70870c2b7f9f</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4909.64</td><td style=\"text-align: right;\">  0.734024</td><td style=\"text-align: right;\">      0.0785097</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   1464   1468   1470   2779   4191   4201   4216   7993  32826  35408\n",
       "  51952 110395 114044 118743 118935 129694 140512 150098 181503 184913\n",
       " 202237 229194]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>67d469882a190b2d6262a34bcca389d43799a46e823c51da3c685150a32c5779132915cfd6cc965db7d7f92639dd725dad1e29d2f69598d63cdf1402d2fa66b3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   5203.28</td><td style=\"text-align: right;\">  0.682076</td><td style=\"text-align: right;\">      0.0799091</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   1409   1411   1413   1593   3716   3726   3731   6099  11019  28962\n",
       "  34089  34164  35450  35825  36555  36821  37443  39297  43061  87723\n",
       "  90758  91916  93784  97570 102154 106550 213589 221225]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>hash_message                                                                                                                    </th><th style=\"text-align: right;\">  fraud_label</th><th style=\"text-align: right;\">  kl_words</th><th style=\"text-align: right;\">  ks_words</th><th style=\"text-align: right;\">  entropy_words</th><th style=\"text-align: right;\">  features85_type</th><th style=\"text-align: right;\">  features85_size</th><th style=\"text-align: right;\">  ngramscounts7_type</th><th style=\"text-align: right;\">  ngramscounts7_size</th><th>features85_list_indices  </th><th>features85_list_values  </th><th>ngramscounts7_list_indices  </th><th>ngramscounts7_list_values  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>589ff83a30fa5d82563f0051bbd9f638d3dc7f102f8c78ab137c17b859e740de35348417e0deb2037cd0188c243c674100eb57f97450c4b942c9d3a1ef86a07b</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   5121.78</td><td style=\"text-align: right;\">  0.386449</td><td style=\"text-align: right;\">      0.0775856</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    251    252    253\n",
       "    271    272    312    313    365    366    367    368    369    370\n",
       "    372    373    374    375    376    421    422    423    424    425\n",
       "    426    427    428    532   1571   1572   1573   2191  11120  32829\n",
       "  35576  37068  51952 119101 129064 152122 153250 164794 175213 183033\n",
       " 186242 201741 224421 238588 259672]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>865fc00f8a94dd1c467c39753bfb2b18626f2827db85a05654caf048e657b6856afad3fef87873197e7f92e0ff760c8f04cd5484c910a037476643addfdb5c31</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   3572.81</td><td style=\"text-align: right;\">  0.999849</td><td style=\"text-align: right;\">      0.067809 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    118    119    120    177    178    179    180    181    182    204\n",
       "    271    272    312    313    365    366    367    368    369    370\n",
       "    372    373    374    375    376    421    422    423    424    425\n",
       "    426    427    428   1861   2230   2233   2234   2235   2243   2244\n",
       "   3891   7550   7571   7600   7674  14441  67052  83797 152373 155708\n",
       " 158659 159474 175973 183005 184980 186211 187030 188782 196015 199169\n",
       " 199626 200056]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>a659ae2c8efbde6eb990b90acae3e02f644e44cd1a3a9aa6490632209641eb5714bb4b740ddcbe95e50b5cd319a8725634ffea38ae633fd6ab1f7114ad8c17bd</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4872.41</td><td style=\"text-align: right;\">  0.629505</td><td style=\"text-align: right;\">      0.0770424</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   2210   2212   2213   2766   3349  12663  12732  13137  35371  40445\n",
       "  63248 160374 163934 167319 170979 176627 185968 187302 207482 215154\n",
       " 242580 254804]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>d6d7bcd45dfa2fb6487352a532359f3f64afe250dacb422898ed9854af8992866bff17dac83f36763b46f2db2e0442fdf23fafdd58628636ca3395b6ef019a16</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4971.4 </td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.0765636</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   1409   1411   1413   2218   7166  10778  10969  10974  15342  28341\n",
       "  29276  66279  66595  68252  78062 111684 113098 113516 119462 121057\n",
       " 125868 129046 130194 137990 150551 150859]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>da23c7d6b5dd13228bb9b8e5d3287463ca7b12fbc8a5c068ce2cf4ca3e7e89ca6990a4abfc69dcedd538ee916f64a8d5d0440d1ad309c9604efc9ad4074a81ed</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4871.22</td><td style=\"text-align: right;\">  0.784173</td><td style=\"text-align: right;\">      0.0793658</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    118    119    120    177    178    179    180    181    182    204\n",
       "    234    271    272    312    313    365    366    367    368    369\n",
       "    370    372    373    374    375    376    421    422    423    424\n",
       "    425    426    427    428   3042   3046   3077   3084   7166   8059\n",
       "   8094   8370  16914  17771  25245  25350  25471  26079  26856  27476\n",
       "  27506  89583  90454  93388  96240  97551  97803  99368 104348]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>980071f323752c9f7e987d2f657d244851b601c46ef50b2cd053d69ee9c3a7b413730fff5a68bea2dd9ada49d410f0c0f8165ad2a9096c2c419668df2b829de3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4761.19</td><td style=\"text-align: right;\">  0.679739</td><td style=\"text-align: right;\">      0.0770313</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 38 39 40 41 42 43 44 45 46 47 48\n",
       " 49 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "    588    589    590    990   1571   1572   1573   1813   3385  54750\n",
       "  63934 108396 134505 150356 156504 160046 164074 172543 184330 185036\n",
       " 203108 204988 207776 219974 224760 227729 251427]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>e38e2712270ef1f79716537aa2816eaab104a20e17c94df57b49b787cda6f8e96794acf70b302c9708e9573dda18e402c7e996ea14e537e736001b12070d7542</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4871.09</td><td style=\"text-align: right;\">  0.679739</td><td style=\"text-align: right;\">      0.0751454</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   1464   1468   1470   2377   3698   4191   4201   4216   7993  29538\n",
       "  31603 108794 110094 120213 133311 134383 136510 145291 149087 151081\n",
       " 154755 171878 173525 178505 181503 184913 189087 196194 202237]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>26f328150124298822fc4a0be849251c3d3545dcb2495c71dc92a60d1629ea641ec4d24c7004a3d579df61f5ba7197ffe6e88e3efaee93d226270372ee87d4b2</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4980.78</td><td style=\"text-align: right;\">  0.52636 </td><td style=\"text-align: right;\">      0.0788552</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    118    119    120    177    178    179    180    181    182    204\n",
       "    234    271    272    312    313    365    366    367    368    369\n",
       "    370    372    373    374    375    376    421    422    423    424\n",
       "    425    426    427    428   1409   1411   1413   1813   2364   4990\n",
       "   5008   5010  24711  24781  25711  25882  26069  26190  26285  26724\n",
       "  48517  72318 231749 232265 238880 242356]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>2b8a2419e7f2c6fecb549146c3d66ab9cae9839005d8f848d39313e49b34d22c18c6eb7e20b3b0c5291d4ad0f7f2b329423816423f62a40a7dae70870c2b7f9f</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4909.64</td><td style=\"text-align: right;\">  0.734024</td><td style=\"text-align: right;\">      0.0785097</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   1464   1468   1470   2779   4191   4201   4216   7993  32826  35408\n",
       "  51952 110395 114044 118743 118935 129694 140512 150098 181503 184913\n",
       " 202237 229194]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>67d469882a190b2d6262a34bcca389d43799a46e823c51da3c685150a32c5779132915cfd6cc965db7d7f92639dd725dad1e29d2f69598d63cdf1402d2fa66b3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   5203.28</td><td style=\"text-align: right;\">  0.682076</td><td style=\"text-align: right;\">      0.0799091</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   1409   1411   1413   1593   3716   3726   3731   6099  11019  28962\n",
       "  34089  34164  35450  35825  36555  36821  37443  39297  43061  87723\n",
       "  90758  91916  93784  97570 102154 106550 213589 221225]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preserve_training_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9336f41b1457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0maml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m \u001b[0mpreserve_training_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreserve_training_output_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AutoML Modeling Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preserve_training_output' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "#\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "#\n",
    "#import org.apache.spark.ml.feature.NGram\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from collections import Counter\n",
    "#\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from pyspark.ml.feature import NGram, CountVectorizer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "#\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "#\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "#\n",
    "#  FILTER with PySpark SQL Functions F.\n",
    "#\n",
    "# Arguments\n",
    "#\n",
    "import argparse\n",
    "## Parse date_of execution\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"--datev1\", help=\"Execution Date\")\n",
    "#args = parser.parse_args()\n",
    "#if args.datev1:\n",
    "#    processdate = args.datev1\n",
    "# GENERAL PREPARATION SCRIPT\n",
    "#\n",
    "#  Date in format YYYYMMDD\n",
    "#process_date = processdate\n",
    "#if not process_date:\n",
    "#    process_date = \"20181231\"\n",
    "#\n",
    "process_date=\"20190122\"\n",
    "#\n",
    "#\n",
    "sc = pyspark.SparkContext()\n",
    "#conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','2047mb'),('spark.driver.memory','23g'),('spark.driver.maxResultSize','21g')])\n",
    "conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','512mb'),('spark.driver.memory','16g'),('spark.driver.maxResultSize','12g')])\n",
    "sc.stop()\n",
    "sc.stop()\n",
    "sc = pyspark.SparkContext(conf=conf,appName=\"Notebook-FraudCanada-AUTOML-Model-NGrams-CountVectorizer-KL-KS-Entropy\")\n",
    "sqlContext = SQLContext(sc)\n",
    "#\n",
    "input_most_frequent_df=\"hdfs:///data/staged/ott_dazn/advanced-model-data/the-most-frequent-fraud-hash_message/dt=\"+process_date\n",
    "input_fraud=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-5-features-85/dt=\"+process_date\n",
    "#\n",
    "input_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-5-features-85/dt=\"+process_date\n",
    "output_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/label-fraud-notfraud-data-model/dt=\"+process_date\n",
    "preserve_training_input_file=\"hdfs:///data/staged/ott_dazn/advanced-model-data/preserve-training-output-automl-clean/dt=\"+process_date\n",
    "#\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "#\n",
    "import subprocess\n",
    "subprocess.run('unset http_proxy', shell=True)\n",
    "#\n",
    "# Start an H2O virtual cluster that uses 6 gigs of RAM and 6 cores\n",
    "h2o.init(ip=\"localhost\",port=54321,max_mem_size = \"6g\", nthreads = 6) \n",
    "#\n",
    "# Clean up the h2o cluster just in case\n",
    "h2o.remove_all()\n",
    "#\n",
    "#  TRAINING PROCESS\n",
    "#\n",
    "print(\"Start Training Model NGrams Vectors KS KL Entropty\")\n",
    "#\n",
    "# Horrible code :: close your eyes, is ugly\n",
    "#\n",
    "fraud_label_read_file=sqlContext.read.json(output_file1)\n",
    "fraud_label_read_file.printSchema()\n",
    "#\n",
    "fraud_label_read_df=fraud_label_read_file\\\n",
    ".select(col('hash_message').cast('string'),col('fraud_label').cast('int'),\\\n",
    "        col('kl_words').cast('double'), col('ks_words').cast('double'),col('entropy_words').cast('double'),\\\n",
    "        col('features_85.type').alias('features85_type').cast('long'),\\\n",
    "        col('features_85.size').alias('features85_size').cast('long'),\\\n",
    "        col('features_85.indices').alias('features85_indices'),\\\n",
    "        col('features_85.values').alias('features85_values'),\\\n",
    "        col('ngramscounts_7.type').alias('ngramscounts7_type').cast('long'),\\\n",
    "        col('ngramscounts_7.size').alias('ngramscounts7_size').cast('long'),\\\n",
    "        col('ngramscounts_7.indices').alias('ngramscounts7_indices'),\\\n",
    "        col('ngramscounts_7.values').alias('ngramscounts7_values'))\n",
    "fraud_label_read_df.printSchema()\n",
    "#\n",
    "# ABOVE ARE CASE ISSUES on struct Struct of features_85 and ngramscounts_7 \n",
    "# Both cares conversion to DF valide type list\n",
    "# Flat vars for each, individually and seperately from the original struct\n",
    "#\n",
    "# https://stackoverflow.com/questions/47401418/pyspark-conversion-to-array-types?rq=1 \n",
    "#\n",
    "#\n",
    "fraud_fraud_label_read1_df=fraud_label_read_df.filter(\"fraud_label=1\")\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "notfraud_fraud_label_read1_df=fraud_label_read_df.filter(\"fraud_label=0\")\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "#\n",
    "fraud_fraud_label_read1_df.printSchema()\n",
    "notfraud_fraud_label_read1_df.printSchema()\n",
    "#\n",
    "drop_list_cols=['features85_indices','features85_values','ngramscounts7_indices','ngramscounts7_values']\n",
    "#\n",
    "### 1.) https://stackoverflow.com/questions/38610559/convert-spark-dataframe-column-to-python-list\n",
    "###    list(spark_df.select('mvv').toPandas()['mvv'])\n",
    "### 2.) http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.assign.html\n",
    "###    df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,temp_k=lambda x: (x['temp_f'] +  459.67) * 5 / 9)\n",
    "### 3.) https://stackoverflow.com/questions/43216411/pandas-flatten-a-list-of-list-within-a-column\n",
    "###    df['var2'] = df['var2'].apply(np.ravel)\n",
    "fraud_label_train_pd=fraud_fraud_label_read1_df.limit(2500).toPandas()\\\n",
    ".assign(features85_list_indices=lambda x: x['features85_indices'].apply(np.ravel),\\\n",
    "        features85_list_values=lambda x: x['features85_values'].apply(np.ravel),\\\n",
    "        ngramscounts7_list_indices=lambda x: x['ngramscounts7_indices'].apply(np.ravel),\\\n",
    "        ngramscounts7_list_values=lambda x: x['ngramscounts7_values'].apply(np.ravel))\\\n",
    ".drop(drop_list_cols, axis=1, inplace=False)\n",
    "#.tail(1200)\n",
    "# dummy_dif=lambda x:list(x['fraud_label'])\n",
    "#\n",
    "fraud_label_test_pd=fraud_fraud_label_read1_df.limit(500).toPandas()\\\n",
    ".assign(features85_list_indices=lambda x: x['features85_indices'].apply(np.ravel),\\\n",
    "        features85_list_values=lambda x: x['features85_values'].apply(np.ravel),\\\n",
    "        ngramscounts7_list_indices=lambda x: x['ngramscounts7_indices'].apply(np.ravel),\\\n",
    "        ngramscounts7_list_values=lambda x: x['ngramscounts7_values'].apply(np.ravel))\\\n",
    ".drop(drop_list_cols, axis=1, inplace=False)\n",
    "#\n",
    "not_fraud_label_train_pd=notfraud_fraud_label_read1_df.limit(2500).toPandas()\\\n",
    ".assign(features85_list_indices=lambda x: x['features85_indices'].apply(np.ravel),\\\n",
    "        features85_list_values=lambda x: x['features85_values'].apply(np.ravel),\\\n",
    "        ngramscounts7_list_indices=lambda x: x['ngramscounts7_indices'].apply(np.ravel),\\\n",
    "        ngramscounts7_list_values=lambda x: x['ngramscounts7_values'].apply(np.ravel))\\\n",
    ".drop(drop_list_cols, axis=1, inplace=False)\n",
    "#.tail(3000)\n",
    "#\n",
    "not_fraud_label_test_pd=notfraud_fraud_label_read1_df.limit(500).toPandas()\\\n",
    ".assign(features85_list_indices=lambda x: x['features85_indices'].apply(np.ravel),\\\n",
    "        features85_list_values=lambda x: x['features85_values'].apply(np.ravel),\\\n",
    "        ngramscounts7_list_indices=lambda x: x['ngramscounts7_indices'].apply(np.ravel),\\\n",
    "        ngramscounts7_list_values=lambda x: x['ngramscounts7_values'].apply(np.ravel))\\\n",
    ".drop(drop_list_cols, axis=1, inplace=False)\n",
    "#.head(800)\n",
    "#\n",
    "not_fraud_label_train=h2o.H2OFrame(not_fraud_label_train_pd)\n",
    "not_fraud_label_test=h2o.H2OFrame(not_fraud_label_test_pd)\n",
    "#\n",
    "fraud_label_train=h2o.H2OFrame(fraud_label_train_pd)\n",
    "fraud_label_test=h2o.H2OFrame(fraud_label_test_pd)\n",
    "#\n",
    "################# Use Two DataFrames ##################### - rbind() H2o Frames issue\n",
    "#\n",
    "#\n",
    "###### TRAINING PROCESS ############\n",
    "# RBIND \"Merge\" all of vars internal subset of data with fraud and with not_fraud\n",
    "# function merge() doesn't work if both H2O/dataframes have same variables\n",
    "#\n",
    "train = fraud_label_train.rbind(not_fraud_label_train)\n",
    "test = fraud_label_test.rbind(not_fraud_label_test)\n",
    "#\n",
    "print(\"train\")\n",
    "print(train.head(10))\n",
    "print(\"test\")\n",
    "print(test.head(10))\n",
    "#\n",
    "# Identify predictors and response\n",
    "x = train.columns\n",
    "#\n",
    "# Fraud Label to be learned in the model from the atrributes of the ngram85 learned words\n",
    "#\n",
    "y= 'fraud_label'\n",
    "x.remove(y)\n",
    "#\n",
    "# For binary classification, response should be a factor\n",
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()\n",
    "#\n",
    "# http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html\n",
    "# Balance Classes to compensate unbalanced data\n",
    "# Run AutoML for 25 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=25, seed=19, exclude_algos=[\"DRF\",\"GLM\"])\n",
    "aml.train(x=x, y=y, training_frame=train)\n",
    "#\n",
    "preserve_training_output.write.json(preserve_training_output_file)\n",
    "#\n",
    "print(\"AutoML Modeling Done!\")\n",
    "#\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">   logloss</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">     rmse</th><th style=\"text-align: right;\">        mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_grid_1_AutoML_20190131_132458_model_3          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00125637</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.0175969</td><td style=\"text-align: right;\">0.00030965 </td></tr>\n",
       "<tr><td>GBM_5_AutoML_20190131_132458                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00296727</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.0226319</td><td style=\"text-align: right;\">0.000512201</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20190131_132458                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.0028804 </td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.0209347</td><td style=\"text-align: right;\">0.00043826 </td></tr>\n",
       "<tr><td>GBM_1_AutoML_20190131_132458                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00301976</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.0223972</td><td style=\"text-align: right;\">0.000501634</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190131_132458_model_2          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00292153</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.0230052</td><td style=\"text-align: right;\">0.00052924 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190131_132458_model_5      </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.0625543 </td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.137422 </td><td style=\"text-align: right;\">0.0188849  </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190131_132458_model_4          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00304807</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.024028 </td><td style=\"text-align: right;\">0.000577346</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20190131_132458</td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00202966</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.0166555</td><td style=\"text-align: right;\">0.000277405</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20190131_132458                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00316898</td><td style=\"text-align: right;\">           0.000220848</td><td style=\"text-align: right;\">0.022934 </td><td style=\"text-align: right;\">0.000525969</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20190131_132458                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00267538</td><td style=\"text-align: right;\">           0.000220848</td><td style=\"text-align: right;\">0.0186747</td><td style=\"text-align: right;\">0.000348745</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190131_132458_model_3      </td><td style=\"text-align: right;\">0.999996</td><td style=\"text-align: right;\">0.178583  </td><td style=\"text-align: right;\">           0.000377929</td><td style=\"text-align: right;\">0.240014 </td><td style=\"text-align: right;\">0.0576066  </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190131_132458_model_1      </td><td style=\"text-align: right;\">0.999995</td><td style=\"text-align: right;\">0.00209668</td><td style=\"text-align: right;\">           0.000377929</td><td style=\"text-align: right;\">0.0189632</td><td style=\"text-align: right;\">0.000359602</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190131_132458_model_3 </td><td style=\"text-align: right;\">0.999995</td><td style=\"text-align: right;\">0.00347676</td><td style=\"text-align: right;\">           0.000755858</td><td style=\"text-align: right;\">0.031266 </td><td style=\"text-align: right;\">0.000977565</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20190131_132458   </td><td style=\"text-align: right;\">0.999993</td><td style=\"text-align: right;\">0.00209997</td><td style=\"text-align: right;\">           0.000377929</td><td style=\"text-align: right;\">0.0175134</td><td style=\"text-align: right;\">0.000306718</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20190131_132458              </td><td style=\"text-align: right;\">0.999987</td><td style=\"text-align: right;\">0.0051017 </td><td style=\"text-align: right;\">           0.000819625</td><td style=\"text-align: right;\">0.0363686</td><td style=\"text-align: right;\">0.00132267 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190131_132458_model_2      </td><td style=\"text-align: right;\">0.999984</td><td style=\"text-align: right;\">0.00634859</td><td style=\"text-align: right;\">           0.00163925 </td><td style=\"text-align: right;\">0.0373709</td><td style=\"text-align: right;\">0.00139658 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190131_132458_model_4 </td><td style=\"text-align: right;\">0.999982</td><td style=\"text-align: right;\">0.00648671</td><td style=\"text-align: right;\">           0.00151172 </td><td style=\"text-align: right;\">0.041912 </td><td style=\"text-align: right;\">0.00175662 </td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_20190131_132458                   </td><td style=\"text-align: right;\">0.999977</td><td style=\"text-align: right;\">0.0121082 </td><td style=\"text-align: right;\">           0.00233134 </td><td style=\"text-align: right;\">0.0448421</td><td style=\"text-align: right;\">0.00201081 </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190131_132458_model_2 </td><td style=\"text-align: right;\">0.999972</td><td style=\"text-align: right;\">0.00523317</td><td style=\"text-align: right;\">           0.000377929</td><td style=\"text-align: right;\">0.0332354</td><td style=\"text-align: right;\">0.00110459 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190131_132458_model_6      </td><td style=\"text-align: right;\">0.999951</td><td style=\"text-align: right;\">0.0134683 </td><td style=\"text-align: right;\">           0.00239511 </td><td style=\"text-align: right;\">0.0498108</td><td style=\"text-align: right;\">0.00248112 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190131_132458_model_1          </td><td style=\"text-align: right;\">0.999924</td><td style=\"text-align: right;\">0.00562963</td><td style=\"text-align: right;\">           0.000377929</td><td style=\"text-align: right;\">0.0192264</td><td style=\"text-align: right;\">0.000369653</td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_20190131_132458                   </td><td style=\"text-align: right;\">0.999901</td><td style=\"text-align: right;\">0.0242537 </td><td style=\"text-align: right;\">           0.00378396 </td><td style=\"text-align: right;\">0.0673595</td><td style=\"text-align: right;\">0.0045373  </td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190131_132458_model_1 </td><td style=\"text-align: right;\">0.999682</td><td style=\"text-align: right;\">0.0163097 </td><td style=\"text-align: right;\">           0.00441229 </td><td style=\"text-align: right;\">0.0633615</td><td style=\"text-align: right;\">0.00401468 </td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_20190131_132458                   </td><td style=\"text-align: right;\">0.999605</td><td style=\"text-align: right;\">0.0430195 </td><td style=\"text-align: right;\">           0.00794586 </td><td style=\"text-align: right;\">0.0945305</td><td style=\"text-align: right;\">0.00893601 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190131_132458_model_4      </td><td style=\"text-align: right;\">0.999503</td><td style=\"text-align: right;\">0.0489763 </td><td style=\"text-align: right;\">           0.00927094 </td><td style=\"text-align: right;\">0.100567 </td><td style=\"text-align: right;\">0.0101136  </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190131_132458_model_7      </td><td style=\"text-align: right;\">0.837872</td><td style=\"text-align: right;\">0.461555  </td><td style=\"text-align: right;\">           0.201436   </td><td style=\"text-align: right;\">0.405453 </td><td style=\"text-align: right;\">0.164392   </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_grid_1_AutoML_20190131_132458_model_3\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 4.672689252681684e-18\n",
      "RMSE: 2.1616404078110873e-09\n",
      "LogLoss: 6.55074370626418e-10\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "pr_auc: 0.0007558578987150177\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9999999659099943: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>2264.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/2264.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>1323.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/1323.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>2264.0</td>\n",
       "<td>1323.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/3587.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ------------\n",
       "0      2264  0     0        (0.0/2264.0)\n",
       "1      0     1323  0        (0.0/1323.0)\n",
       "Total  2264  1323  0        (0.0/3587.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       1            1        1\n",
       "max f2                       1            1        1\n",
       "max f0point5                 1            1        1\n",
       "max accuracy                 1            1        1\n",
       "max precision                1            1        0\n",
       "max recall                   1            1        1\n",
       "max specificity              1            1        0\n",
       "max absolute_mcc             1            1        1\n",
       "max min_per_class_accuracy   1            1        1\n",
       "max mean_per_class_accuracy  1            1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 36.88 %, avg score: 36.88 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100362</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0272109</td>\n",
       "<td>0.0272109</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200725</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0272109</td>\n",
       "<td>0.0544218</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0301087</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0272109</td>\n",
       "<td>0.0816327</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0401450</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0272109</td>\n",
       "<td>0.1088435</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0501812</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0272109</td>\n",
       "<td>0.1360544</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000836</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1352986</td>\n",
       "<td>0.2713530</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1499861</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1352986</td>\n",
       "<td>0.4066515</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2001673</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1360544</td>\n",
       "<td>0.5427060</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999721</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.2705971</td>\n",
       "<td>0.8133031</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000558</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.8654089</td>\n",
       "<td>2.4996516</td>\n",
       "<td>0.6880223</td>\n",
       "<td>0.6880223</td>\n",
       "<td>0.9219512</td>\n",
       "<td>0.9219512</td>\n",
       "<td>0.1866969</td>\n",
       "<td>1.0</td>\n",
       "<td>86.5408869</td>\n",
       "<td>149.9651568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5001394</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9994426</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.7374582</td>\n",
       "<td>0.7374582</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.9442586</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999442</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6668216</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.6147770</td>\n",
       "<td>0.6147770</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6821561</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000279</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285145</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.5268817</td>\n",
       "<td>0.5268817</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8514536</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7998327</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2502614</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4611363</td>\n",
       "<td>0.4611363</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0261415</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999164</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1112144</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4098513</td>\n",
       "<td>0.4098513</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1214374</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3688319</td>\n",
       "<td>0.3688319</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0100362                   1                  2.71126  2.71126            1                1            1                           1                   0.0272109       0.0272109                  171.126  171.126\n",
       "    2        0.0200725                   1                  2.71126  2.71126            1                1            1                           1                   0.0272109       0.0544218                  171.126  171.126\n",
       "    3        0.0301087                   1                  2.71126  2.71126            1                1            1                           1                   0.0272109       0.0816327                  171.126  171.126\n",
       "    4        0.040145                    1                  2.71126  2.71126            1                1            1                           1                   0.0272109       0.108844                   171.126  171.126\n",
       "    5        0.0501812                   1                  2.71126  2.71126            1                1            1                           1                   0.0272109       0.136054                   171.126  171.126\n",
       "    6        0.100084                    1                  2.71126  2.71126            1                1            1                           1                   0.135299        0.271353                   171.126  171.126\n",
       "    7        0.149986                    1                  2.71126  2.71126            1                1            1                           1                   0.135299        0.406652                   171.126  171.126\n",
       "    8        0.200167                    1                  2.71126  2.71126            1                1            1                           1                   0.136054        0.542706                   171.126  171.126\n",
       "    9        0.299972                    1                  2.71126  2.71126            1                1            1                           1                   0.270597        0.813303                   171.126  171.126\n",
       "    10       0.400056                    3.29648e-09        1.86541  2.49965            0.688022         0.688022     0.921951                    0.921951            0.186697        1                          86.5409  149.965\n",
       "    11       0.500139                    6.70987e-11        0        1.99944            0                6.23619e-10  0.737458                    0.737458            0               1                          -100     99.9443\n",
       "    12       0.599944                    1.0757e-11         0        1.66682            0                2.79633e-11  0.614777                    0.614777            0               1                          -100     66.6822\n",
       "    13       0.700028                    3.91928e-12        0        1.42851            0                6.59065e-12  0.526882                    0.526882            0               1                          -100     42.8515\n",
       "    14       0.799833                    1.68e-12           0        1.25026            0                2.6106e-12   0.461136                    0.461136            0               1                          -100     25.0261\n",
       "    15       0.899916                    8.23966e-13        0        1.11121            0                1.21339e-12  0.409851                    0.409851            0               1                          -100     11.1214\n",
       "    16       1                           2.28061e-13        0        1                  0                5.60333e-13  0.368832                    0.368832            0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 3.2413930716779464e-15\n",
      "RMSE: 5.6933233455319804e-08\n",
      "LogLoss: 5.336647081326041e-09\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "pr_auc: 0.01388888888888884\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9999999424961982: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>236.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/236.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>144.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/144.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>236.0</td>\n",
       "<td>144.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/380.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      236  0    0        (0.0/236.0)\n",
       "1      0    144  0        (0.0/144.0)\n",
       "Total  236  144  0        (0.0/380.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       1            1        1\n",
       "max f2                       1            1        1\n",
       "max f0point5                 1            1        1\n",
       "max accuracy                 1            1        1\n",
       "max precision                1            1        0\n",
       "max recall                   1            1        1\n",
       "max specificity              1            1        0\n",
       "max absolute_mcc             1            1        1\n",
       "max min_per_class_accuracy   1            1        1\n",
       "max mean_per_class_accuracy  1            1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 37.89 %, avg score: 37.89 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0105263</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0210526</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0315789</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0833333</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0421053</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1111111</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.1319444</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1319444</td>\n",
       "<td>0.2638889</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1319444</td>\n",
       "<td>0.3958333</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1319444</td>\n",
       "<td>0.5277778</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.2638889</td>\n",
       "<td>0.7916667</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0000000</td>\n",
       "<td>2.0833333</td>\n",
       "<td>2.5</td>\n",
       "<td>0.7894737</td>\n",
       "<td>0.7894737</td>\n",
       "<td>0.9473684</td>\n",
       "<td>0.9473684</td>\n",
       "<td>0.2083333</td>\n",
       "<td>1.0</td>\n",
       "<td>108.3333333</td>\n",
       "<td>150.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.7578947</td>\n",
       "<td>0.7578947</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.6315789</td>\n",
       "<td>0.6315790</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.5413534</td>\n",
       "<td>0.5413534</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4736842</td>\n",
       "<td>0.4736842</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4210526</td>\n",
       "<td>0.4210526</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3789474</td>\n",
       "<td>0.3789474</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0105263                   1                  2.63889  2.63889            1                1            1                           1                   0.0277778       0.0277778                  163.889  163.889\n",
       "    2        0.0210526                   1                  2.63889  2.63889            1                1            1                           1                   0.0277778       0.0555556                  163.889  163.889\n",
       "    3        0.0315789                   1                  2.63889  2.63889            1                1            1                           1                   0.0277778       0.0833333                  163.889  163.889\n",
       "    4        0.0421053                   1                  2.63889  2.63889            1                1            1                           1                   0.0277778       0.111111                   163.889  163.889\n",
       "    5        0.05                        1                  2.63889  2.63889            1                1            1                           1                   0.0208333       0.131944                   163.889  163.889\n",
       "    6        0.1                         1                  2.63889  2.63889            1                1            1                           1                   0.131944        0.263889                   163.889  163.889\n",
       "    7        0.15                        1                  2.63889  2.63889            1                1            1                           1                   0.131944        0.395833                   163.889  163.889\n",
       "    8        0.2                         1                  2.63889  2.63889            1                1            1                           1                   0.131944        0.527778                   163.889  163.889\n",
       "    9        0.3                         1                  2.63889  2.63889            1                1            1                           1                   0.263889        0.791667                   163.889  163.889\n",
       "    10       0.4                         1.08378e-08        2.08333  2.5                0.789474         0.789474     0.947368                    0.947368            0.208333        1                          108.333  150\n",
       "    11       0.5                         6.31579e-11        0        2                  0                1.65358e-09  0.757895                    0.757895            0               1                          -100     100\n",
       "    12       0.6                         1.00269e-11        0        1.66667            0                3.00831e-11  0.631579                    0.631579            0               1                          -100     66.6667\n",
       "    13       0.7                         3.66789e-12        0        1.42857            0                5.62522e-12  0.541353                    0.541353            0               1                          -100     42.8571\n",
       "    14       0.8                         1.53395e-12        0        1.25               0                2.33041e-12  0.473684                    0.473684            0               1                          -100     25\n",
       "    15       0.9                         8.28279e-13        0        1.11111            0                1.15685e-12  0.421053                    0.421053            0               1                          -100     11.1111\n",
       "    16       1                           2.30425e-13        0        1                  0                4.54299e-13  0.378947                    0.378947            0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.0003096497654099919\n",
      "RMSE: 0.01759686805684443\n",
      "LogLoss: 0.0012563667886395385\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "pr_auc: 0.6016628873771731\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.029200452923347428: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>2264.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/2264.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>1323.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/1323.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>2264.0</td>\n",
       "<td>1323.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/3587.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ------------\n",
       "0      2264  0     0        (0.0/2264.0)\n",
       "1      0     1323  0        (0.0/1323.0)\n",
       "Total  2264  1323  0        (0.0/3587.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       0.0292005    1        213\n",
       "max f2                       0.0292005    1        213\n",
       "max f0point5                 0.0292005    1        213\n",
       "max accuracy                 0.0292005    1        213\n",
       "max precision                1            1        0\n",
       "max recall                   0.0292005    1        213\n",
       "max specificity              1            1        0\n",
       "max absolute_mcc             0.0292005    1        213\n",
       "max min_per_class_accuracy   0.0292005    1        213\n",
       "max mean_per_class_accuracy  0.0292005    1        213"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 36.88 %, avg score: 36.84 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0674658</td>\n",
       "<td>1.0</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1829176</td>\n",
       "<td>0.1829176</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.1000836</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0884354</td>\n",
       "<td>0.2713530</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.1499861</td>\n",
       "<td>0.9999998</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1352986</td>\n",
       "<td>0.4066515</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.2001673</td>\n",
       "<td>0.9999989</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999993</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.1360544</td>\n",
       "<td>0.5427060</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.2999721</td>\n",
       "<td>0.9999506</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999899</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999965</td>\n",
       "<td>0.2705971</td>\n",
       "<td>0.8133031</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.4000558</td>\n",
       "<td>0.0000657</td>\n",
       "<td>1.8654089</td>\n",
       "<td>2.4996516</td>\n",
       "<td>0.6880223</td>\n",
       "<td>0.6832836</td>\n",
       "<td>0.9219512</td>\n",
       "<td>0.9207631</td>\n",
       "<td>0.1866969</td>\n",
       "<td>1.0</td>\n",
       "<td>86.5408869</td>\n",
       "<td>149.9651568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.5001394</td>\n",
       "<td>0.0000118</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9994426</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000263</td>\n",
       "<td>0.7374582</td>\n",
       "<td>0.7365131</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.9442586</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.5999442</td>\n",
       "<td>0.0000004</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6668216</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000028</td>\n",
       "<td>0.6147770</td>\n",
       "<td>0.6139896</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6821561</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.7000279</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285145</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.5268817</td>\n",
       "<td>0.5262069</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8514536</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.7998327</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2502614</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4611363</td>\n",
       "<td>0.4605457</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0261415</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>1.0</td>\n",
       "<td>1e-19</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3688319</td>\n",
       "<td>0.3683595</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0674658                   1                  2.71126  2.71126            1                1            1                           1                   0.182918        0.182918                   171.126  171.126\n",
       "    2        0.100084                    1                  2.71126  2.71126            1                1            1                           1                   0.0884354       0.271353                   171.126  171.126\n",
       "    3        0.149986                    1                  2.71126  2.71126            1                1            1                           1                   0.135299        0.406652                   171.126  171.126\n",
       "    4        0.200167                    0.999999           2.71126  2.71126            1                0.999999     1                           1                   0.136054        0.542706                   171.126  171.126\n",
       "    5        0.299972                    0.999951           2.71126  2.71126            1                0.99999      1                           0.999997            0.270597        0.813303                   171.126  171.126\n",
       "    6        0.400056                    6.56677e-05        1.86541  2.49965            0.688022         0.683284     0.921951                    0.920763            0.186697        1                          86.5409  149.965\n",
       "    7        0.500139                    1.18336e-05        0        1.99944            0                2.63325e-05  0.737458                    0.736513            0               1                          -100     99.9443\n",
       "    8        0.599944                    3.57631e-07        0        1.66682            0                2.79703e-06  0.614777                    0.61399             0               1                          -100     66.6822\n",
       "    9        0.700028                    1.0833e-07         0        1.42851            0                2.03735e-07  0.526882                    0.526207            0               1                          -100     42.8515\n",
       "    10       0.799833                    2.2661e-12         0        1.25026            0                3.28814e-08  0.461136                    0.460546            0               1                          -100     25.0261\n",
       "    11       1                           1e-19              0        1                  0                2.18056e-13  0.368832                    0.36836             0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.7112694</td>\n",
       "<td>0.0028505</td>\n",
       "<td>2.709434</td>\n",
       "<td>2.709434</td>\n",
       "<td>2.7056603</td>\n",
       "<td>2.715909</td>\n",
       "<td>2.715909</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0012569</td>\n",
       "<td>0.0013725</td>\n",
       "<td>0.0006465</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0005358</td>\n",
       "<td>0.0051021</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0003098</td>\n",
       "<td>0.0003574</td>\n",
       "<td>0.0000940</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0001402</td>\n",
       "<td>0.0013147</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9986684</td>\n",
       "<td>0.0015362</td>\n",
       "<td>0.9995962</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9993972</td>\n",
       "<td>0.9943485</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.0115597</td>\n",
       "<td>0.0093854</td>\n",
       "<td>0.0096971</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000003</td>\n",
       "<td>0.0118420</td>\n",
       "<td>0.0362590</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 1            0            1             1             1             1             1\n",
       "auc                      1            0            1             1             1             1             1\n",
       "err                      0            0            0             0             0             0             0\n",
       "err_count                0            0            0             0             0             0             0\n",
       "f0point5                 1            0            1             1             1             1             1\n",
       "f1                       1            0            1             1             1             1             1\n",
       "f2                       1            0            1             1             1             1             1\n",
       "lift_top_group           2.71127      0.00285048   2.70943       2.70943       2.70566       2.71591       2.71591\n",
       "logloss                  0.00125689   0.00137251   0.000646514   2.01325e-16   1.40619e-08   0.000535789   0.00510212\n",
       "max_per_class_error      0            0            0             0             0             0             0\n",
       "mcc                      1            0            1             1             1             1             1\n",
       "mean_per_class_accuracy  1            0            1             1             1             1             1\n",
       "mean_per_class_error     0            0            0             0             0             0             0\n",
       "mse                      0.000309796  0.000357368  9.40328e-05   5.08588e-30   1.14301e-13   0.000140232   0.00131472\n",
       "precision                1            0            1             1             1             1             1\n",
       "r2                       0.998668     0.00153624   0.999596      1             1             0.999397      0.994348\n",
       "recall                   1            0            1             1             1             1             1\n",
       "rmse                     0.0115597    0.00938537   0.00969705    2.25519e-15   3.38084e-07   0.011842      0.036259\n",
       "specificity              1            0            1             1             1             1             1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_pr_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:55</td>\n",
       "<td> 3 min 36.342 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4824883</td>\n",
       "<td>0.6583311</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6311681</td>\n",
       "<td>0.4852304</td>\n",
       "<td>0.6637654</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6210526</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:55</td>\n",
       "<td> 3 min 36.381 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.3338924</td>\n",
       "<td>0.3975409</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969766</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3374659</td>\n",
       "<td>0.4025303</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9930556</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:55</td>\n",
       "<td> 3 min 36.446 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.2222338</td>\n",
       "<td>0.2440872</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984883</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2250764</td>\n",
       "<td>0.2472630</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9930556</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:55</td>\n",
       "<td> 3 min 36.505 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.1511170</td>\n",
       "<td>0.1583229</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984883</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1538599</td>\n",
       "<td>0.1610000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9930556</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:55</td>\n",
       "<td> 3 min 36.561 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.1064182</td>\n",
       "<td>0.1077223</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984883</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1094944</td>\n",
       "<td>0.1104652</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9930556</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:59</td>\n",
       "<td> 3 min 40.526 sec</td>\n",
       "<td>335.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0015117</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0277778</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:59</td>\n",
       "<td> 3 min 40.593 sec</td>\n",
       "<td>340.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0015117</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0277778</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:59</td>\n",
       "<td> 3 min 40.651 sec</td>\n",
       "<td>345.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0015117</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0208333</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:59</td>\n",
       "<td> 3 min 40.721 sec</td>\n",
       "<td>350.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0007559</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0138889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:59</td>\n",
       "<td> 3 min 40.746 sec</td>\n",
       "<td>351.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0007559</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0138889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration          number_of_trees    training_rmse           training_logloss        training_auc    training_pr_auc        training_lift      training_classification_error    validation_rmse         validation_logloss     validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "---  -------------------  ----------------  -----------------  ----------------------  ----------------------  --------------  ---------------------  -----------------  -------------------------------  ----------------------  ---------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "     2019-01-31 13:30:55  3 min 36.342 sec  0.0                0.4824882668957528      0.6583310663944258      0.5             0.0                    1.0                0.6311681070532479               0.4852304434306271      0.6637654161828104     0.5               0.0                  1.0                0.6210526315789474\n",
       "     2019-01-31 13:30:55  3 min 36.381 sec  5.0                0.3338923938209607      0.3975408862887319      1.0             0.9969765684051399     2.711262282690854  0.0                              0.3374658603277833      0.4025303058297335     1.0               0.9930555555555556   2.638888888888889  0.0\n",
       "     2019-01-31 13:30:55  3 min 36.446 sec  10.0               0.22223383951504874     0.24408719994791403     1.0             0.9984882842025699     2.711262282690854  0.0                              0.22507640678724808     0.247262971780396      1.0               0.9930555555555556   2.638888888888889  0.0\n",
       "     2019-01-31 13:30:55  3 min 36.505 sec  15.0               0.1511170337302948      0.1583228870967358      1.0             0.9984882842025699     2.711262282690854  0.0                              0.15385990038886896     0.1610000144560166     1.0               0.9930555555555556   2.638888888888889  0.0\n",
       "     2019-01-31 13:30:55  3 min 36.561 sec  20.0               0.10641817590333631     0.10772231077176093     1.0             0.9984882842025699     2.711262282690854  0.0                              0.109494446077383       0.1104652391290607     1.0               0.9930555555555556   2.638888888888889  0.0\n",
       "---  ---                  ---               ---                ---                     ---                     ---             ---                    ---                ---                              ---                     ---                    ---               ---                  ---                ---\n",
       "     2019-01-31 13:30:59  3 min 40.526 sec  335.0              4.470706188231968e-09   1.3548147475462647e-09  1.0             0.0015117157974300355  2.711262282690854  0.0                              7.011395106103285e-08   7.837808094368834e-09  1.0               0.02777777777777779  2.638888888888889  0.0\n",
       "     2019-01-31 13:30:59  3 min 40.593 sec  340.0              3.4203004652129214e-09  1.0406551070795538e-09  1.0             0.0015117157974300355  2.711262282690854  0.0                              6.185703819903474e-08   6.495827537621287e-09  1.0               0.02777777777777779  2.638888888888889  0.0\n",
       "     2019-01-31 13:30:59  3 min 40.651 sec  345.0              2.851766215627652e-09   8.601684547358576e-10   1.0             0.0015117157974300355  2.711262282690854  0.0                              6.493285845596487e-08   6.270629006279485e-09  1.0               0.02083333333333337  2.638888888888889  0.0\n",
       "     2019-01-31 13:30:59  3 min 40.721 sec  350.0              2.187256652114171e-09   6.62928142306428e-10    1.0             0.0007558578987150177  2.711262282690854  0.0                              5.270692695954748e-08   5.064310856701214e-09  1.0               0.01388888888888884  2.638888888888889  0.0\n",
       "     2019-01-31 13:30:59  3 min 40.746 sec  351.0              2.1616404078110873e-09  6.55074370626418e-10    1.0             0.0007558578987150177  2.711262282690854  0.0                              5.6933233455319804e-08  5.336647081326041e-09  1.0               0.01388888888888884  2.638888888888889  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>features85_list_indices</td>\n",
       "<td>2386.1770020</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4569574</td></tr>\n",
       "<tr><td>features85_list_values</td>\n",
       "<td>1668.8812256</td>\n",
       "<td>0.6993954</td>\n",
       "<td>0.3195939</td></tr>\n",
       "<tr><td>kl_words</td>\n",
       "<td>580.0820923</td>\n",
       "<td>0.2431010</td>\n",
       "<td>0.1110868</td></tr>\n",
       "<tr><td>ks_words</td>\n",
       "<td>257.0541687</td>\n",
       "<td>0.1077264</td>\n",
       "<td>0.0492264</td></tr>\n",
       "<tr><td>ngramscounts7_list_values</td>\n",
       "<td>221.1662292</td>\n",
       "<td>0.0926864</td>\n",
       "<td>0.0423537</td></tr>\n",
       "<tr><td>entropy_words</td>\n",
       "<td>108.5201645</td>\n",
       "<td>0.0454787</td>\n",
       "<td>0.0207818</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                   relative_importance    scaled_importance    percentage\n",
       "-------------------------  ---------------------  -------------------  ------------\n",
       "features85_list_indices    2386.18                1                    0.456957\n",
       "features85_list_values     1668.88                0.699395             0.319594\n",
       "kl_words                   580.082                0.243101             0.111087\n",
       "ks_words                   257.054                0.107726             0.0492264\n",
       "ngramscounts7_list_values  221.166                0.0926864            0.0423537\n",
       "entropy_words              108.52                 0.0454787            0.0207818"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The leader model is stored here\n",
    "aml.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>hash_message                                                                                                                    </th><th style=\"text-align: right;\">  fraud_label</th><th style=\"text-align: right;\">  kl_words</th><th style=\"text-align: right;\">  ks_words</th><th style=\"text-align: right;\">  entropy_words</th><th style=\"text-align: right;\">  features85_type</th><th style=\"text-align: right;\">  features85_size</th><th style=\"text-align: right;\">  ngramscounts7_type</th><th style=\"text-align: right;\">  ngramscounts7_size</th><th>features85_list_indices  </th><th>features85_list_values  </th><th>ngramscounts7_list_indices  </th><th>ngramscounts7_list_values  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>589ff83a30fa5d82563f0051bbd9f638d3dc7f102f8c78ab137c17b859e740de35348417e0deb2037cd0188c243c674100eb57f97450c4b942c9d3a1ef86a07b</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   5121.78</td><td style=\"text-align: right;\">  0.386449</td><td style=\"text-align: right;\">      0.0775856</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    251    252    253\n",
       "    271    272    312    313    365    366    367    368    369    370\n",
       "    372    373    374    375    376    421    422    423    424    425\n",
       "    426    427    428    532   1571   1572   1573   2191  11120  32829\n",
       "  35576  37068  51952 119101 129064 152122 153250 164794 175213 183033\n",
       " 186242 201741 224421 238588 259672]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>865fc00f8a94dd1c467c39753bfb2b18626f2827db85a05654caf048e657b6856afad3fef87873197e7f92e0ff760c8f04cd5484c910a037476643addfdb5c31</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   3572.81</td><td style=\"text-align: right;\">  0.999849</td><td style=\"text-align: right;\">      0.067809 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    118    119    120    177    178    179    180    181    182    204\n",
       "    271    272    312    313    365    366    367    368    369    370\n",
       "    372    373    374    375    376    421    422    423    424    425\n",
       "    426    427    428   1861   2230   2233   2234   2235   2243   2244\n",
       "   3891   7550   7571   7600   7674  14441  67052  83797 152373 155708\n",
       " 158659 159474 175973 183005 184980 186211 187030 188782 196015 199169\n",
       " 199626 200056]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>a659ae2c8efbde6eb990b90acae3e02f644e44cd1a3a9aa6490632209641eb5714bb4b740ddcbe95e50b5cd319a8725634ffea38ae633fd6ab1f7114ad8c17bd</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4872.41</td><td style=\"text-align: right;\">  0.629505</td><td style=\"text-align: right;\">      0.0770424</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   2210   2212   2213   2766   3349  12663  12732  13137  35371  40445\n",
       "  63248 160374 163934 167319 170979 176627 185968 187302 207482 215154\n",
       " 242580 254804]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>d6d7bcd45dfa2fb6487352a532359f3f64afe250dacb422898ed9854af8992866bff17dac83f36763b46f2db2e0442fdf23fafdd58628636ca3395b6ef019a16</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4971.4 </td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.0765636</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   1409   1411   1413   2218   7166  10778  10969  10974  15342  28341\n",
       "  29276  66279  66595  68252  78062 111684 113098 113516 119462 121057\n",
       " 125868 129046 130194 137990 150551 150859]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>da23c7d6b5dd13228bb9b8e5d3287463ca7b12fbc8a5c068ce2cf4ca3e7e89ca6990a4abfc69dcedd538ee916f64a8d5d0440d1ad309c9604efc9ad4074a81ed</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4871.22</td><td style=\"text-align: right;\">  0.784173</td><td style=\"text-align: right;\">      0.0793658</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    118    119    120    177    178    179    180    181    182    204\n",
       "    234    271    272    312    313    365    366    367    368    369\n",
       "    370    372    373    374    375    376    421    422    423    424\n",
       "    425    426    427    428   3042   3046   3077   3084   7166   8059\n",
       "   8094   8370  16914  17771  25245  25350  25471  26079  26856  27476\n",
       "  27506  89583  90454  93388  96240  97551  97803  99368 104348]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>980071f323752c9f7e987d2f657d244851b601c46ef50b2cd053d69ee9c3a7b413730fff5a68bea2dd9ada49d410f0c0f8165ad2a9096c2c419668df2b829de3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4761.19</td><td style=\"text-align: right;\">  0.679739</td><td style=\"text-align: right;\">      0.0770313</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 38 39 40 41 42 43 44 45 46 47 48\n",
       " 49 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "    588    589    590    990   1571   1572   1573   1813   3385  54750\n",
       "  63934 108396 134505 150356 156504 160046 164074 172543 184330 185036\n",
       " 203108 204988 207776 219974 224760 227729 251427]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>e38e2712270ef1f79716537aa2816eaab104a20e17c94df57b49b787cda6f8e96794acf70b302c9708e9573dda18e402c7e996ea14e537e736001b12070d7542</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4871.09</td><td style=\"text-align: right;\">  0.679739</td><td style=\"text-align: right;\">      0.0751454</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   1464   1468   1470   2377   3698   4191   4201   4216   7993  29538\n",
       "  31603 108794 110094 120213 133311 134383 136510 145291 149087 151081\n",
       " 154755 171878 173525 178505 181503 184913 189087 196194 202237]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>26f328150124298822fc4a0be849251c3d3545dcb2495c71dc92a60d1629ea641ec4d24c7004a3d579df61f5ba7197ffe6e88e3efaee93d226270372ee87d4b2</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4980.78</td><td style=\"text-align: right;\">  0.52636 </td><td style=\"text-align: right;\">      0.0788552</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    118    119    120    177    178    179    180    181    182    204\n",
       "    234    271    272    312    313    365    366    367    368    369\n",
       "    370    372    373    374    375    376    421    422    423    424\n",
       "    425    426    427    428   1409   1411   1413   1813   2364   4990\n",
       "   5008   5010  24711  24781  25711  25882  26069  26190  26285  26724\n",
       "  48517  72318 231749 232265 238880 242356]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>2b8a2419e7f2c6fecb549146c3d66ab9cae9839005d8f848d39313e49b34d22c18c6eb7e20b3b0c5291d4ad0f7f2b329423816423f62a40a7dae70870c2b7f9f</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4909.64</td><td style=\"text-align: right;\">  0.734024</td><td style=\"text-align: right;\">      0.0785097</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   1464   1468   1470   2779   4191   4201   4216   7993  32826  35408\n",
       "  51952 110395 114044 118743 118935 129694 140512 150098 181503 184913\n",
       " 202237 229194]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>67d469882a190b2d6262a34bcca389d43799a46e823c51da3c685150a32c5779132915cfd6cc965db7d7f92639dd725dad1e29d2f69598d63cdf1402d2fa66b3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   5203.28</td><td style=\"text-align: right;\">  0.682076</td><td style=\"text-align: right;\">      0.0799091</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     16     66     67     68     69     70\n",
       "    177    178    179    180    181    182    204    271    272    312\n",
       "    313    365    366    367    368    369    370    372    373    374\n",
       "    375    376    421    422    423    424    425    426    427    428\n",
       "   1409   1411   1413   1593   3716   3726   3731   6099  11019  28962\n",
       "  34089  34164  35450  35825  36555  36821  37443  39297  43061  87723\n",
       "  90758  91916  93784  97570 102154 106550 213589 221225]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">         p0</th><th style=\"text-align: right;\">  p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.87768e-10</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.4861e-09 </td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">3.62737e-11</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.359e-11  </td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">3.21747e-11</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">3.42677e-10</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.86118e-11</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">2.32721e-10</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">9.11604e-12</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.69261e-10</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# If you need to generate predictions on a test set, you can make\n",
    "# predictions directly on the `\"H2OAutoML\"` object, or on the leader\n",
    "# model object directly\n",
    "\n",
    "#preds = aml.predict(test)\n",
    "# or:\n",
    "preds = aml.leader.predict(test)\n",
    "print(\"test\")\n",
    "print(test.head(10))\n",
    "print(\"prediction\")\n",
    "print(preds.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GBM_grid_1_AutoML_20190131_132458_model_3', 'GBM_5_AutoML_20190131_132458', 'GBM_2_AutoML_20190131_132458', 'GBM_1_AutoML_20190131_132458', 'GBM_grid_1_AutoML_20190131_132458_model_2', 'XGBoost_grid_1_AutoML_20190131_132458_model_5', 'GBM_grid_1_AutoML_20190131_132458_model_4', 'StackedEnsemble_BestOfFamily_AutoML_20190131_132458', 'GBM_4_AutoML_20190131_132458', 'GBM_3_AutoML_20190131_132458', 'XGBoost_grid_1_AutoML_20190131_132458_model_3', 'XGBoost_grid_1_AutoML_20190131_132458_model_1', 'DeepLearning_grid_1_AutoML_20190131_132458_model_3', 'StackedEnsemble_AllModels_AutoML_20190131_132458', 'DeepLearning_1_AutoML_20190131_132458', 'XGBoost_grid_1_AutoML_20190131_132458_model_2', 'DeepLearning_grid_1_AutoML_20190131_132458_model_4', 'XGBoost_1_AutoML_20190131_132458', 'DeepLearning_grid_1_AutoML_20190131_132458_model_2', 'XGBoost_grid_1_AutoML_20190131_132458_model_6', 'GBM_grid_1_AutoML_20190131_132458_model_1', 'XGBoost_2_AutoML_20190131_132458', 'DeepLearning_grid_1_AutoML_20190131_132458_model_1', 'XGBoost_3_AutoML_20190131_132458', 'XGBoost_grid_1_AutoML_20190131_132458_model_4', 'XGBoost_grid_1_AutoML_20190131_132458_model_7']\n",
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_grid_1_AutoML_20190131_132458_model_3\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 4.672689252681684e-18\n",
      "RMSE: 2.1616404078110873e-09\n",
      "LogLoss: 6.55074370626418e-10\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "pr_auc: 0.0007558578987150177\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9999999659099943: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>2264.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/2264.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>1323.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/1323.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>2264.0</td>\n",
       "<td>1323.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/3587.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ------------\n",
       "0      2264  0     0        (0.0/2264.0)\n",
       "1      0     1323  0        (0.0/1323.0)\n",
       "Total  2264  1323  0        (0.0/3587.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       1            1        1\n",
       "max f2                       1            1        1\n",
       "max f0point5                 1            1        1\n",
       "max accuracy                 1            1        1\n",
       "max precision                1            1        0\n",
       "max recall                   1            1        1\n",
       "max specificity              1            1        0\n",
       "max absolute_mcc             1            1        1\n",
       "max min_per_class_accuracy   1            1        1\n",
       "max mean_per_class_accuracy  1            1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 36.88 %, avg score: 36.88 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100362</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0272109</td>\n",
       "<td>0.0272109</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200725</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0272109</td>\n",
       "<td>0.0544218</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0301087</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0272109</td>\n",
       "<td>0.0816327</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0401450</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0272109</td>\n",
       "<td>0.1088435</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0501812</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0272109</td>\n",
       "<td>0.1360544</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000836</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1352986</td>\n",
       "<td>0.2713530</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1499861</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1352986</td>\n",
       "<td>0.4066515</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2001673</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1360544</td>\n",
       "<td>0.5427060</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999721</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.2705971</td>\n",
       "<td>0.8133031</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000558</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.8654089</td>\n",
       "<td>2.4996516</td>\n",
       "<td>0.6880223</td>\n",
       "<td>0.6880223</td>\n",
       "<td>0.9219512</td>\n",
       "<td>0.9219512</td>\n",
       "<td>0.1866969</td>\n",
       "<td>1.0</td>\n",
       "<td>86.5408869</td>\n",
       "<td>149.9651568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5001394</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9994426</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.7374582</td>\n",
       "<td>0.7374582</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.9442586</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999442</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6668216</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.6147770</td>\n",
       "<td>0.6147770</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6821561</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000279</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285145</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.5268817</td>\n",
       "<td>0.5268817</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8514536</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7998327</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2502614</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4611363</td>\n",
       "<td>0.4611363</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0261415</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999164</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1112144</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4098513</td>\n",
       "<td>0.4098513</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1214374</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3688319</td>\n",
       "<td>0.3688319</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0100362                   1                  2.71126  2.71126            1                1            1                           1                   0.0272109       0.0272109                  171.126  171.126\n",
       "    2        0.0200725                   1                  2.71126  2.71126            1                1            1                           1                   0.0272109       0.0544218                  171.126  171.126\n",
       "    3        0.0301087                   1                  2.71126  2.71126            1                1            1                           1                   0.0272109       0.0816327                  171.126  171.126\n",
       "    4        0.040145                    1                  2.71126  2.71126            1                1            1                           1                   0.0272109       0.108844                   171.126  171.126\n",
       "    5        0.0501812                   1                  2.71126  2.71126            1                1            1                           1                   0.0272109       0.136054                   171.126  171.126\n",
       "    6        0.100084                    1                  2.71126  2.71126            1                1            1                           1                   0.135299        0.271353                   171.126  171.126\n",
       "    7        0.149986                    1                  2.71126  2.71126            1                1            1                           1                   0.135299        0.406652                   171.126  171.126\n",
       "    8        0.200167                    1                  2.71126  2.71126            1                1            1                           1                   0.136054        0.542706                   171.126  171.126\n",
       "    9        0.299972                    1                  2.71126  2.71126            1                1            1                           1                   0.270597        0.813303                   171.126  171.126\n",
       "    10       0.400056                    3.29648e-09        1.86541  2.49965            0.688022         0.688022     0.921951                    0.921951            0.186697        1                          86.5409  149.965\n",
       "    11       0.500139                    6.70987e-11        0        1.99944            0                6.23619e-10  0.737458                    0.737458            0               1                          -100     99.9443\n",
       "    12       0.599944                    1.0757e-11         0        1.66682            0                2.79633e-11  0.614777                    0.614777            0               1                          -100     66.6822\n",
       "    13       0.700028                    3.91928e-12        0        1.42851            0                6.59065e-12  0.526882                    0.526882            0               1                          -100     42.8515\n",
       "    14       0.799833                    1.68e-12           0        1.25026            0                2.6106e-12   0.461136                    0.461136            0               1                          -100     25.0261\n",
       "    15       0.899916                    8.23966e-13        0        1.11121            0                1.21339e-12  0.409851                    0.409851            0               1                          -100     11.1214\n",
       "    16       1                           2.28061e-13        0        1                  0                5.60333e-13  0.368832                    0.368832            0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 3.2413930716779464e-15\n",
      "RMSE: 5.6933233455319804e-08\n",
      "LogLoss: 5.336647081326041e-09\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "pr_auc: 0.01388888888888884\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9999999424961982: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>236.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/236.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>144.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/144.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>236.0</td>\n",
       "<td>144.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/380.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      236  0    0        (0.0/236.0)\n",
       "1      0    144  0        (0.0/144.0)\n",
       "Total  236  144  0        (0.0/380.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       1            1        1\n",
       "max f2                       1            1        1\n",
       "max f0point5                 1            1        1\n",
       "max accuracy                 1            1        1\n",
       "max precision                1            1        0\n",
       "max recall                   1            1        1\n",
       "max specificity              1            1        0\n",
       "max absolute_mcc             1            1        1\n",
       "max min_per_class_accuracy   1            1        1\n",
       "max mean_per_class_accuracy  1            1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 37.89 %, avg score: 37.89 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0105263</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0210526</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0315789</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0833333</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0421053</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1111111</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.1319444</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1319444</td>\n",
       "<td>0.2638889</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1319444</td>\n",
       "<td>0.3958333</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1319444</td>\n",
       "<td>0.5277778</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.2638889</td>\n",
       "<td>0.7916667</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0000000</td>\n",
       "<td>2.0833333</td>\n",
       "<td>2.5</td>\n",
       "<td>0.7894737</td>\n",
       "<td>0.7894737</td>\n",
       "<td>0.9473684</td>\n",
       "<td>0.9473684</td>\n",
       "<td>0.2083333</td>\n",
       "<td>1.0</td>\n",
       "<td>108.3333333</td>\n",
       "<td>150.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.7578947</td>\n",
       "<td>0.7578947</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.6315789</td>\n",
       "<td>0.6315790</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.5413534</td>\n",
       "<td>0.5413534</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4736842</td>\n",
       "<td>0.4736842</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4210526</td>\n",
       "<td>0.4210526</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3789474</td>\n",
       "<td>0.3789474</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0105263                   1                  2.63889  2.63889            1                1            1                           1                   0.0277778       0.0277778                  163.889  163.889\n",
       "    2        0.0210526                   1                  2.63889  2.63889            1                1            1                           1                   0.0277778       0.0555556                  163.889  163.889\n",
       "    3        0.0315789                   1                  2.63889  2.63889            1                1            1                           1                   0.0277778       0.0833333                  163.889  163.889\n",
       "    4        0.0421053                   1                  2.63889  2.63889            1                1            1                           1                   0.0277778       0.111111                   163.889  163.889\n",
       "    5        0.05                        1                  2.63889  2.63889            1                1            1                           1                   0.0208333       0.131944                   163.889  163.889\n",
       "    6        0.1                         1                  2.63889  2.63889            1                1            1                           1                   0.131944        0.263889                   163.889  163.889\n",
       "    7        0.15                        1                  2.63889  2.63889            1                1            1                           1                   0.131944        0.395833                   163.889  163.889\n",
       "    8        0.2                         1                  2.63889  2.63889            1                1            1                           1                   0.131944        0.527778                   163.889  163.889\n",
       "    9        0.3                         1                  2.63889  2.63889            1                1            1                           1                   0.263889        0.791667                   163.889  163.889\n",
       "    10       0.4                         1.08378e-08        2.08333  2.5                0.789474         0.789474     0.947368                    0.947368            0.208333        1                          108.333  150\n",
       "    11       0.5                         6.31579e-11        0        2                  0                1.65358e-09  0.757895                    0.757895            0               1                          -100     100\n",
       "    12       0.6                         1.00269e-11        0        1.66667            0                3.00831e-11  0.631579                    0.631579            0               1                          -100     66.6667\n",
       "    13       0.7                         3.66789e-12        0        1.42857            0                5.62522e-12  0.541353                    0.541353            0               1                          -100     42.8571\n",
       "    14       0.8                         1.53395e-12        0        1.25               0                2.33041e-12  0.473684                    0.473684            0               1                          -100     25\n",
       "    15       0.9                         8.28279e-13        0        1.11111            0                1.15685e-12  0.421053                    0.421053            0               1                          -100     11.1111\n",
       "    16       1                           2.30425e-13        0        1                  0                4.54299e-13  0.378947                    0.378947            0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.0003096497654099919\n",
      "RMSE: 0.01759686805684443\n",
      "LogLoss: 0.0012563667886395385\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "pr_auc: 0.6016628873771731\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.029200452923347428: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>2264.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/2264.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>1323.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/1323.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>2264.0</td>\n",
       "<td>1323.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/3587.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ------------\n",
       "0      2264  0     0        (0.0/2264.0)\n",
       "1      0     1323  0        (0.0/1323.0)\n",
       "Total  2264  1323  0        (0.0/3587.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0292005</td>\n",
       "<td>1.0</td>\n",
       "<td>213.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       0.0292005    1        213\n",
       "max f2                       0.0292005    1        213\n",
       "max f0point5                 0.0292005    1        213\n",
       "max accuracy                 0.0292005    1        213\n",
       "max precision                1            1        0\n",
       "max recall                   0.0292005    1        213\n",
       "max specificity              1            1        0\n",
       "max absolute_mcc             0.0292005    1        213\n",
       "max min_per_class_accuracy   0.0292005    1        213\n",
       "max mean_per_class_accuracy  0.0292005    1        213"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 36.88 %, avg score: 36.84 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0674658</td>\n",
       "<td>1.0</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1829176</td>\n",
       "<td>0.1829176</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.1000836</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0884354</td>\n",
       "<td>0.2713530</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.1499861</td>\n",
       "<td>0.9999998</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1352986</td>\n",
       "<td>0.4066515</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.2001673</td>\n",
       "<td>0.9999989</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999993</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.1360544</td>\n",
       "<td>0.5427060</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.2999721</td>\n",
       "<td>0.9999506</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999899</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999965</td>\n",
       "<td>0.2705971</td>\n",
       "<td>0.8133031</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.4000558</td>\n",
       "<td>0.0000657</td>\n",
       "<td>1.8654089</td>\n",
       "<td>2.4996516</td>\n",
       "<td>0.6880223</td>\n",
       "<td>0.6832836</td>\n",
       "<td>0.9219512</td>\n",
       "<td>0.9207631</td>\n",
       "<td>0.1866969</td>\n",
       "<td>1.0</td>\n",
       "<td>86.5408869</td>\n",
       "<td>149.9651568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.5001394</td>\n",
       "<td>0.0000118</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9994426</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000263</td>\n",
       "<td>0.7374582</td>\n",
       "<td>0.7365131</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.9442586</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.5999442</td>\n",
       "<td>0.0000004</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6668216</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000028</td>\n",
       "<td>0.6147770</td>\n",
       "<td>0.6139896</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6821561</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.7000279</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285145</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.5268817</td>\n",
       "<td>0.5262069</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8514536</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.7998327</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2502614</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4611363</td>\n",
       "<td>0.4605457</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0261415</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>1.0</td>\n",
       "<td>1e-19</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3688319</td>\n",
       "<td>0.3683595</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0674658                   1                  2.71126  2.71126            1                1            1                           1                   0.182918        0.182918                   171.126  171.126\n",
       "    2        0.100084                    1                  2.71126  2.71126            1                1            1                           1                   0.0884354       0.271353                   171.126  171.126\n",
       "    3        0.149986                    1                  2.71126  2.71126            1                1            1                           1                   0.135299        0.406652                   171.126  171.126\n",
       "    4        0.200167                    0.999999           2.71126  2.71126            1                0.999999     1                           1                   0.136054        0.542706                   171.126  171.126\n",
       "    5        0.299972                    0.999951           2.71126  2.71126            1                0.99999      1                           0.999997            0.270597        0.813303                   171.126  171.126\n",
       "    6        0.400056                    6.56677e-05        1.86541  2.49965            0.688022         0.683284     0.921951                    0.920763            0.186697        1                          86.5409  149.965\n",
       "    7        0.500139                    1.18336e-05        0        1.99944            0                2.63325e-05  0.737458                    0.736513            0               1                          -100     99.9443\n",
       "    8        0.599944                    3.57631e-07        0        1.66682            0                2.79703e-06  0.614777                    0.61399             0               1                          -100     66.6822\n",
       "    9        0.700028                    1.0833e-07         0        1.42851            0                2.03735e-07  0.526882                    0.526207            0               1                          -100     42.8515\n",
       "    10       0.799833                    2.2661e-12         0        1.25026            0                3.28814e-08  0.461136                    0.460546            0               1                          -100     25.0261\n",
       "    11       1                           1e-19              0        1                  0                2.18056e-13  0.368832                    0.36836             0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.7112694</td>\n",
       "<td>0.0028505</td>\n",
       "<td>2.709434</td>\n",
       "<td>2.709434</td>\n",
       "<td>2.7056603</td>\n",
       "<td>2.715909</td>\n",
       "<td>2.715909</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0012569</td>\n",
       "<td>0.0013725</td>\n",
       "<td>0.0006465</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0005358</td>\n",
       "<td>0.0051021</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0003098</td>\n",
       "<td>0.0003574</td>\n",
       "<td>0.0000940</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0001402</td>\n",
       "<td>0.0013147</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9986684</td>\n",
       "<td>0.0015362</td>\n",
       "<td>0.9995962</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9993972</td>\n",
       "<td>0.9943485</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.0115597</td>\n",
       "<td>0.0093854</td>\n",
       "<td>0.0096971</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000003</td>\n",
       "<td>0.0118420</td>\n",
       "<td>0.0362590</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 1            0            1             1             1             1             1\n",
       "auc                      1            0            1             1             1             1             1\n",
       "err                      0            0            0             0             0             0             0\n",
       "err_count                0            0            0             0             0             0             0\n",
       "f0point5                 1            0            1             1             1             1             1\n",
       "f1                       1            0            1             1             1             1             1\n",
       "f2                       1            0            1             1             1             1             1\n",
       "lift_top_group           2.71127      0.00285048   2.70943       2.70943       2.70566       2.71591       2.71591\n",
       "logloss                  0.00125689   0.00137251   0.000646514   2.01325e-16   1.40619e-08   0.000535789   0.00510212\n",
       "max_per_class_error      0            0            0             0             0             0             0\n",
       "mcc                      1            0            1             1             1             1             1\n",
       "mean_per_class_accuracy  1            0            1             1             1             1             1\n",
       "mean_per_class_error     0            0            0             0             0             0             0\n",
       "mse                      0.000309796  0.000357368  9.40328e-05   5.08588e-30   1.14301e-13   0.000140232   0.00131472\n",
       "precision                1            0            1             1             1             1             1\n",
       "r2                       0.998668     0.00153624   0.999596      1             1             0.999397      0.994348\n",
       "recall                   1            0            1             1             1             1             1\n",
       "rmse                     0.0115597    0.00938537   0.00969705    2.25519e-15   3.38084e-07   0.011842      0.036259\n",
       "specificity              1            0            1             1             1             1             1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_pr_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:55</td>\n",
       "<td> 3 min 36.342 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4824883</td>\n",
       "<td>0.6583311</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6311681</td>\n",
       "<td>0.4852304</td>\n",
       "<td>0.6637654</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6210526</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:55</td>\n",
       "<td> 3 min 36.381 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.3338924</td>\n",
       "<td>0.3975409</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969766</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3374659</td>\n",
       "<td>0.4025303</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9930556</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:55</td>\n",
       "<td> 3 min 36.446 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.2222338</td>\n",
       "<td>0.2440872</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984883</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2250764</td>\n",
       "<td>0.2472630</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9930556</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:55</td>\n",
       "<td> 3 min 36.505 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.1511170</td>\n",
       "<td>0.1583229</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984883</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1538599</td>\n",
       "<td>0.1610000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9930556</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:55</td>\n",
       "<td> 3 min 36.561 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.1064182</td>\n",
       "<td>0.1077223</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984883</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1094944</td>\n",
       "<td>0.1104652</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9930556</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:59</td>\n",
       "<td> 3 min 40.526 sec</td>\n",
       "<td>335.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0015117</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0277778</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:59</td>\n",
       "<td> 3 min 40.593 sec</td>\n",
       "<td>340.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0015117</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0277778</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:59</td>\n",
       "<td> 3 min 40.651 sec</td>\n",
       "<td>345.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0015117</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0208333</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:59</td>\n",
       "<td> 3 min 40.721 sec</td>\n",
       "<td>350.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0007559</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0138889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-31 13:30:59</td>\n",
       "<td> 3 min 40.746 sec</td>\n",
       "<td>351.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0007559</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0138889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration          number_of_trees    training_rmse           training_logloss        training_auc    training_pr_auc        training_lift      training_classification_error    validation_rmse         validation_logloss     validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "---  -------------------  ----------------  -----------------  ----------------------  ----------------------  --------------  ---------------------  -----------------  -------------------------------  ----------------------  ---------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "     2019-01-31 13:30:55  3 min 36.342 sec  0.0                0.4824882668957528      0.6583310663944258      0.5             0.0                    1.0                0.6311681070532479               0.4852304434306271      0.6637654161828104     0.5               0.0                  1.0                0.6210526315789474\n",
       "     2019-01-31 13:30:55  3 min 36.381 sec  5.0                0.3338923938209607      0.3975408862887319      1.0             0.9969765684051399     2.711262282690854  0.0                              0.3374658603277833      0.4025303058297335     1.0               0.9930555555555556   2.638888888888889  0.0\n",
       "     2019-01-31 13:30:55  3 min 36.446 sec  10.0               0.22223383951504874     0.24408719994791403     1.0             0.9984882842025699     2.711262282690854  0.0                              0.22507640678724808     0.247262971780396      1.0               0.9930555555555556   2.638888888888889  0.0\n",
       "     2019-01-31 13:30:55  3 min 36.505 sec  15.0               0.1511170337302948      0.1583228870967358      1.0             0.9984882842025699     2.711262282690854  0.0                              0.15385990038886896     0.1610000144560166     1.0               0.9930555555555556   2.638888888888889  0.0\n",
       "     2019-01-31 13:30:55  3 min 36.561 sec  20.0               0.10641817590333631     0.10772231077176093     1.0             0.9984882842025699     2.711262282690854  0.0                              0.109494446077383       0.1104652391290607     1.0               0.9930555555555556   2.638888888888889  0.0\n",
       "---  ---                  ---               ---                ---                     ---                     ---             ---                    ---                ---                              ---                     ---                    ---               ---                  ---                ---\n",
       "     2019-01-31 13:30:59  3 min 40.526 sec  335.0              4.470706188231968e-09   1.3548147475462647e-09  1.0             0.0015117157974300355  2.711262282690854  0.0                              7.011395106103285e-08   7.837808094368834e-09  1.0               0.02777777777777779  2.638888888888889  0.0\n",
       "     2019-01-31 13:30:59  3 min 40.593 sec  340.0              3.4203004652129214e-09  1.0406551070795538e-09  1.0             0.0015117157974300355  2.711262282690854  0.0                              6.185703819903474e-08   6.495827537621287e-09  1.0               0.02777777777777779  2.638888888888889  0.0\n",
       "     2019-01-31 13:30:59  3 min 40.651 sec  345.0              2.851766215627652e-09   8.601684547358576e-10   1.0             0.0015117157974300355  2.711262282690854  0.0                              6.493285845596487e-08   6.270629006279485e-09  1.0               0.02083333333333337  2.638888888888889  0.0\n",
       "     2019-01-31 13:30:59  3 min 40.721 sec  350.0              2.187256652114171e-09   6.62928142306428e-10    1.0             0.0007558578987150177  2.711262282690854  0.0                              5.270692695954748e-08   5.064310856701214e-09  1.0               0.01388888888888884  2.638888888888889  0.0\n",
       "     2019-01-31 13:30:59  3 min 40.746 sec  351.0              2.1616404078110873e-09  6.55074370626418e-10    1.0             0.0007558578987150177  2.711262282690854  0.0                              5.6933233455319804e-08  5.336647081326041e-09  1.0               0.01388888888888884  2.638888888888889  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>features85_list_indices</td>\n",
       "<td>2386.1770020</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4569574</td></tr>\n",
       "<tr><td>features85_list_values</td>\n",
       "<td>1668.8812256</td>\n",
       "<td>0.6993954</td>\n",
       "<td>0.3195939</td></tr>\n",
       "<tr><td>kl_words</td>\n",
       "<td>580.0820923</td>\n",
       "<td>0.2431010</td>\n",
       "<td>0.1110868</td></tr>\n",
       "<tr><td>ks_words</td>\n",
       "<td>257.0541687</td>\n",
       "<td>0.1077264</td>\n",
       "<td>0.0492264</td></tr>\n",
       "<tr><td>ngramscounts7_list_values</td>\n",
       "<td>221.1662292</td>\n",
       "<td>0.0926864</td>\n",
       "<td>0.0423537</td></tr>\n",
       "<tr><td>entropy_words</td>\n",
       "<td>108.5201645</td>\n",
       "<td>0.0454787</td>\n",
       "<td>0.0207818</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                   relative_importance    scaled_importance    percentage\n",
       "-------------------------  ---------------------  -------------------  ------------\n",
       "features85_list_indices    2386.18                1                    0.456957\n",
       "features85_list_values     1668.88                0.699395             0.319594\n",
       "kl_words                   580.082                0.243101             0.111087\n",
       "ks_words                   257.054                0.107726             0.0492264\n",
       "ngramscounts7_list_values  221.166                0.0926864            0.0423537\n",
       "entropy_words              108.52                 0.0454787            0.0207818"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'H2OGradientBoostingEstimator' has no attribute 'metalearner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-401d11ca7ede>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Get the Stacked Ensemble metalearner model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmetalearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetalearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmetalearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-5.1.0.1/lib/python3.6/site-packages/h2o/utils/backward_compatibility.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bcin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Make sure that we look up any names not found on the instance also in the class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-5.1.0.1/lib/python3.6/site-packages/h2o/utils/backward_compatibility.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# print(\"Warning: Method %s in class %s is deprecated.\" % (name, cls.__name__))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'H2OGradientBoostingEstimator' has no attribute 'metalearner'"
     ]
    }
   ],
   "source": [
    "# Get model ids for all models in the AutoML Leaderboard\n",
    "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
    "\n",
    "print(model_ids)\n",
    "# Get the \"All Models\" Stacked Ensemble model\n",
    "se = h2o.get_model([mid for mid in model_ids if \"GBM\" in mid][0])\n",
    "print(se)\n",
    "\n",
    "# Get the Stacked Ensemble metalearner model\n",
    "metalearner = h2o.get_model(aml.leader.metalearner()['name'])\n",
    "metalearner.coef_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metalearner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-5a4538925986>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetalearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd_coef_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metalearner' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "metalearner.std_coef_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/siemanalyst/projects/logs-archive-production/fraud-canada-tokenizedwords/notebooks/product_model_bin/ngrams7_features85_vectors_m25/v5/mojo/GBM_grid_1_AutoML_20190131_132458_model_3.zip'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.download_mojo(path = \"./product_model_bin/ngrams7_features85_vectors_m25/v5/mojo\", get_genmodel_jar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>hash_message                                                                                                                    </th><th style=\"text-align: right;\">  fraud_label</th><th style=\"text-align: right;\">  kl_words</th><th style=\"text-align: right;\">  ks_words</th><th style=\"text-align: right;\">  entropy_words</th><th style=\"text-align: right;\">  features85_type</th><th style=\"text-align: right;\">  features85_size</th><th style=\"text-align: right;\">  ngramscounts7_type</th><th style=\"text-align: right;\">  ngramscounts7_size</th><th>features85_list_indices  </th><th>features85_list_values  </th><th>ngramscounts7_list_indices  </th><th>ngramscounts7_list_values  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>7ff628bb5dad0bc3bfaace8dcaf726381c929567fd826cab34bcb1105bf7163d46bd0fedff87bb7f862c65062c6f66d3e180bc017dd8bcb86b7f0f339cca7e49</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   3138.88</td><td style=\"text-align: right;\">0.821826  </td><td style=\"text-align: right;\">      0.078551 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
       " 26 27 28 29 30 31 32 33 34 36 40 41 42 43 44 45 46 55 57 60 63 64 73]                          </td><td>[2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      6      7      8    118    119\n",
       "    120    234    322    323    324    325    326    327    328    371\n",
       "    551    552    553    554    659    661    662    668    669    670\n",
       "    671    833    916    917    922   2099   4069   4072   4075   4078\n",
       "   4086   4094   4642 128603 154244 160075 189935 213892 223092 226684\n",
       " 237182 242787 243084 257059 259373]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>80f857718be06e2b40b853bca245aa2f837e3819078437c26f1d698066f3fb109b59a0c576124d19cf77ae4e84da945bf851a44ba51e1b7e5979f4b1743a269b</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   3329.22</td><td style=\"text-align: right;\">1         </td><td style=\"text-align: right;\">      0.0647077</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
       " 48 49 51 52 53 54 56 59 61 62 64 65]                          </td><td>[2. 2. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     12     13     14     15     16     17     18     32\n",
       "     33     34     45     46     47     48     49     50     51     52\n",
       "     53     54     66     67     68     69     70    303    304    536\n",
       "    537    538    539    540    742    759    760    761    825   1364\n",
       "   1367   1437   2438   3232   4499  22852  23023  23067  23271  23885\n",
       "  23986  24422  28670  28719  28815  29516  29863  30180  30888  31026\n",
       "  31316  31331  31824  32187  32268  32371  32423 168497 173647 186559]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>8304b24b1f8c03a69df330a2aa87776e29410e861b0fe6341c9ad39a3aeffcbb60fc0512edf219f2d222a2674955b6e6fbf9db39596c8e1643739f41c0e2be8f</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   6177.7 </td><td style=\"text-align: right;\">0.00655865</td><td style=\"text-align: right;\">      0.0662884</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 38 39 40 41 47 48 49 50 51 52 53 54 58\n",
       " 60 66 67 68 69 70 71 72 79 80]                          </td><td>[4. 2. 3. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      9     19     20     21\n",
       "     22     23     24     25     28     29     30     31     35     55\n",
       "     58     59     79     80     81     82     83     84     85     86\n",
       "     87     88     89     93     94     95     96     97     98     99\n",
       "    100    101    102    103    106    107    108    149    197    198\n",
       "    199    216    217    409    410    411 107715 114476 131663 141917\n",
       " 143900 252020]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>83ab14f4f479c67c6604658cca2ae22c4ddaad756aaff0dc31ee0b1d2c17760d4d1a987fc6b8a704c0a17e02b841955152eabfb2973c5c844072290462fa56d2</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   5679.1 </td><td style=\"text-align: right;\">0.0642194 </td><td style=\"text-align: right;\">      0.0708878</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 47 48 49 51 52 53\n",
       " 54 56 58 59 60 67 68 69 70 71 72 76 77 81 82 84]                          </td><td>[5. 2. 3. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      9     10     11     12\n",
       "     19     20     21     22     23     24     25     26     27     28\n",
       "     29     35     36     37     43     44    104    109    110    111\n",
       "    112    113    114    115    116    136    137    138    139    140\n",
       "    141    142    143    150    153    154    155    156    157    158\n",
       "    159    160    161    162    163    164    165    166    173    174\n",
       "    175    301    302    308  46741  46756  50450  52504  52912  59145\n",
       "  59637  88987 102725 124273 145654 239935]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>8501af76c1df0f17b32813227e7efb1ff66690fcb8d2e4aeb410218e2bf677479a7a98d91a7c068ea33dc23d95b897a3491e73cde06b34ba6e1cf3f84d2fcbb1</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   5502.12</td><td style=\"text-align: right;\">0.0524957 </td><td style=\"text-align: right;\">      0.0721789</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 47 48 49 51 52 53\n",
       " 54 56 59 60 63 65 67 68 69 70 71 72 76 77 79 81 82 84]                          </td><td>[4. 2. 3. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      9     10     11     12\n",
       "     13     14     15     16     17     18     19     20     21     22\n",
       "     23     24     25     26     27     28     29     30     35     36\n",
       "     37     43     44     56     57     60     61     62     63     64\n",
       "     65    109    110    111    112    113    114    115    116    389\n",
       "    390    391    392    393    394    395    396   4284   4832   4837\n",
       "   4864   4888  16424  16492  17155  17306  18204  18977  19067  19643\n",
       " 222071]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>87487ff3efc0e894b97b6fe6476242b9f9876790f7f6ff2071cfa9ad9b717bb6125ddbab279f8288c061eb6c4e343e45e960dd4a2cff34a819a9fb8c2a648b05</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   2555.14</td><td style=\"text-align: right;\">0.320446  </td><td style=\"text-align: right;\">      0.0781556</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
       " 25 26 27 28 29 30 31 32 33 34 36 40 41 42 43 44 45 46 55 60]                          </td><td>[1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[    0     1     2     3     4     6     7     8   235   236   237   238\n",
       "   550   772   773   774   775   776   777   778   779  1158  1159  1160\n",
       "  1161  1162  1163  3693  3694  3697 11381 44172 44914 45611 45771 46946\n",
       " 47304 48090 48541 49311 49614 51348 52936 53111 53251 53479 54059]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>88ada1a0c6826c40389a5688265c408cd01183cbd98f3c361be101b70099faf8049d048bbfe92b2b320bc48af45316091881f0797325b332551f7b1c8a0efce2</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   4978.05</td><td style=\"text-align: right;\">0.0575    </td><td style=\"text-align: right;\">      0.0628579</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
       " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 47 48 49 51 52 53 54\n",
       " 56 59 60 65 67 68 69 70 71 72 76 77 79 81 82 84]                          </td><td>[4. 2. 3. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[    0     1     2     3     4     5    12    13    14    15    19    20\n",
       "    21    22    23    24    25    26    27    30    36    37    43    44\n",
       "    56    57    62    63    64    65   109   110   111   112   113   114\n",
       "   115   116   211   245   246   385   386   387   389   390   391   392\n",
       "   393   394   395   396   419   420   506   625   626  2063  2144  2146\n",
       "  2147  4869  4877  4882 11067 11084 11113 11325 11568 36499 36947]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>8b655e8b3181dc87aeb49e8ce9348ca9bb84929e172292c671ab32b5bce1852592ba980798acd89e52e0e41da3befdc6a1ef98bf98a1d92b01e239516b42829b</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   4556.05</td><td style=\"text-align: right;\">0.418023  </td><td style=\"text-align: right;\">      0.0588851</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
       " 51 52 53 54 55 56 57 60 63 64 66 78 80]                          </td><td>[3. 2. 2. 3. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2.\n",
       " 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1.]                         </td><td>[    0     1     2     3     4     5     6     7     8     9    38    39\n",
       "    40    41    42    58    59    76    77    78    90    91    92   133\n",
       "   201   202   203   205   206   207   208   210   212   338   339   340\n",
       "   341   416   417   738  1073  1074  1075  1076  1077  1078  1079  1080\n",
       "  1081  1084  1085  1086  1087  1088  1090  2524  4099  4112  4114  4147\n",
       " 22878 66020 66233 66461 66946 69509 70935 72142 72150 72287 72984 73689\n",
       " 76530 76574 77684 78067 78089 78758 79728 79869 81175 83849]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>8b691e13e7211ccb3e02c0df2a9022c45e6c639f60ca8ffb4354152ab0c6aab2891af8e06165b395b59271d45feddb2f601eef72d9a48439f251952db95cfd64</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   3189.67</td><td style=\"text-align: right;\">0.748482  </td><td style=\"text-align: right;\">      0.0641655</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 51 52 53 54 55 56 57 63 65 83]                          </td><td>[2. 2. 2. 3. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1.]                         </td><td>[     0      1      2      3      4      5      6      7      8      9\n",
       "     10     11     13     14     15     16     17     18     38     39\n",
       "     40     41     42     66     67     68     69     70     76     77\n",
       "     78    177    178    179    180    181    182    204    287    291\n",
       "    292    303    304    377    378    379    380    381    382    576\n",
       "    577    578    579    580    607    608   1451   2194   9848  45545\n",
       "  47909  50319  52193  52382 112310 120984 121134 124231 125310 126824\n",
       " 128205 131509 137265 139691 144499 150609 150674 208477 242192 253675]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "<tr><td>8c80692a3319a417bef43be5d755db431cb10119339800b0dea6fff5d2342617e61c20b0e19009f090e8cac1df41247215c3394589d0f9b1bdb1c3f0b116f8e5</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   3650.27</td><td style=\"text-align: right;\">0.74681   </td><td style=\"text-align: right;\">      0.0720005</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">              262144</td><td>[ 0  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
       " 25 26 27 28 29 30 31 32 33 34 36 42 43 44 45 46 50 61 62 66 73 75 78 80]                          </td><td>[1. 4. 3. 1. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 3. 1. 1. 1. 1. 3. 1. 1.]                         </td><td>[     0      1      2      3      4      6      7      8     76     77\n",
       "     78    125    126    127    128    129    130    131    132    134\n",
       "    135    455    521    531    571    572    694    746    747    864\n",
       "    869    870   1798   1933   1935   1936   1937   1939   3729   4773\n",
       "  12531  69185  69605  71022  94386  96097 214065 217434 218729 220180\n",
       " 227939 229164 253131 253430 254864 256519 260369]                             </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1.]                            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">  p0</th><th style=\"text-align: right;\">         p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">2.51032e-11</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">2.43197e-11</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">3.43393e-13</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">9.69218e-12</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">5.20138e-11</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">6.69659e-12</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">1.26701e-11</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">1.46862e-10</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">1.46238e-12</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">2.00686e-10</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# If you need to generate predictions on a test set, you can make\n",
    "# predictions directly on the `\"H2OAutoML\"` object, or on the leader\n",
    "# model object directly\n",
    "\n",
    "#preds = aml.predict(test)\n",
    "# or:\n",
    "preds = aml.leader.predict(test)\n",
    "print(\"test\")\n",
    "print(test.tail(10))\n",
    "print(\"prediction\")\n",
    "print(preds.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |"
     ]
    }
   ],
   "source": [
    "# If you need to generate predictions on a test set, you can make\n",
    "# predictions directly on the `\"H2OAutoML\"` object, or on the leader\n",
    "# model object directly\n",
    "\n",
    "#preds = aml.predict(test)\n",
    "# or:\n",
    "preds_over_all_hf = aml.leader.predict(train)\n",
    "path_out_file=\"20190122\"\n",
    "output_pred_file=h2o.export_file(frame=preds_over_all_hf, path=path_out_file, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
