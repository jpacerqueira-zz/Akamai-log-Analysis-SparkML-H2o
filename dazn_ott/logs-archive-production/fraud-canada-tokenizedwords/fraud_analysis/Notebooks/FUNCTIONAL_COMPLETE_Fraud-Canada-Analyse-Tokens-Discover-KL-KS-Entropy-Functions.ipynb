{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- awsRegion: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- correlationId: string (nullable = true)\n",
      " |-- function_version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- hostname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- invoked_function_arn: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- level: long (nullable = true)\n",
      " |-- logGroup: string (nullable = true)\n",
      " |-- logStream: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messageType: string (nullable = true)\n",
      " |-- msg: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- owner: string (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- token: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- awsRegion: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- correlationId: string (nullable = true)\n",
      " |-- function_version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- hostname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- invoked_function_arn: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- level: long (nullable = true)\n",
      " |-- logGroup: string (nullable = true)\n",
      " |-- logStream: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messageType: string (nullable = true)\n",
      " |-- msg: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- owner: string (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- token: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- awsRegion: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- correlationId: string (nullable = true)\n",
      " |-- function_version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- hostname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- invoked_function_arn: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- level: long (nullable = true)\n",
      " |-- logGroup: string (nullable = true)\n",
      " |-- logStream: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messageType: string (nullable = true)\n",
      " |-- msg: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- owner: string (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- token: string (nullable = true)\n",
      " |-- messagecut: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messagecut: string (nullable = true)\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- message: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- @metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- @timestamp: string (nullable = true)\n",
      " |-- __logz_account_id: string (nullable = true)\n",
      " |-- __logz_received_timestamp: string (nullable = true)\n",
      " |-- __logzio_X-B3-Sampled: string (nullable = true)\n",
      " |-- __logzio_X-B3-SpanId: string (nullable = true)\n",
      " |-- __logzio_X-B3-TraceId: string (nullable = true)\n",
      " |-- __logzio_id: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messagecut: string (nullable = true)\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- message: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngrams_15: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- ngramscounts_15: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngrams_15: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- ngramscounts_15: vector (nullable = true)\n",
      " |-- features_85: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_15: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_15: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "Calculation of standard_fraud_ngram - Start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      "\n",
      "Value Print: standard_fraud_ngram=\n",
      "                                        hash_message\n",
      "0  deb7454c80749f06dc2cfc384c4b59fdb891965dbf1432...\n",
      "Calculation of standard_fraud_ngram - Done!\n",
      "Preparation of Data Done!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "#\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "#\n",
    "#import org.apache.spark.ml.feature.NGram\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from collections import Counter\n",
    "#\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from pyspark.ml.feature import NGram, CountVectorizer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "#\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "#\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "#\n",
    "#\n",
    "#\n",
    "# Ugly workarround to increase spark.kryoserializer.buffer.max\n",
    "# Only way in session to Run :\n",
    "#        - treeAggregate at RowMatrix.scala:122 \n",
    "#        - first at PCA.scala:43\n",
    "#\n",
    "sc = pyspark.SparkContext()\n",
    "#conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','2047mb'),('spark.driver.memory','23g'),('spark.driver.maxResultSize','21g')])\n",
    "conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','512mb')])\n",
    "sc.stop()\n",
    "sc = pyspark.SparkContext(conf=conf,appName=\"Notebook-FraudCanada-Model-NGrams-CountVectorizer-KL-KS-Entropy-Model-CleanData\")\n",
    "sqlContext = SQLContext(sc)\n",
    "#\n",
    "#\n",
    "# Arguments\n",
    "#\n",
    "#import argparse\n",
    "## Parse date_of execution\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"--datev1\", help=\"Execution Date\")\n",
    "#args = parser.parse_args()\n",
    "#if args.datev1:\n",
    "#    processdate = args.datev1\n",
    "# GENERAL PREPARATION SCRIPT\n",
    "#\n",
    "#  Date in format YYYYMMDD\n",
    "#process_date = processdate\n",
    "#if not process_date:\n",
    "#    process_date = \"20181231\"\n",
    "#\n",
    "process_date=\"20190122\"\n",
    "#\n",
    "input_file1_playback_fraud=\"hdfs:///data/staged/ott_dazn/fraud-canada-tokenizedwords/dt=*/*.json\"\n",
    "output_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-15-features-85/dt=\"+process_date\n",
    "#\n",
    "input_file2_playback_not_fraud=\"hdfs:///data/staged/ott_dazn/logs-archive-production/parquet/dt=\"+process_date+\"/*.parquet\"\n",
    "output_file2=\"hdfs:///data/staged/ott_dazn/advanced-model-data/not-fraud-canada-tokenizedwords/dt=\"+process_date\n",
    "input_file3=output_file2\n",
    "#\n",
    "input_file4=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-15-features-85/dt=\"+process_date+\"/*.*\"\n",
    "#\n",
    "output_most_frequent_df=\"hdfs:///data/staged/ott_dazn/advanced-model-data/the-most-frequent-fraud-hash_message/dt=\"+process_date\n",
    "#\n",
    "#  FILTER Non-Fraud AND LABEL\n",
    "from pyspark.sql import functions as F\n",
    "#\n",
    "#\n",
    "df2= sqlContext.read.parquet(input_file2_playback_not_fraud)\n",
    "df2.printSchema()\n",
    "#\n",
    "df3 = df2.filter(\" (message LIKE '%\\\"Url\\\":\\\"https://isl-ca.dazn.com/misl/v2/Playback%') AND (message LIKE '%,\\\"Response\\\":{\\\"StatusCode\\\":200,\\\"ReasonPhrase\\\":\\\"OK\\\",%') AND ( ( (message LIKE '%&Format=MPEG-DASH&%' OR message LIKE '%&Format=M3U&%') ) OR (message NOT LIKE '%\\\"User-Agent\\\":\\\"Mozilla/5.0,(Macintosh; Intel Mac OS X 10_12_6),AppleWebKit/605.1.75,(KHTML, like Gecko),Version/11.1.2,Safari/605.1.75\\\"},%')   )  \")\n",
    "df3.printSchema()\n",
    "df4 = df3.withColumn(\"messagecut\", expr(\"substring(message, locate('|Livesport.WebApi.Controllers.Playback.PlaybackV2Controller|',message)+60 , length(message)-1)\"))\n",
    "#\n",
    "# val regexTokenizer = new RegexTokenizer().setInputCol(\"messagecut\").setOutputCol(\"words\").setPattern(\"\\\\w+|\").setGaps(false)\n",
    "#\n",
    "regexTokenizer = RegexTokenizer(minTokenLength=1, gaps=False, pattern='\\\\w+|', inputCol=\"messagecut\", outputCol=\"words\", toLowercase=True)\n",
    "#\n",
    "tokenized = regexTokenizer.transform(df4)\n",
    "tokenized.printSchema()\n",
    "tokenized.coalesce(1).write.json(output_file2)\n",
    "# Tokenize NON-Fraud-LABEL\n",
    "# hash the message de-duplicate those records\n",
    "notfraud_file=sqlContext.read.json(input_file3)\n",
    "notfraud_file.printSchema()\n",
    "#\n",
    "notfraud_df=notfraud_file\\\n",
    ".filter(\"message IS NOT NULL\").filter(\"words IS NOT NULL\")\\\n",
    ".withColumn('fraud_label',lit(0).cast('int'))\\\n",
    ".withColumn('hash_message',F.sha2(col('message'),512)).groupby(col('hash_message'))\\\n",
    ".agg(F.first(col('fraud_label')).alias('fraud_label'),F.first(col('words')).alias('words'),F.first(col('message')).alias('message'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "notfraud_df.printSchema()\n",
    "#\n",
    "df_notfraud_words = notfraud_df.filter(\"message IS NOT NULL\").select(col('fraud_label'),col('hash_message'),col('words'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "df_notfraud_words.printSchema()\n",
    "#\n",
    "# FILTER FRAUD AND LABEL \n",
    "# Join with Internal Curation Data in urltopredict staged folder\n",
    "# hash the message de-duplicate those records\n",
    "fraud_file=sqlContext.read.json(input_file1_playback_fraud)\n",
    "fraud_file.printSchema()\n",
    "#\n",
    "fraud_df=fraud_file\\\n",
    ".filter(\"message IS NOT NULL\").filter(\"words IS NOT NULL\")\\\n",
    ".withColumn('fraud_label',lit(1).cast('int'))\\\n",
    ".withColumn('hash_message',F.sha2(col('message'),512)).groupby(col('hash_message'))\\\n",
    ".agg(F.first(col('fraud_label')).alias('fraud_label'),F.first(col('words')).alias('words'),F.first(col('message')).alias('message'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "fraud_df.printSchema()\n",
    "#\n",
    "df_words = fraud_df.filter(\"message IS NOT NULL\").select(col('fraud_label'),col('hash_message'),col('words'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "df_words.printSchema()\n",
    "#\n",
    "result_fraud_nofraud_words = df_words.union(df_notfraud_words)\n",
    "## Register Generic Functions\n",
    "# -----------------------------------------------------------------------------\n",
    "# Build ngrams 75 90 n=6 \n",
    "# support : https://stackoverflow.com/questions/51473703/pyspark-ml-ngrams-countvectorizer-sorted-based-on-count-weights\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_ngrams_part(inputCol=\"words\", n=6):\n",
    "    ngrams = [ \n",
    "        NGram(n=i, inputCol=\"words\", outputCol=\"ngrams_{0}\".format(i)) \n",
    "        for i in range(75, n + 1) ]\n",
    "    vectorizers = [ \n",
    "        CountVectorizer(inputCol=\"ngrams_{0}\".format(i), outputCol=\"ngramscounts_{0}\".format(i)) \n",
    "        for i in range(75, n + 1) ]\n",
    "    return Pipeline(stages=ngrams + vectorizers)\n",
    "#    assembler = [VectorAssembler( inputCols=[\"ngramscounts_{0}\".format(i) for i in range(1, n + 1)], outputCol=\"features\" )]\n",
    "#    return Pipeline(stages=ngrams + DenseVector(SparseVector(vectorizers).toArray()))\n",
    "#\n",
    "# \n",
    "# -----------------------------------------------------------------------------\n",
    "#ngram = build_ngrams_part().fit(df_words)\n",
    "#ngramDataFrame = ngram.transform(df_words)\n",
    "#ngramDataFrame.coalesce(1).write.json(output_file1)\n",
    "#\n",
    "ngram = NGram(n=15, inputCol=\"words\", outputCol=\"ngrams_15\")\n",
    "countvector = CountVectorizer(inputCol=\"ngrams_15\", outputCol=\"ngramscounts_15\")\n",
    "# fit a CountVectorizerModel from the corpus.\n",
    "countvModel = CountVectorizer(inputCol=\"words\", outputCol=\"features_85\", vocabSize=85, minDF=2.0)\n",
    "# fit a PCA Dimensionality reduction into 75/15=5 components from ngramscounts_75 ## Too Heavy 1st PCA\n",
    "pcaNgrams = PCA(k=5, inputCol=\"ngramscounts_15\", outputCol=\"pcaweightngrams\")\n",
    "# fit a PCA Dimensionality reduction into 75/15=5 components from words\n",
    "pcaWords = PCA(k=5, inputCol=\"features_85\", outputCol=\"pcaweightwords\")  ## Too Heavy 2nd PCA\n",
    "#\n",
    "ngram_fraud_DF = ngram.transform(result_fraud_nofraud_words)\n",
    "ngram_vc_fraud_DF = countvector.fit(ngram_fraud_DF).transform(ngram_fraud_DF)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "ngram_vc_fraud_DF.printSchema()\n",
    "#\n",
    "#modelPCA_ngram_fraud_DF = pcaNgrams.fit(ngram_vc_fraud_DF).transform(ngram_vc_fraud_DF)\\\n",
    "#.persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "#modelPCA_ngram_fraud_DF.printSchema()\n",
    "#\n",
    "#result_ngrams_words_fraud_DF = countvModel.fit(modelPCA_ngram_fraud_DF).transform(modelPCA_ngram_fraud_DF)\\\n",
    "result_ngrams_words_fraud_DF = countvModel.fit(ngram_vc_fraud_DF).transform(ngram_vc_fraud_DF)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "result_ngrams_words_fraud_DF.printSchema()\n",
    "#\n",
    "result_ngrams_words_fraud_DF.coalesce(1).write.json(output_file1)\n",
    "#\n",
    "#  CALCULATE KL,KS COEF. Label Data\n",
    "ngram15_fraud=sqlContext.read.json(input_file4).filter(\"fraud_label=0\" )\n",
    "ngram15_fraud.printSchema()\n",
    "#\n",
    "print(\"Calculation of standard_fraud_ngram - Start!\")\n",
    "#\n",
    "# Obtain the most frequent word on each position \n",
    "# Compose the standard_fraud_ngram from the most common positions\n",
    "# Calculate the standard_fraud_ngram\n",
    "#\n",
    "# https://stackoverflow.com/questions/35218882/find-maximum-row-per-group-in-spark-dataframe \n",
    "# Using struct ordering:\n",
    "#from pyspark.sql.functions import struct\n",
    "#\n",
    "#(cnts\n",
    "#  .groupBy(\"id_sa\")\n",
    "#  .agg(F.max(struct(col(\"cnt\"), col(\"id_sb\"))).alias(\"max\"))\n",
    "#  .select(col(\"id_sa\"), col(\"max.id_sb\")))\n",
    "#\n",
    "#Py4JJavaError: An error occurred while calling o3400.select.\n",
    "#: org.apache.spark.sql.AnalysisException: cannot resolve '`ngrams`' given input columns: [mostfrequent];;\n",
    "#'Project ['ngrams, mostfrequent#8033.count AS count#8037L]\n",
    "#+- AnalysisBarrier\n",
    "#      +- Aggregate [max(named_struct(count, count#8029L)) AS mostfrequent#8033]\n",
    "#         +- Aggregate [ngrams#8016], [ngrams#8016, count(1) AS count#8029L]\n",
    "#            +- Relation[fraud_label#8013L,hash_message#8014,message#8075,ngrams#8016,words#8017] json\n",
    "#\n",
    "####### OLD  ######\n",
    "#.groupby(col('hash_message'))\\\n",
    "#.agg(F.first(col('features_75')).alias('features_75'),\\\n",
    "#     F.first(col('fraud_label')).alias('fraud_label'),\\\n",
    "#     F.first(col('ngrams_75')).alias('ngrams_75'),\\\n",
    "#     F.first(col('ngramscounts_75')).alias('ngramscounts_75'),F.first(col('words')).alias('words'))\n",
    "####################\n",
    "#\n",
    "most_frequent_df=ngram15_fraud\\\n",
    ".withColumn(\"value_sum\",F.explode(\"ngramscounts_15.values\"))\\\n",
    ".groupBy(\"hash_message\").agg(F.sum(\"value_sum\").alias('count'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "most_frequent_df.printSchema()\n",
    "#\n",
    "most_frequent_df.coalesce(1).write.json(output_most_frequent_df)\n",
    "#\n",
    "# The most Frequent would the the max\n",
    "standard_fraud_ngram=most_frequent_df.orderBy(col('count').desc()).select(col('hash_message')).limit(1).toPandas()\n",
    "#\n",
    "print(\"Value Print: standard_fraud_ngram=\")\n",
    "print(standard_fraud_ngram)\n",
    "#\n",
    "print(\"Calculation of standard_fraud_ngram - Done!\")\n",
    "#\n",
    "sc.stop()\n",
    "#\n",
    "print(\"Preparation of Data Done!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value UDF : standard_fraud_ngram=\n",
      "c9b49b5510dc0c1f48de5a2b9e2d94682902ea27525fec5d9c6cd176dd7bdb59e2ff6c21a6823ed83de3e19770eebb415589e71bdbc62ff7b1a7f1b69fbe5637\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_15: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_15: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_15: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_15: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- fraud_master_hash: string (nullable = false)\n",
      "\n",
      "Value UDF : standard_words=\n",
      "c9b49b5510dc0c1f48de5a2b9e2d94682902ea27525fec5d9c6cd176dd7bdb59e2ff6c21a6823ed83de3e19770eebb415589e71bdbc62ff7b1a7f1b69fbe5637\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_15: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_15: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngramscounts_15: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words_conc: string (nullable = false)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- entropy_words: double (nullable = true)\n",
      "\n",
      "Model Data KL,KS, Entropy Done! NGrams Vectors Data Done!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "#\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "#\n",
    "#import org.apache.spark.ml.feature.NGram\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from collections import Counter\n",
    "#\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from pyspark.ml.feature import NGram, CountVectorizer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "#\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "#\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "#\n",
    "#  FILTER with PySpark SQL Functions F.\n",
    "from pyspark.sql import functions as F\n",
    "# FUNCTIONS\n",
    "# \n",
    "##\n",
    "## Register Generic UDF Functions\n",
    "# -----------------------------------------------------------------------------\n",
    "# KL : Kullback-Leibler Divergence\n",
    "# KS : Kolmogorov-Smirnov ( Sample sizes can be different)\n",
    "# -----------------------------------------------------------------------------    \n",
    "## NGRAM hash_mesage KL from URL TO Default NGRAM KL\n",
    "def func_kl_ngram_msg(var1,var_match):\n",
    "    ##Making sure the analysis of has_message SHA_512 is linear.\n",
    "    ##Making sure the analysis is over the words list on same size\n",
    "    def KL(P,Q):\n",
    "        epsilon = 0.00001\n",
    "        P = P+epsilon\n",
    "        Q = Q+epsilon\n",
    "        divergence = np.sum(P*np.log(P/Q))\n",
    "        return np.asscalar(divergence)\n",
    "    ##Making sure the analysis ignore trash\n",
    "    cleanvar=var1.strip('http://').strip('https://').strip('www.')\n",
    "    len_var1=len(cleanvar)\n",
    "    idx_var1=cleanvar[:4]# Use \"root1\" as baseline #cleanvar.split(\"/\")[0]#cleanvar[:8]\n",
    "    list_values1 = list(cleanvar)\n",
    "    list_of_ord_values1 = [ord(char) for char in list_values1]\n",
    "    values1 = np.asarray(list_of_ord_values1)\n",
    "    # URLS with at least 4166 characters\n",
    "    ## TODO : Complete this list with common Malware/phishing sites used in internal webtraffic\n",
    "    list_values2 = var_match\n",
    "    list_values2 += var_match\n",
    "    ## Making sure the analysis start on the same webdomain name\n",
    "    idx_var2 = list_values2.find(idx_var1)\n",
    "    start_values2 = list_values2[idx_var2:(idx_var2+len_var1)]\n",
    "    list_values2 = list(start_values2+list_values2)\n",
    "    list_values2 = list_values2[:len_var1]\n",
    "    list_of_ord_values2 = [ord(char) for char in list_values2]\n",
    "    values2 = np.asarray(list_of_ord_values2)\n",
    "    return KL(values1,values2)\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "## NGRAM hash_message \"Kolmogorov-Smirnov test KS pvalue= ks_2samp function8.\n",
    "def func_ks_ngram_msg(var1,var_match):\n",
    "    ##Making sure the analysis of has_message SHA_512 is linear.\n",
    "    ##Making sure the analysis is over the words list on same size\n",
    "    cleanvar=var1.strip('http://').strip('https://').strip('www.')\n",
    "    len_var1=len(cleanvar)\n",
    "    idx_var1=cleanvar[:4]# Use \"root1\" as baseline #cleanvar.split(\"/\")[0]#cleanvar[:8]\n",
    "    list_values1 = list(cleanvar)\n",
    "    list_of_ord_values1 = [ord(char) for char in list_values1]\n",
    "    values1 = np.asarray(list_of_ord_values1)\n",
    "    values1= np.sort(values1)\n",
    "    # URLS with up to least 4166 characters\n",
    "    list_values2 = var_match\n",
    "    list_values2 += var_match\n",
    "    ## Making sure the analysis start on the same messgae\n",
    "    idx_var2 = list_values2.find(idx_var1)\n",
    "    start_values2 = list_values2[idx_var2:(idx_var2+len_var1)]\n",
    "    list_values2 = list(start_values2+list_values2)\n",
    "    list_values2 = list_values2[:len_var1]\n",
    "    list_of_ord_values2 = [ord(char) for char in list_values2]\n",
    "    values2 = np.asarray(list_of_ord_values2)\n",
    "    values2=np.sort(values2)\n",
    "    (Darray,pvalue)=stats.ks_2samp(values1, values2)\n",
    "    return np.asscalar(pvalue)\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "## Entropy TO hash_message function3.\n",
    "def func_entropy_ngram_msg(var1,var_match):\n",
    "    ##Making sure the analysis of has_message SHA_512 is linear.\n",
    "    ##Making sure the analysis is over the words list ignore size\n",
    "    #\n",
    "    cleanvar=var1.strip('http://').strip('https://').strip('www.')\n",
    "    len_var1=len(cleanvar)\n",
    "    idx_var1=cleanvar[:4]# Use \"root1\" as baseline #cleanvar.split(\"/\")[0]#cleanvar[:8]\n",
    "    list_values1 = list(cleanvar)\n",
    "    list_of_ord_values1 = [ord(char) for char in list_values1]\n",
    "    values1 = np.asarray(list_of_ord_values1)\n",
    "    # URLS with at least 4166 characters\n",
    "    ## TODO : Complete this list with an NGRAM search\n",
    "    list_values2 = var_match\n",
    "    list_values2 += var_match\n",
    "    ## Making sure the analysis start on point\n",
    "    idx_var2 = list_values2.find(idx_var1)\n",
    "    start_values2 = list_values2[idx_var2:(idx_var2+len_var1)]\n",
    "    list_values2 = list(start_values2+list_values2)\n",
    "    list_values2 = list_values2[:len_var1]\n",
    "    list_of_ord_values2 = [ord(char) for char in list_values2]\n",
    "    values2 = np.asarray(list_of_ord_values2)\n",
    "    pvalue=stats.entropy(values1, values2)\n",
    "    scalar_pvalue=np.asscalar(pvalue)\n",
    "    return scalar_pvalue\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "func_kl_ngram_msg_udf = udf(func_kl_ngram_msg, FloatType())\n",
    "func_ks_ngram_msg_udf = udf(func_ks_ngram_msg, FloatType())\n",
    "func_entropy_ngram_msg_udf = udf(func_entropy_ngram_msg, FloatType())\n",
    "#\n",
    "# Arguments\n",
    "#\n",
    "import argparse\n",
    "## Parse date_of execution\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"--datev1\", help=\"Execution Date\")\n",
    "#args = parser.parse_args()\n",
    "#if args.datev1:\n",
    "#    processdate = args.datev1\n",
    "# GENERAL PREPARATION SCRIPT\n",
    "#\n",
    "#  Date in format YYYYMMDD\n",
    "#process_date = processdate\n",
    "#if not process_date:\n",
    "#    process_date = \"20181231\"\n",
    "#\n",
    "process_date=\"20190122\"\n",
    "#\n",
    "#\n",
    "sc = pyspark.SparkContext()\n",
    "#conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','2047mb'),('spark.driver.memory','23g'),('spark.driver.maxResultSize','21g')])\n",
    "conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','512mb')])\n",
    "sc.stop()\n",
    "sc.stop()\n",
    "sc = pyspark.SparkContext(conf=conf,appName=\"Notebook-FraudCanada-Model-NGrams-CountVectorizer-KL-KS-Entropy-Model-Labeling\")\n",
    "sqlContext = SQLContext(sc)\n",
    "# Clean up the cluster just in case\n",
    "h2o.remove_all()\n",
    "#\n",
    "input_most_frequent_df=\"hdfs:///data/staged/ott_dazn/advanced-model-data/the-most-frequent-fraud-hash_message/dt=\"+process_date\n",
    "input_fraud=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-15-features-85/dt=\"+process_date\n",
    "#\n",
    "input_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-15-features-85/dt=\"+process_date\n",
    "output_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/label-fraud-notfraud-data-model/dt=\"+process_date\n",
    "preserve_training_output_file=\"hdfs:///data/staged/ott_dazn/advanced-model-data/preserve-training-output-automl-clean/dt=\"+process_date\n",
    "#\n",
    "# The most Frequent would the ones with the max frequency of NGrams85 tokens\n",
    "pd.options.display.max_colwidth = 512\n",
    "#\n",
    "standard_fraud_ngram=sqlContext.read.json(input_most_frequent_df)\\\n",
    ".orderBy(col('count').desc()).select(col('hash_message')).limit(1).toPandas()['hash_message'][0]\n",
    "print(\"Value UDF : standard_fraud_ngram=\")\n",
    "print(standard_fraud_ngram)\n",
    "#\n",
    "# Select Tokens/words form the max frequency of NGrams85 tokens hash_message\n",
    "standard_fraud_ngram_words=sqlContext.read.json(input_fraud)\n",
    "standard_fraud_ngram_words.printSchema()\n",
    "#\n",
    "standard_words_search=standard_fraud_ngram_words\\\n",
    ".withColumn('fraud_master_hash',lit(standard_fraud_ngram).cast('string'))\\\n",
    ".filter(\" hash_message=fraud_master_hash \")\n",
    "standard_words_search.printSchema()\n",
    "#\n",
    "standard_words=standard_words_search\\\n",
    ".withColumn('words_conc',F.concat_ws('',col('words')).cast('string'))\\\n",
    ".select(col('words_conc')).limit(1).toPandas()['words_conc'][0] \n",
    "# Working now! \n",
    "# Needs to be bigger than message twice should be tested!\n",
    "#   Py4JJavaError: An error occurred while calling z:org.apache.spark.sql.functions.lit.\n",
    "#      : java.lang.RuntimeException: Unsupported literal type class java.util.HashMap \n",
    "# {0=root15c466c8e6e8f9d17adb73426cd55c70f72b9f18e39e3455c9043a18b86b122b6requestmethodgeturlhttpsislcadazncommislv2playbackassetidfg5oon8sl71n1nfwuegbo8npgeventidarticleidfg5oon8sl71n1nfwuegbo8npgformatmpegdashplayeriddaznf3874e050812a853securetruelanguagecodeenlatitudenulllongitudenullplatformandroidtvmanufacturernvidiamodelnullmtalanguagecodeenclientip50100225179headersuseragentmozilla50linuxandroid800shieldandroidtvbuildopr6170623010wvapplewebkit53736khtmllikegeckoversion40chrome710357899mobilesafari53736fev1420typeinresponsestatuscode200reasonphraseokduration47jwtvieweridc2ebc25d8085deviceid993bf365c72c4b0b9168c2ebc25d8085f3874e050812a853userstatusactivepaid}\n",
    "#\n",
    "print(\"Value UDF : standard_words=\")\n",
    "print(standard_fraud_ngram)\n",
    "#\n",
    "ngram15_fraud=sqlContext.read.json(input_file1)\n",
    "ngram15_fraud.printSchema()\n",
    "#\n",
    "drop_phish_cols=['words','ngrams_15']\n",
    "#\n",
    "fraud_label_read_df=ngram15_fraud.filter(\"hash_message is not NULL\")\\\n",
    ".withColumn('words_conc',F.concat_ws('',col('words')).cast('string'))\\\n",
    "    .drop(*drop_phish_cols)\\\n",
    "    .withColumn('kl_words',func_kl_ngram_msg_udf(col('words_conc'),lit(standard_words).cast('string')).cast('double'))\\\n",
    "    .withColumn('ks_words',func_ks_ngram_msg_udf(col('words_conc'),lit(standard_words).cast('string')).cast('double'))\\\n",
    "    .withColumn('entropy_words',func_entropy_ngram_msg_udf(col('words_conc'),lit(standard_words).cast('string')).cast('double'))\\\n",
    "    .persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "fraud_label_read_df.printSchema()\n",
    "#\n",
    "fraud_label_read_df.coalesce(1).write.json(output_file1)\n",
    "#\n",
    "fraud_label_read_df.unpersist()\n",
    "#\n",
    "sc.stop()\n",
    "#\n",
    "print(\"Model Data KL,KS, Entropy Done! NGrams Vectors Data Done!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>7 days 7 hours 57 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.1</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>3 months and 4 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_siemanalyst_f03p4d</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>5.023 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.4 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         7 days 7 hours 57 mins\n",
       "H2O cluster timezone:       UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.1\n",
       "H2O cluster version age:    3 months and 4 days\n",
       "H2O cluster name:           H2O_from_python_siemanalyst_f03p4d\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    5.023 Gb\n",
       "H2O cluster total cores:    12\n",
       "H2O cluster allowed cores:  12\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.4 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training Model NGrams Vectors KS KL Entropty\n",
      "root\n",
      " |-- entropy_words: double (nullable = true)\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- ngramscounts_15: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words_conc: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- entropy_words: double (nullable = true)\n",
      " |-- features85_type: long (nullable = true)\n",
      " |-- features85_size: long (nullable = true)\n",
      " |-- features85_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- features85_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- ngramscounts15_type: long (nullable = true)\n",
      " |-- ngramscounts15_size: long (nullable = true)\n",
      " |-- ngramscounts15_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- ngramscounts15_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- entropy_words: double (nullable = true)\n",
      " |-- features85_type: long (nullable = true)\n",
      " |-- features85_size: long (nullable = true)\n",
      " |-- features85_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- features85_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- ngramscounts15_type: long (nullable = true)\n",
      " |-- ngramscounts15_size: long (nullable = true)\n",
      " |-- ngramscounts15_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- ngramscounts15_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- entropy_words: double (nullable = true)\n",
      " |-- features85_type: long (nullable = true)\n",
      " |-- features85_size: long (nullable = true)\n",
      " |-- features85_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- features85_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- ngramscounts15_type: long (nullable = true)\n",
      " |-- ngramscounts15_size: long (nullable = true)\n",
      " |-- ngramscounts15_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- ngramscounts15_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>hash_message                                                                                                                    </th><th style=\"text-align: right;\">  fraud_label</th><th style=\"text-align: right;\">  kl_words</th><th style=\"text-align: right;\">  ks_words</th><th style=\"text-align: right;\">  entropy_words</th><th style=\"text-align: right;\">  features85_type</th><th style=\"text-align: right;\">  features85_size</th><th style=\"text-align: right;\">  ngramscounts15_type</th><th style=\"text-align: right;\">  ngramscounts15_size</th><th>features85_list_indices  </th><th>features85_list_values  </th><th>ngramscounts15_list_indices  </th><th>ngramscounts15_list_values  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>589ff83a30fa5d82563f0051bbd9f638d3dc7f102f8c78ab137c17b859e740de35348417e0deb2037cd0188c243c674100eb57f97450c4b942c9d3a1ef86a07b</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4446.55</td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.0719711</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   2470   2735   3693\n",
       "   3764  36147  37143  37419  37711  38564  40263  54086 126340 135455\n",
       " 156927 193991 197546 197841 202865 205302 207492 208360 217507 218422\n",
       " 226659 239341 240569 246870]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>865fc00f8a94dd1c467c39753bfb2b18626f2827db85a05654caf048e657b6856afad3fef87873197e7f92e0ff760c8f04cd5484c910a037476643addfdb5c31</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   3287.65</td><td style=\"text-align: right;\">  0.947901</td><td style=\"text-align: right;\">      0.0696592</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284    746    822   1088\n",
       "   1854   7730   7735   7778   7808   7809   7814   7838   7872   7930\n",
       "   7935  14872  79502  82612 186447 194478 196889 198437 199717 208120\n",
       " 208331 214821 220456 221302 221526 222588 224016 231721 232821 234003\n",
       " 235173 240449 241239 242109 245164 246700 246748 248632 254896 257357\n",
       " 257450 259557]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>a659ae2c8efbde6eb990b90acae3e02f644e44cd1a3a9aa6490632209641eb5714bb4b740ddcbe95e50b5cd319a8725634ffea38ae633fd6ab1f7114ad8c17bd</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4169.68</td><td style=\"text-align: right;\">  0.52636 </td><td style=\"text-align: right;\">      0.0708245</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   3362  60557  69076\n",
       " 124379 197626 200410 200494 205837 218883 227283 229369 240735 240954\n",
       " 249778 255226]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>d6d7bcd45dfa2fb6487352a532359f3f64afe250dacb422898ed9854af8992866bff17dac83f36763b46f2db2e0442fdf23fafdd58628636ca3395b6ef019a16</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4538.96</td><td style=\"text-align: right;\">  0.210665</td><td style=\"text-align: right;\">      0.0757622</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   7253  32369  33820\n",
       "  88300  99401 100951 105511 127809 131543 131649 134219 137596 140394\n",
       " 141193 142373 145485 145729 153068 153992 155860 155919 158762 159310\n",
       " 160557 161212 165997 167110 167685 174858 176679 178410 179476 184686\n",
       " 190025]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>da23c7d6b5dd13228bb9b8e5d3287463ca7b12fbc8a5c068ce2cf4ca3e7e89ca6990a4abfc69dcedd538ee916f64a8d5d0440d1ad309c9604efc9ad4074a81ed</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4378.87</td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.077328 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284    746    822   1088\n",
       "   1149   5578   7253   8314   8323   8397   8425   8428   8593  18273\n",
       "  19204  26918  27068  27332  27919  27991  28156  28296  28380  28412\n",
       "  28952  29015  29041  29403  29405  98084  99873 100375 101619 102460\n",
       " 103277 107156 108692 110004 110158 112115 115060 116522 119369 120568\n",
       " 123239]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>980071f323752c9f7e987d2f657d244851b601c46ef50b2cd053d69ee9c3a7b413730fff5a68bea2dd9ada49d410f0c0f8165ad2a9096c2c419668df2b829de3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4222.18</td><td style=\"text-align: right;\">  0.523838</td><td style=\"text-align: right;\">      0.0740113</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 38 39 40 41 42 43 44 45 46 47 48\n",
       " 49 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   1780   6964   8267\n",
       "  13288  19547  67596  68543 106236 134459 138290 153693 162050 167036\n",
       " 178195 194296 198255 211624 213658 216527 218287 221815 222537 225699\n",
       " 242637 243896 244686 245816]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>e38e2712270ef1f79716537aa2816eaab104a20e17c94df57b49b787cda6f8e96794acf70b302c9708e9573dda18e402c7e996ea14e537e736001b12070d7542</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4279.72</td><td style=\"text-align: right;\">  0.679739</td><td style=\"text-align: right;\">      0.0711178</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   3749   9036  34285\n",
       "  34469  48737  50620  51165  56786 138543 140698 147456 150909 152545\n",
       " 153462 157813 166319 167113 167404 171492 172849 175007 176099 181215\n",
       " 191663 197526 202991 203690 210273 210642 211331 213296 225240 232933\n",
       " 236100 236152 236967 238367 246778 249963 250489 253180 254626 259157\n",
       " 260686]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>26f328150124298822fc4a0be849251c3d3545dcb2495c71dc92a60d1629ea641ec4d24c7004a3d579df61f5ba7197ffe6e88e3efaee93d226270372ee87d4b2</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4375.28</td><td style=\"text-align: right;\">  0.386449</td><td style=\"text-align: right;\">      0.0745828</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[  213   214   215   216   217   218   219   220   221   222   223   224\n",
       "   225   226   227   271   272   273   274   275   276   279   280   281\n",
       "   282   283   284   746   822  1088  1149  1780  5036  5047  5048  5061\n",
       "  5072  5081 25558 26463 26526 26586 26779 26806 26872 27695 27696 27705\n",
       " 27946 28786 29147 29478 29515 30180 30227 80288 90884]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>2b8a2419e7f2c6fecb549146c3d66ab9cae9839005d8f848d39313e49b34d22c18c6eb7e20b3b0c5291d4ad0f7f2b329423816423f62a40a7dae70870c2b7f9f</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4396.63</td><td style=\"text-align: right;\">  0.430514</td><td style=\"text-align: right;\">      0.0760735</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284  37539  39230  48737\n",
       "  50317  50620  51165  54086  56786 136103 138338 146222 150118 155432\n",
       " 159786 168532 168885 173914 176279 181552 183110 184567 189142 203690\n",
       " 236100 236967 238367 246778 259157]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>67d469882a190b2d6262a34bcca389d43799a46e823c51da3c685150a32c5779132915cfd6cc965db7d7f92639dd725dad1e29d2f69598d63cdf1402d2fa66b3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4478.26</td><td style=\"text-align: right;\">  0.307116</td><td style=\"text-align: right;\">      0.073295 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284  10989  15232  30288\n",
       "  35120  35398  35501  36039  36588  36629  36995  37039  38659  38832\n",
       "  38914  39203  40955  41119  41228  41930  45675  98646  99563 100217\n",
       " 100989 101877 104876 104964 106194 116195 122133 122201 123031 125489\n",
       " 125649 162602 223741]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>hash_message                                                                                                                    </th><th style=\"text-align: right;\">  fraud_label</th><th style=\"text-align: right;\">  kl_words</th><th style=\"text-align: right;\">  ks_words</th><th style=\"text-align: right;\">  entropy_words</th><th style=\"text-align: right;\">  features85_type</th><th style=\"text-align: right;\">  features85_size</th><th style=\"text-align: right;\">  ngramscounts15_type</th><th style=\"text-align: right;\">  ngramscounts15_size</th><th>features85_list_indices  </th><th>features85_list_values  </th><th>ngramscounts15_list_indices  </th><th>ngramscounts15_list_values  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>589ff83a30fa5d82563f0051bbd9f638d3dc7f102f8c78ab137c17b859e740de35348417e0deb2037cd0188c243c674100eb57f97450c4b942c9d3a1ef86a07b</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4446.55</td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.0719711</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   2470   2735   3693\n",
       "   3764  36147  37143  37419  37711  38564  40263  54086 126340 135455\n",
       " 156927 193991 197546 197841 202865 205302 207492 208360 217507 218422\n",
       " 226659 239341 240569 246870]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>865fc00f8a94dd1c467c39753bfb2b18626f2827db85a05654caf048e657b6856afad3fef87873197e7f92e0ff760c8f04cd5484c910a037476643addfdb5c31</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   3287.65</td><td style=\"text-align: right;\">  0.947901</td><td style=\"text-align: right;\">      0.0696592</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284    746    822   1088\n",
       "   1854   7730   7735   7778   7808   7809   7814   7838   7872   7930\n",
       "   7935  14872  79502  82612 186447 194478 196889 198437 199717 208120\n",
       " 208331 214821 220456 221302 221526 222588 224016 231721 232821 234003\n",
       " 235173 240449 241239 242109 245164 246700 246748 248632 254896 257357\n",
       " 257450 259557]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>a659ae2c8efbde6eb990b90acae3e02f644e44cd1a3a9aa6490632209641eb5714bb4b740ddcbe95e50b5cd319a8725634ffea38ae633fd6ab1f7114ad8c17bd</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4169.68</td><td style=\"text-align: right;\">  0.52636 </td><td style=\"text-align: right;\">      0.0708245</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   3362  60557  69076\n",
       " 124379 197626 200410 200494 205837 218883 227283 229369 240735 240954\n",
       " 249778 255226]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>d6d7bcd45dfa2fb6487352a532359f3f64afe250dacb422898ed9854af8992866bff17dac83f36763b46f2db2e0442fdf23fafdd58628636ca3395b6ef019a16</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4538.96</td><td style=\"text-align: right;\">  0.210665</td><td style=\"text-align: right;\">      0.0757622</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   7253  32369  33820\n",
       "  88300  99401 100951 105511 127809 131543 131649 134219 137596 140394\n",
       " 141193 142373 145485 145729 153068 153992 155860 155919 158762 159310\n",
       " 160557 161212 165997 167110 167685 174858 176679 178410 179476 184686\n",
       " 190025]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>da23c7d6b5dd13228bb9b8e5d3287463ca7b12fbc8a5c068ce2cf4ca3e7e89ca6990a4abfc69dcedd538ee916f64a8d5d0440d1ad309c9604efc9ad4074a81ed</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4378.87</td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.077328 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284    746    822   1088\n",
       "   1149   5578   7253   8314   8323   8397   8425   8428   8593  18273\n",
       "  19204  26918  27068  27332  27919  27991  28156  28296  28380  28412\n",
       "  28952  29015  29041  29403  29405  98084  99873 100375 101619 102460\n",
       " 103277 107156 108692 110004 110158 112115 115060 116522 119369 120568\n",
       " 123239]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>980071f323752c9f7e987d2f657d244851b601c46ef50b2cd053d69ee9c3a7b413730fff5a68bea2dd9ada49d410f0c0f8165ad2a9096c2c419668df2b829de3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4222.18</td><td style=\"text-align: right;\">  0.523838</td><td style=\"text-align: right;\">      0.0740113</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 38 39 40 41 42 43 44 45 46 47 48\n",
       " 49 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   1780   6964   8267\n",
       "  13288  19547  67596  68543 106236 134459 138290 153693 162050 167036\n",
       " 178195 194296 198255 211624 213658 216527 218287 221815 222537 225699\n",
       " 242637 243896 244686 245816]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>e38e2712270ef1f79716537aa2816eaab104a20e17c94df57b49b787cda6f8e96794acf70b302c9708e9573dda18e402c7e996ea14e537e736001b12070d7542</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4279.72</td><td style=\"text-align: right;\">  0.679739</td><td style=\"text-align: right;\">      0.0711178</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   3749   9036  34285\n",
       "  34469  48737  50620  51165  56786 138543 140698 147456 150909 152545\n",
       " 153462 157813 166319 167113 167404 171492 172849 175007 176099 181215\n",
       " 191663 197526 202991 203690 210273 210642 211331 213296 225240 232933\n",
       " 236100 236152 236967 238367 246778 249963 250489 253180 254626 259157\n",
       " 260686]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>26f328150124298822fc4a0be849251c3d3545dcb2495c71dc92a60d1629ea641ec4d24c7004a3d579df61f5ba7197ffe6e88e3efaee93d226270372ee87d4b2</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4375.28</td><td style=\"text-align: right;\">  0.386449</td><td style=\"text-align: right;\">      0.0745828</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[  213   214   215   216   217   218   219   220   221   222   223   224\n",
       "   225   226   227   271   272   273   274   275   276   279   280   281\n",
       "   282   283   284   746   822  1088  1149  1780  5036  5047  5048  5061\n",
       "  5072  5081 25558 26463 26526 26586 26779 26806 26872 27695 27696 27705\n",
       " 27946 28786 29147 29478 29515 30180 30227 80288 90884]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>2b8a2419e7f2c6fecb549146c3d66ab9cae9839005d8f848d39313e49b34d22c18c6eb7e20b3b0c5291d4ad0f7f2b329423816423f62a40a7dae70870c2b7f9f</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4396.63</td><td style=\"text-align: right;\">  0.430514</td><td style=\"text-align: right;\">      0.0760735</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284  37539  39230  48737\n",
       "  50317  50620  51165  54086  56786 136103 138338 146222 150118 155432\n",
       " 159786 168532 168885 173914 176279 181552 183110 184567 189142 203690\n",
       " 236100 236967 238367 246778 259157]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>67d469882a190b2d6262a34bcca389d43799a46e823c51da3c685150a32c5779132915cfd6cc965db7d7f92639dd725dad1e29d2f69598d63cdf1402d2fa66b3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4478.26</td><td style=\"text-align: right;\">  0.307116</td><td style=\"text-align: right;\">      0.073295 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284  10989  15232  30288\n",
       "  35120  35398  35501  36039  36588  36629  36995  37039  38659  38832\n",
       "  38914  39203  40955  41119  41228  41930  45675  98646  99563 100217\n",
       " 100989 101877 104876 104964 106194 116195 122133 122201 123031 125489\n",
       " 125649 162602 223741]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preserve_training_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9fcd557a1f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0maml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m \u001b[0mpreserve_training_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreserve_training_output_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AutoML Modeling Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preserve_training_output' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "#\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "#\n",
    "#import org.apache.spark.ml.feature.NGram\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from collections import Counter\n",
    "#\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from pyspark.ml.feature import NGram, CountVectorizer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "#\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "#\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "#\n",
    "#  FILTER with PySpark SQL Functions F.\n",
    "#\n",
    "# Arguments\n",
    "#\n",
    "import argparse\n",
    "## Parse date_of execution\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"--datev1\", help=\"Execution Date\")\n",
    "#args = parser.parse_args()\n",
    "#if args.datev1:\n",
    "#    processdate = args.datev1\n",
    "# GENERAL PREPARATION SCRIPT\n",
    "#\n",
    "#  Date in format YYYYMMDD\n",
    "#process_date = processdate\n",
    "#if not process_date:\n",
    "#    process_date = \"20181231\"\n",
    "#\n",
    "process_date=\"20190122\"\n",
    "#\n",
    "#\n",
    "sc = pyspark.SparkContext()\n",
    "#conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','2047mb'),('spark.driver.memory','23g'),('spark.driver.maxResultSize','21g')])\n",
    "conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','512mb'),('spark.driver.memory','16g'),('spark.driver.maxResultSize','12g')])\n",
    "sc.stop()\n",
    "sc.stop()\n",
    "sc = pyspark.SparkContext(conf=conf,appName=\"Notebook-FraudCanada-AUTOML-Model-NGrams-CountVectorizer-KL-KS-Entropy\")\n",
    "sqlContext = SQLContext(sc)\n",
    "#\n",
    "input_most_frequent_df=\"hdfs:///data/staged/ott_dazn/advanced-model-data/the-most-frequent-fraud-hash_message/dt=\"+process_date\n",
    "input_fraud=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-15-features-85/dt=\"+process_date\n",
    "#\n",
    "input_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-15-features-85/dt=\"+process_date\n",
    "output_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/label-fraud-notfraud-data-model/dt=\"+process_date\n",
    "preserve_training_input_file=\"hdfs:///data/staged/ott_dazn/advanced-model-data/preserve-training-output-automl-clean/dt=\"+process_date\n",
    "#\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "#\n",
    "import subprocess\n",
    "subprocess.run('unset http_proxy', shell=True)\n",
    "#\n",
    "# Start an H2O virtual cluster that uses 6 gigs of RAM and 6 cores\n",
    "h2o.init(ip=\"localhost\",port=54321,max_mem_size = \"6g\", nthreads = 6) \n",
    "#\n",
    "# Clean up the h2o cluster just in case\n",
    "h2o.remove_all()\n",
    "#\n",
    "#  TRAINING PROCESS\n",
    "#\n",
    "print(\"Start Training Model NGrams Vectors KS KL Entropty\")\n",
    "#\n",
    "# Horrible code :: close your eyes, is ugly\n",
    "#\n",
    "fraud_label_read_file=sqlContext.read.json(output_file1)\n",
    "fraud_label_read_file.printSchema()\n",
    "#\n",
    "fraud_label_read_df=fraud_label_read_file\\\n",
    ".select(col('hash_message').cast('string'),col('fraud_label').cast('int'),\\\n",
    "        col('kl_words').cast('double'), col('ks_words').cast('double'),col('entropy_words').cast('double'),\\\n",
    "        col('features_85.type').alias('features85_type').cast('long'),\\\n",
    "        col('features_85.size').alias('features85_size').cast('long'),\\\n",
    "        col('features_85.indices').alias('features85_indices'),\\\n",
    "        col('features_85.values').alias('features85_values'),\\\n",
    "        col('ngramscounts_15.type').alias('ngramscounts15_type').cast('long'),\\\n",
    "        col('ngramscounts_15.size').alias('ngramscounts15_size').cast('long'),\\\n",
    "        col('ngramscounts_15.indices').alias('ngramscounts15_indices'),\\\n",
    "        col('ngramscounts_15.values').alias('ngramscounts15_values'))\n",
    "fraud_label_read_df.printSchema()\n",
    "#\n",
    "# ABOVE ARE CASE ISSUES on struct Struct of features_85 and ngramscounts_15 \n",
    "# Both cares conversion to DF valide type list\n",
    "# Flat vars for each, individually and seperately from the original struct\n",
    "#\n",
    "# https://stackoverflow.com/questions/47401418/pyspark-conversion-to-array-types?rq=1 \n",
    "#\n",
    "#\n",
    "fraud_fraud_label_read1_df=fraud_label_read_df.filter(\"fraud_label=1\")\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "notfraud_fraud_label_read1_df=fraud_label_read_df.filter(\"fraud_label=0\")\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "#\n",
    "fraud_fraud_label_read1_df.printSchema()\n",
    "notfraud_fraud_label_read1_df.printSchema()\n",
    "#\n",
    "drop_list_cols=['features85_indices','features85_values','ngramscounts15_indices','ngramscounts15_values']\n",
    "#\n",
    "### 1.) https://stackoverflow.com/questions/38610559/convert-spark-dataframe-column-to-python-list\n",
    "###    list(spark_df.select('mvv').toPandas()['mvv'])\n",
    "### 2.) http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.assign.html\n",
    "###    df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,temp_k=lambda x: (x['temp_f'] +  459.67) * 5 / 9)\n",
    "### 3.) https://stackoverflow.com/questions/43216411/pandas-flatten-a-list-of-list-within-a-column\n",
    "###    df['var2'] = df['var2'].apply(np.ravel)\n",
    "fraud_label_train_pd=fraud_fraud_label_read1_df.limit(2500).toPandas()\\\n",
    ".assign(features85_list_indices=lambda x: x['features85_indices'].apply(np.ravel),\\\n",
    "        features85_list_values=lambda x: x['features85_values'].apply(np.ravel),\\\n",
    "        ngramscounts15_list_indices=lambda x: x['ngramscounts15_indices'].apply(np.ravel),\\\n",
    "        ngramscounts15_list_values=lambda x: x['ngramscounts15_values'].apply(np.ravel))\\\n",
    ".drop(drop_list_cols, axis=1, inplace=False)\n",
    "#.tail(1200)\n",
    "# dummy_dif=lambda x:list(x['fraud_label'])\n",
    "#\n",
    "fraud_label_test_pd=fraud_fraud_label_read1_df.limit(500).toPandas()\\\n",
    ".assign(features85_list_indices=lambda x: x['features85_indices'].apply(np.ravel),\\\n",
    "        features85_list_values=lambda x: x['features85_values'].apply(np.ravel),\\\n",
    "        ngramscounts15_list_indices=lambda x: x['ngramscounts15_indices'].apply(np.ravel),\\\n",
    "        ngramscounts15_list_values=lambda x: x['ngramscounts15_values'].apply(np.ravel))\\\n",
    ".drop(drop_list_cols, axis=1, inplace=False)\n",
    "#\n",
    "not_fraud_label_train_pd=notfraud_fraud_label_read1_df.limit(2500).toPandas()\\\n",
    ".assign(features85_list_indices=lambda x: x['features85_indices'].apply(np.ravel),\\\n",
    "        features85_list_values=lambda x: x['features85_values'].apply(np.ravel),\\\n",
    "        ngramscounts15_list_indices=lambda x: x['ngramscounts15_indices'].apply(np.ravel),\\\n",
    "        ngramscounts15_list_values=lambda x: x['ngramscounts15_values'].apply(np.ravel))\\\n",
    ".drop(drop_list_cols, axis=1, inplace=False)\n",
    "#.tail(3000)\n",
    "#\n",
    "not_fraud_label_test_pd=notfraud_fraud_label_read1_df.limit(500).toPandas()\\\n",
    ".assign(features85_list_indices=lambda x: x['features85_indices'].apply(np.ravel),\\\n",
    "        features85_list_values=lambda x: x['features85_values'].apply(np.ravel),\\\n",
    "        ngramscounts15_list_indices=lambda x: x['ngramscounts15_indices'].apply(np.ravel),\\\n",
    "        ngramscounts15_list_values=lambda x: x['ngramscounts15_values'].apply(np.ravel))\\\n",
    ".drop(drop_list_cols, axis=1, inplace=False)\n",
    "#.head(800)\n",
    "#\n",
    "not_fraud_label_train=h2o.H2OFrame(not_fraud_label_train_pd)\n",
    "not_fraud_label_test=h2o.H2OFrame(not_fraud_label_test_pd)\n",
    "#\n",
    "fraud_label_train=h2o.H2OFrame(fraud_label_train_pd)\n",
    "fraud_label_test=h2o.H2OFrame(fraud_label_test_pd)\n",
    "#\n",
    "################# Use Two DataFrames ##################### - rbind() H2o Frames issue\n",
    "#\n",
    "#\n",
    "###### TRAINING PROCESS ############\n",
    "# RBIND \"Merge\" all of vars internal subset of data with fraud and with not_fraud\n",
    "# function merge() doesn't work if both H2O/dataframes have same variables\n",
    "#\n",
    "train = fraud_label_train.rbind(not_fraud_label_train)\n",
    "test = fraud_label_test.rbind(not_fraud_label_test)\n",
    "#\n",
    "print(\"train\")\n",
    "print(train.head(10))\n",
    "print(\"test\")\n",
    "print(test.head(10))\n",
    "#\n",
    "# Identify predictors and response\n",
    "x = train.columns\n",
    "#\n",
    "# Fraud Label to be learned in the model from the atrributes of the ngram85 learned words\n",
    "#\n",
    "y= 'fraud_label'\n",
    "x.remove(y)\n",
    "#\n",
    "# For binary classification, response should be a factor\n",
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()\n",
    "#\n",
    "# http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html\n",
    "# Balance Classes to compensate unbalanced data\n",
    "# Run AutoML for 25 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=25, seed=19, exclude_algos=[\"DRF\",\"GLM\"])\n",
    "aml.train(x=x, y=y, training_frame=train)\n",
    "#\n",
    "preserve_training_output.write.json(preserve_training_output_file)\n",
    "#\n",
    "print(\"AutoML Modeling Done!\")\n",
    "#\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">   logloss</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">     rmse</th><th style=\"text-align: right;\">        mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_grid_1_AutoML_20190130_220356_model_2          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00306745</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.0243367</td><td style=\"text-align: right;\">0.000592275</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190130_220356_model_4          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00307677</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.0239174</td><td style=\"text-align: right;\">0.00057204 </td></tr>\n",
       "<tr><td>GBM_1_AutoML_20190130_220356                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00268356</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.019373 </td><td style=\"text-align: right;\">0.000375312</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20190130_220356                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00307771</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.0225409</td><td style=\"text-align: right;\">0.000508093</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20190130_220356                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00311036</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.0227483</td><td style=\"text-align: right;\">0.000517484</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20190130_220356                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00298126</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.0222751</td><td style=\"text-align: right;\">0.000496179</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190130_220356_model_3          </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00116999</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.0166812</td><td style=\"text-align: right;\">0.000278263</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20190130_220356                       </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00309766</td><td style=\"text-align: right;\">           0          </td><td style=\"text-align: right;\">0.022929 </td><td style=\"text-align: right;\">0.000525738</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190130_220356_model_1      </td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">0.00179216</td><td style=\"text-align: right;\">           0.000220848</td><td style=\"text-align: right;\">0.0184063</td><td style=\"text-align: right;\">0.000338791</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190130_220356_model_2 </td><td style=\"text-align: right;\">0.999999</td><td style=\"text-align: right;\">0.00465119</td><td style=\"text-align: right;\">           0.000377929</td><td style=\"text-align: right;\">0.0315187</td><td style=\"text-align: right;\">0.000993428</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190130_220356_model_4 </td><td style=\"text-align: right;\">0.999999</td><td style=\"text-align: right;\">0.00366538</td><td style=\"text-align: right;\">           0.000441696</td><td style=\"text-align: right;\">0.0316414</td><td style=\"text-align: right;\">0.00100118 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190130_220356_model_2      </td><td style=\"text-align: right;\">0.999998</td><td style=\"text-align: right;\">0.00481781</td><td style=\"text-align: right;\">           0.000598777</td><td style=\"text-align: right;\">0.0307196</td><td style=\"text-align: right;\">0.000943691</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190130_220356_model_1 </td><td style=\"text-align: right;\">0.999996</td><td style=\"text-align: right;\">0.00750053</td><td style=\"text-align: right;\">           0.000819625</td><td style=\"text-align: right;\">0.0463469</td><td style=\"text-align: right;\">0.00214804 </td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20190130_220356              </td><td style=\"text-align: right;\">0.999994</td><td style=\"text-align: right;\">0.00294748</td><td style=\"text-align: right;\">           0.000755858</td><td style=\"text-align: right;\">0.0252187</td><td style=\"text-align: right;\">0.000635984</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20190130_220356   </td><td style=\"text-align: right;\">0.999993</td><td style=\"text-align: right;\">0.00197742</td><td style=\"text-align: right;\">           0.000377929</td><td style=\"text-align: right;\">0.0168657</td><td style=\"text-align: right;\">0.000284452</td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_20190130_220356                   </td><td style=\"text-align: right;\">0.999971</td><td style=\"text-align: right;\">0.0114278 </td><td style=\"text-align: right;\">           0.00195341 </td><td style=\"text-align: right;\">0.0444003</td><td style=\"text-align: right;\">0.00197138 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190130_220356_model_6      </td><td style=\"text-align: right;\">0.999956</td><td style=\"text-align: right;\">0.0126281 </td><td style=\"text-align: right;\">           0.00261596 </td><td style=\"text-align: right;\">0.0485266</td><td style=\"text-align: right;\">0.00235483 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190130_220356_model_1          </td><td style=\"text-align: right;\">0.999924</td><td style=\"text-align: right;\">0.00562963</td><td style=\"text-align: right;\">           0.000377929</td><td style=\"text-align: right;\">0.0192264</td><td style=\"text-align: right;\">0.000369653</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190130_220356_model_3 </td><td style=\"text-align: right;\">0.999924</td><td style=\"text-align: right;\">0.0116439 </td><td style=\"text-align: right;\">           0.00296434 </td><td style=\"text-align: right;\">0.0557697</td><td style=\"text-align: right;\">0.00311026 </td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_20190130_220356                   </td><td style=\"text-align: right;\">0.999881</td><td style=\"text-align: right;\">0.0237528 </td><td style=\"text-align: right;\">           0.00374974 </td><td style=\"text-align: right;\">0.0665605</td><td style=\"text-align: right;\">0.0044303  </td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_20190130_220356                   </td><td style=\"text-align: right;\">0.999504</td><td style=\"text-align: right;\">0.0425624 </td><td style=\"text-align: right;\">           0.00992881 </td><td style=\"text-align: right;\">0.0941322</td><td style=\"text-align: right;\">0.00886087 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20190130_220356</td><td style=\"text-align: right;\">0.999398</td><td style=\"text-align: right;\">0.00287595</td><td style=\"text-align: right;\">           0.000377929</td><td style=\"text-align: right;\">0.0167195</td><td style=\"text-align: right;\">0.000279542</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190130_220356_model_4      </td><td style=\"text-align: right;\">0.999344</td><td style=\"text-align: right;\">0.0497422 </td><td style=\"text-align: right;\">           0.0104685  </td><td style=\"text-align: right;\">0.102814 </td><td style=\"text-align: right;\">0.0105707  </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190130_220356_model_7      </td><td style=\"text-align: right;\">0.997852</td><td style=\"text-align: right;\">0.194314  </td><td style=\"text-align: right;\">           0.0026455  </td><td style=\"text-align: right;\">0.256731 </td><td style=\"text-align: right;\">0.0659107  </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190130_220356_model_3      </td><td style=\"text-align: right;\">0.977887</td><td style=\"text-align: right;\">0.16649   </td><td style=\"text-align: right;\">           0.105064   </td><td style=\"text-align: right;\">0.231664 </td><td style=\"text-align: right;\">0.0536684  </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190130_220356_model_5      </td><td style=\"text-align: right;\">0.959208</td><td style=\"text-align: right;\">0.255479  </td><td style=\"text-align: right;\">           0.100907   </td><td style=\"text-align: right;\">0.293214 </td><td style=\"text-align: right;\">0.0859744  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_grid_1_AutoML_20190130_220356_model_2\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 1.372641304208612e-18\n",
      "RMSE: 1.171597757000504e-09\n",
      "LogLoss: 1.0032474162261598e-09\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "pr_auc: 0.0\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9999999986197364: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>2264.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/2264.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>1323.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/1323.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>2264.0</td>\n",
       "<td>1323.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/3587.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ------------\n",
       "0      2264  0     0        (0.0/2264.0)\n",
       "1      0     1323  0        (0.0/1323.0)\n",
       "Total  2264  1323  0        (0.0/3587.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       1            1        0\n",
       "max f2                       1            1        0\n",
       "max f0point5                 1            1        0\n",
       "max accuracy                 1            1        0\n",
       "max precision                1            1        0\n",
       "max recall                   1            1        0\n",
       "max specificity              1            1        0\n",
       "max absolute_mcc             1            1        0\n",
       "max min_per_class_accuracy   1            1        0\n",
       "max mean_per_class_accuracy  1            1        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 36.88 %, avg score: 36.88 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100362</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0272109</td>\n",
       "<td>0.0272109</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0203513</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0279667</td>\n",
       "<td>0.0551776</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0309451</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0287226</td>\n",
       "<td>0.0839002</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0401450</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0249433</td>\n",
       "<td>0.1088435</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0501812</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0272109</td>\n",
       "<td>0.1360544</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000836</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1352986</td>\n",
       "<td>0.2713530</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1499861</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1352986</td>\n",
       "<td>0.4066515</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2001673</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1360544</td>\n",
       "<td>0.5427060</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999721</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.2705971</td>\n",
       "<td>0.8133031</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000558</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.8654089</td>\n",
       "<td>2.4996516</td>\n",
       "<td>0.6880223</td>\n",
       "<td>0.6880223</td>\n",
       "<td>0.9219512</td>\n",
       "<td>0.9219512</td>\n",
       "<td>0.1866969</td>\n",
       "<td>1.0</td>\n",
       "<td>86.5408869</td>\n",
       "<td>149.9651568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5004182</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9983287</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.7370474</td>\n",
       "<td>0.7370474</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.8328691</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6665737</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.5002091</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.5533250</td>\n",
       "<td>0.5533250</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>50.0209118</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7911904</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2639183</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4661734</td>\n",
       "<td>0.4661734</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>26.3918252</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8260385</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2105974</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4465069</td>\n",
       "<td>0.4465069</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>21.0597368</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9007527</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1101826</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4094708</td>\n",
       "<td>0.4094708</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.0182606</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3688319</td>\n",
       "<td>0.3688319</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0100362                   1                  2.71126  2.71126            1                1            1                           1                   0.0272109       0.0272109                  171.126  171.126\n",
       "    2        0.0203513                   1                  2.71126  2.71126            1                1            1                           1                   0.0279667       0.0551776                  171.126  171.126\n",
       "    3        0.0309451                   1                  2.71126  2.71126            1                1            1                           1                   0.0287226       0.0839002                  171.126  171.126\n",
       "    4        0.040145                    1                  2.71126  2.71126            1                1            1                           1                   0.0249433       0.108844                   171.126  171.126\n",
       "    5        0.0501812                   1                  2.71126  2.71126            1                1            1                           1                   0.0272109       0.136054                   171.126  171.126\n",
       "    6        0.100084                    1                  2.71126  2.71126            1                1            1                           1                   0.135299        0.271353                   171.126  171.126\n",
       "    7        0.149986                    1                  2.71126  2.71126            1                1            1                           1                   0.135299        0.406652                   171.126  171.126\n",
       "    8        0.200167                    1                  2.71126  2.71126            1                1            1                           1                   0.136054        0.542706                   171.126  171.126\n",
       "    9        0.299972                    1                  2.71126  2.71126            1                1            1                           1                   0.270597        0.813303                   171.126  171.126\n",
       "    10       0.400056                    1.46746e-09        1.86541  2.49965            0.688022         0.688022     0.921951                    0.921951            0.186697        1                          86.5409  149.965\n",
       "    11       0.500418                    6.65861e-10        0        1.99833            0                8.29255e-10  0.737047                    0.737047            0               1                          -100     99.8329\n",
       "    12       0.666574                    6.52687e-10        0        1.50021            0                6.53817e-10  0.553325                    0.553325            0               1                          -100     50.0209\n",
       "    13       0.79119                     6.52686e-10        0        1.26392            0                6.52686e-10  0.466173                    0.466173            0               1                          -100     26.3918\n",
       "    14       0.826038                    6.52685e-10        0        1.2106             0                6.52685e-10  0.446507                    0.446507            0               1                          -100     21.0597\n",
       "    15       0.900753                    6.52667e-10        0        1.11018            0                6.52678e-10  0.409471                    0.409471            0               1                          -100     11.0183\n",
       "    16       1                           6.46995e-10        0        1                  0                6.52321e-10  0.368832                    0.368832            0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 2.891618789925138e-18\n",
      "RMSE: 1.700476048030415e-09\n",
      "LogLoss: 1.1779277445107951e-09\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "pr_auc: 0.0\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9999999982914622: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>236.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/236.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>144.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/144.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>236.0</td>\n",
       "<td>144.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/380.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      236  0    0        (0.0/236.0)\n",
       "1      0    144  0        (0.0/144.0)\n",
       "Total  236  144  0        (0.0/380.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       1            1        0\n",
       "max f2                       1            1        0\n",
       "max f0point5                 1            1        0\n",
       "max accuracy                 1            1        0\n",
       "max precision                1            1        0\n",
       "max recall                   1            1        0\n",
       "max specificity              1            1        0\n",
       "max absolute_mcc             1            1        0\n",
       "max min_per_class_accuracy   1            1        0\n",
       "max mean_per_class_accuracy  1            1        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 37.89 %, avg score: 37.89 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0105263</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0210526</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0315789</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0833333</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0421053</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1111111</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0526316</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1388889</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.125</td>\n",
       "<td>0.2638889</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1319444</td>\n",
       "<td>0.3958333</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1319444</td>\n",
       "<td>0.5277778</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6388889</td>\n",
       "<td>2.6388889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.2638889</td>\n",
       "<td>0.7916667</td>\n",
       "<td>163.8888889</td>\n",
       "<td>163.8888889</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0000000</td>\n",
       "<td>2.0833333</td>\n",
       "<td>2.5</td>\n",
       "<td>0.7894737</td>\n",
       "<td>0.7894737</td>\n",
       "<td>0.9473684</td>\n",
       "<td>0.9473684</td>\n",
       "<td>0.2083333</td>\n",
       "<td>1.0</td>\n",
       "<td>108.3333333</td>\n",
       "<td>150.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.7578947</td>\n",
       "<td>0.7578947</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.6315789</td>\n",
       "<td>0.6315789</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.5413534</td>\n",
       "<td>0.5413534</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4736842</td>\n",
       "<td>0.4736842</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4210526</td>\n",
       "<td>0.4210526</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3789474</td>\n",
       "<td>0.3789474</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0105263                   1                  2.63889  2.63889            1                1            1                           1                   0.0277778       0.0277778                  163.889  163.889\n",
       "    2        0.0210526                   1                  2.63889  2.63889            1                1            1                           1                   0.0277778       0.0555556                  163.889  163.889\n",
       "    3        0.0315789                   1                  2.63889  2.63889            1                1            1                           1                   0.0277778       0.0833333                  163.889  163.889\n",
       "    4        0.0421053                   1                  2.63889  2.63889            1                1            1                           1                   0.0277778       0.111111                   163.889  163.889\n",
       "    5        0.0526316                   1                  2.63889  2.63889            1                1            1                           1                   0.0277778       0.138889                   163.889  163.889\n",
       "    6        0.1                         1                  2.63889  2.63889            1                1            1                           1                   0.125           0.263889                   163.889  163.889\n",
       "    7        0.15                        1                  2.63889  2.63889            1                1            1                           1                   0.131944        0.395833                   163.889  163.889\n",
       "    8        0.2                         1                  2.63889  2.63889            1                1            1                           1                   0.131944        0.527778                   163.889  163.889\n",
       "    9        0.3                         1                  2.63889  2.63889            1                1            1                           1                   0.263889        0.791667                   163.889  163.889\n",
       "    10       0.4                         2.6364e-09         2.08333  2.5                0.789474         0.789474     0.947368                    0.947368            0.208333        1                          108.333  150\n",
       "    11       0.5                         6.85187e-10        0        2                  0                1.07472e-09  0.757895                    0.757895            0               1                          -100     100\n",
       "    12       0.6                         6.53126e-10        0        1.66667            0                6.59299e-10  0.631579                    0.631579            0               1                          -100     66.6667\n",
       "    13       0.7                         6.52821e-10        0        1.42857            0                6.52854e-10  0.541353                    0.541353            0               1                          -100     42.8571\n",
       "    14       0.8                         6.5282e-10         0        1.25               0                6.5282e-10   0.473684                    0.473684            0               1                          -100     25\n",
       "    15       0.9                         6.52803e-10        0        1.11111            0                6.52816e-10  0.421053                    0.421053            0               1                          -100     11.1111\n",
       "    16       1                           6.46803e-10        0        1                  0                6.52274e-10  0.378947                    0.378947            0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.0005922752286615499\n",
      "RMSE: 0.024336705378122773\n",
      "LogLoss: 0.0030674458314021193\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "pr_auc: 0.5993953136810279\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.003534642799794412: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>2264.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/2264.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>1323.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/1323.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>2264.0</td>\n",
       "<td>1323.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/3587.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ------------\n",
       "0      2264  0     0        (0.0/2264.0)\n",
       "1      0     1323  0        (0.0/1323.0)\n",
       "Total  2264  1323  0        (0.0/3587.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.0035346</td>\n",
       "<td>1.0</td>\n",
       "<td>231.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0035346</td>\n",
       "<td>1.0</td>\n",
       "<td>231.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.0035346</td>\n",
       "<td>1.0</td>\n",
       "<td>231.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.0035346</td>\n",
       "<td>1.0</td>\n",
       "<td>231.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0035346</td>\n",
       "<td>1.0</td>\n",
       "<td>231.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0035346</td>\n",
       "<td>1.0</td>\n",
       "<td>231.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0035346</td>\n",
       "<td>1.0</td>\n",
       "<td>231.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0035346</td>\n",
       "<td>1.0</td>\n",
       "<td>231.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       0.00353464   1        231\n",
       "max f2                       0.00353464   1        231\n",
       "max f0point5                 0.00353464   1        231\n",
       "max accuracy                 0.00353464   1        231\n",
       "max precision                1            1        0\n",
       "max recall                   0.00353464   1        231\n",
       "max specificity              1            1        0\n",
       "max absolute_mcc             0.00353464   1        231\n",
       "max min_per_class_accuracy   0.00353464   1        231\n",
       "max mean_per_class_accuracy  0.00353464   1        231"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 36.88 %, avg score: 36.78 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.1368832</td>\n",
       "<td>1.0</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3711262</td>\n",
       "<td>0.3711262</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.1499861</td>\n",
       "<td>0.9998437</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999735</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999977</td>\n",
       "<td>0.0355253</td>\n",
       "<td>0.4066515</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.2001673</td>\n",
       "<td>0.9998376</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998424</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999588</td>\n",
       "<td>0.1360544</td>\n",
       "<td>0.5427060</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.2999721</td>\n",
       "<td>0.9974319</td>\n",
       "<td>2.7112623</td>\n",
       "<td>2.7112623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992314</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997168</td>\n",
       "<td>0.2705971</td>\n",
       "<td>0.8133031</td>\n",
       "<td>171.1262283</td>\n",
       "<td>171.1262283</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.4000558</td>\n",
       "<td>0.0015045</td>\n",
       "<td>1.8654089</td>\n",
       "<td>2.4996516</td>\n",
       "<td>0.6880223</td>\n",
       "<td>0.6767041</td>\n",
       "<td>0.9219512</td>\n",
       "<td>0.9189073</td>\n",
       "<td>0.1866969</td>\n",
       "<td>1.0</td>\n",
       "<td>86.5408869</td>\n",
       "<td>149.9651568</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.5001394</td>\n",
       "<td>0.0006805</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9994426</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0014746</td>\n",
       "<td>0.7374582</td>\n",
       "<td>0.7353185</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.9442586</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.5999442</td>\n",
       "<td>0.0004098</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6668216</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004228</td>\n",
       "<td>0.6147770</td>\n",
       "<td>0.6130635</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6821561</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.7000279</td>\n",
       "<td>0.0000915</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285145</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001701</td>\n",
       "<td>0.5268817</td>\n",
       "<td>0.5254376</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8514536</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.7998327</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2502614</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000437</td>\n",
       "<td>0.4611363</td>\n",
       "<td>0.4598778</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0261415</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.8999164</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1112144</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4098513</td>\n",
       "<td>0.4087328</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1214374</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3688319</td>\n",
       "<td>0.3678253</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.136883                    1                  2.71126  2.71126            1                1            1                           1                   0.371126        0.371126                   171.126  171.126\n",
       "    2        0.149986                    0.999844           2.71126  2.71126            1                0.999973     1                           0.999998            0.0355253       0.406652                   171.126  171.126\n",
       "    3        0.200167                    0.999838           2.71126  2.71126            1                0.999842     1                           0.999959            0.136054        0.542706                   171.126  171.126\n",
       "    4        0.299972                    0.997432           2.71126  2.71126            1                0.999231     1                           0.999717            0.270597        0.813303                   171.126  171.126\n",
       "    5        0.400056                    0.00150452         1.86541  2.49965            0.688022         0.676704     0.921951                    0.918907            0.186697        1                          86.5409  149.965\n",
       "    6        0.500139                    0.000680532        0        1.99944            0                0.00147463   0.737458                    0.735318            0               1                          -100     99.9443\n",
       "    7        0.599944                    0.000409754        0        1.66682            0                0.00042284   0.614777                    0.613064            0               1                          -100     66.6822\n",
       "    8        0.700028                    9.14889e-05        0        1.42851            0                0.000170132  0.526882                    0.525438            0               1                          -100     42.8515\n",
       "    9        0.799833                    5.27199e-18        0        1.25026            0                4.36763e-05  0.461136                    0.459878            0               1                          -100     25.0261\n",
       "    10       0.899916                    1.62858e-18        0        1.11121            0                4.56393e-18  0.409851                    0.408733            0               1                          -100     11.1214\n",
       "    11       1                           6.07864e-19        0        1                  0                1.30885e-18  0.368832                    0.367825            0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.7112694</td>\n",
       "<td>0.0028505</td>\n",
       "<td>2.709434</td>\n",
       "<td>2.709434</td>\n",
       "<td>2.7056603</td>\n",
       "<td>2.715909</td>\n",
       "<td>2.715909</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0030679</td>\n",
       "<td>0.0026807</td>\n",
       "<td>0.0044472</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0009839</td>\n",
       "<td>0.0099084</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0005922</td>\n",
       "<td>0.0004356</td>\n",
       "<td>0.0012785</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0002932</td>\n",
       "<td>0.0013895</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9974552</td>\n",
       "<td>0.0018717</td>\n",
       "<td>0.9945094</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9987398</td>\n",
       "<td>0.9940268</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.0180311</td>\n",
       "<td>0.0115570</td>\n",
       "<td>0.0357567</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0171221</td>\n",
       "<td>0.0372765</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 1            0            1             1             1             1             1\n",
       "auc                      1            0            1             1             1             1             1\n",
       "err                      0            0            0             0             0             0             0\n",
       "err_count                0            0            0             0             0             0             0\n",
       "f0point5                 1            0            1             1             1             1             1\n",
       "f1                       1            0            1             1             1             1             1\n",
       "f2                       1            0            1             1             1             1             1\n",
       "lift_top_group           2.71127      0.00285048   2.70943       2.70943       2.70566       2.71591       2.71591\n",
       "logloss                  0.00306792   0.00268071   0.00444724    3.71105e-18   2.29167e-17   0.000983944   0.0099084\n",
       "max_per_class_error      0            0            0             0             0             0             0\n",
       "mcc                      1            0            1             1             1             1             1\n",
       "mean_per_class_accuracy  1            0            1             1             1             1             1\n",
       "mean_per_class_error     0            0            0             0             0             0             0\n",
       "mse                      0.000592249  0.000435619  0.00127854    1.20169e-33   1.64002e-32   0.000293166   0.00138954\n",
       "precision                1            0            1             1             1             1             1\n",
       "r2                       0.997455     0.00187173   0.994509      1             1             0.99874       0.994027\n",
       "recall                   1            0            1             1             1             1             1\n",
       "rmse                     0.0180311    0.011557     0.0357567     3.46655e-17   1.28063e-16   0.0171221     0.0372765\n",
       "specificity              1            0            1             1             1             1             1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_pr_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 22:09:30</td>\n",
       "<td> 3 min  4.785 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4824883</td>\n",
       "<td>0.6583311</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6311681</td>\n",
       "<td>0.4852304</td>\n",
       "<td>0.6637654</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6210526</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 22:09:30</td>\n",
       "<td> 3 min  4.804 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.4588153</td>\n",
       "<td>0.6107558</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4614217</td>\n",
       "<td>0.6156582</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 22:09:30</td>\n",
       "<td> 3 min  4.818 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.4363190</td>\n",
       "<td>0.5680655</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4387966</td>\n",
       "<td>0.5725122</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 22:09:30</td>\n",
       "<td> 3 min  4.833 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.4149377</td>\n",
       "<td>0.5294965</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4172931</td>\n",
       "<td>0.5335487</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 22:09:30</td>\n",
       "<td> 3 min  4.850 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.3946137</td>\n",
       "<td>0.4944553</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3968531</td>\n",
       "<td>0.4981626</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 22:10:04</td>\n",
       "<td> 3 min 38.233 sec</td>\n",
       "<td>1995.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 22:10:04</td>\n",
       "<td> 3 min 38.320 sec</td>\n",
       "<td>2000.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 22:10:04</td>\n",
       "<td> 3 min 38.410 sec</td>\n",
       "<td>2005.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 22:10:04</td>\n",
       "<td> 3 min 38.499 sec</td>\n",
       "<td>2010.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 22:10:04</td>\n",
       "<td> 3 min 38.583 sec</td>\n",
       "<td>2015.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.7112623</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6388889</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration          number_of_trees    training_rmse           training_logloss        training_auc    training_pr_auc    training_lift      training_classification_error    validation_rmse         validation_logloss      validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "---  -------------------  ----------------  -----------------  ----------------------  ----------------------  --------------  -----------------  -----------------  -------------------------------  ----------------------  ----------------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "     2019-01-30 22:09:30  3 min  4.785 sec  0.0                0.4824882668957528      0.6583310663944258      0.5             0.0                1.0                0.6311681070532479               0.4852304434306271      0.6637654161828104      0.5               0.0                  1.0                0.6210526315789474\n",
       "     2019-01-30 22:09:30  3 min  4.804 sec  5.0                0.45881531386762475     0.610755824606028       1.0             0.0                2.711262282690854  0.0                              0.46142172270711956     0.615658180416699       1.0               0.0                  2.638888888888889  0.0\n",
       "     2019-01-30 22:09:30  3 min  4.818 sec  10.0               0.43631901582814214     0.568065518289145       1.0             0.0                2.711262282690854  0.0                              0.4387966294527057      0.5725122401002352      1.0               0.0                  2.638888888888889  0.0\n",
       "     2019-01-30 22:09:30  3 min  4.833 sec  15.0               0.4149376896133102      0.5294965411743762      1.0             0.0                2.711262282690854  0.0                              0.41729307744155764     0.5335487099449802      1.0               0.0                  2.638888888888889  0.0\n",
       "     2019-01-30 22:09:30  3 min  4.850 sec  20.0               0.3946137340419827      0.49445528603624467     1.0             0.0                2.711262282690854  0.0                              0.39685306843980594     0.4981625649716792      1.0               0.0                  2.638888888888889  0.0\n",
       "---  ---                  ---               ---                ---                     ---                     ---             ---                ---                ---                              ---                     ---                     ---               ---                  ---                ---\n",
       "     2019-01-30 22:10:04  3 min 38.233 sec  1995.0             1.430999283207979e-09   1.225374773805035e-09   1.0             0.0                2.711262282690854  0.0                              2.0769661222363603e-09  1.4387241904800435e-09  1.0               0.0                  2.638888888888889  0.0\n",
       "     2019-01-30 22:10:04  3 min 38.320 sec  2000.0             1.3612070630516623e-09  1.1656111990157465e-09  1.0             0.0                2.711262282690854  0.0                              1.9756712943323847e-09  1.3685567841788178e-09  1.0               0.0                  2.638888888888889  0.0\n",
       "     2019-01-30 22:10:04  3 min 38.410 sec  2005.0             1.2948187337724072e-09  1.108762408809632e-09   1.0             0.0                2.711262282690854  0.0                              1.8793166766572608e-09  1.301811493119898e-09   1.0               0.0                  2.638888888888889  0.0\n",
       "     2019-01-30 22:10:04  3 min 38.499 sec  2010.0             1.231668266798768e-09   1.0546862170128183e-09  1.0             0.0                2.711262282690854  0.0                              1.787661318910644e-09   1.2383213920558705e-09  1.0               0.0                  2.638888888888889  0.0\n",
       "     2019-01-30 22:10:04  3 min 38.583 sec  2015.0             1.171597757000504e-09   1.0032474162261598e-09  1.0             0.0                2.711262282690854  0.0                              1.700476048030415e-09   1.1779277445107951e-09  1.0               0.0                  2.638888888888889  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>features85_list_indices</td>\n",
       "<td>21270.7089844</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5126532</td></tr>\n",
       "<tr><td>features85_list_values</td>\n",
       "<td>18873.0742188</td>\n",
       "<td>0.8872800</td>\n",
       "<td>0.4548669</td></tr>\n",
       "<tr><td>entropy_words</td>\n",
       "<td>800.6923218</td>\n",
       "<td>0.0376430</td>\n",
       "<td>0.0192978</td></tr>\n",
       "<tr><td>kl_words</td>\n",
       "<td>312.5476685</td>\n",
       "<td>0.0146938</td>\n",
       "<td>0.0075328</td></tr>\n",
       "<tr><td>ks_words</td>\n",
       "<td>138.6884460</td>\n",
       "<td>0.0065202</td>\n",
       "<td>0.0033426</td></tr>\n",
       "<tr><td>ngramscounts15_list_values</td>\n",
       "<td>95.7104645</td>\n",
       "<td>0.0044996</td>\n",
       "<td>0.0023068</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                    relative_importance    scaled_importance    percentage\n",
       "--------------------------  ---------------------  -------------------  ------------\n",
       "features85_list_indices     21270.7                1                    0.512653\n",
       "features85_list_values      18873.1                0.88728              0.454867\n",
       "entropy_words               800.692                0.037643             0.0192978\n",
       "kl_words                    312.548                0.0146938            0.00753283\n",
       "ks_words                    138.688                0.00652016           0.00334258\n",
       "ngramscounts15_list_values  95.7105                0.00449964           0.00230675"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The leader model is stored here\n",
    "aml.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>hash_message                                                                                                                    </th><th style=\"text-align: right;\">  fraud_label</th><th style=\"text-align: right;\">  kl_words</th><th style=\"text-align: right;\">  ks_words</th><th style=\"text-align: right;\">  entropy_words</th><th style=\"text-align: right;\">  features85_type</th><th style=\"text-align: right;\">  features85_size</th><th style=\"text-align: right;\">  ngramscounts15_type</th><th style=\"text-align: right;\">  ngramscounts15_size</th><th>features85_list_indices  </th><th>features85_list_values  </th><th>ngramscounts15_list_indices  </th><th>ngramscounts15_list_values  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>589ff83a30fa5d82563f0051bbd9f638d3dc7f102f8c78ab137c17b859e740de35348417e0deb2037cd0188c243c674100eb57f97450c4b942c9d3a1ef86a07b</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4446.55</td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.0719711</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   2470   2735   3693\n",
       "   3764  36147  37143  37419  37711  38564  40263  54086 126340 135455\n",
       " 156927 193991 197546 197841 202865 205302 207492 208360 217507 218422\n",
       " 226659 239341 240569 246870]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>865fc00f8a94dd1c467c39753bfb2b18626f2827db85a05654caf048e657b6856afad3fef87873197e7f92e0ff760c8f04cd5484c910a037476643addfdb5c31</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   3287.65</td><td style=\"text-align: right;\">  0.947901</td><td style=\"text-align: right;\">      0.0696592</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284    746    822   1088\n",
       "   1854   7730   7735   7778   7808   7809   7814   7838   7872   7930\n",
       "   7935  14872  79502  82612 186447 194478 196889 198437 199717 208120\n",
       " 208331 214821 220456 221302 221526 222588 224016 231721 232821 234003\n",
       " 235173 240449 241239 242109 245164 246700 246748 248632 254896 257357\n",
       " 257450 259557]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>a659ae2c8efbde6eb990b90acae3e02f644e44cd1a3a9aa6490632209641eb5714bb4b740ddcbe95e50b5cd319a8725634ffea38ae633fd6ab1f7114ad8c17bd</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4169.68</td><td style=\"text-align: right;\">  0.52636 </td><td style=\"text-align: right;\">      0.0708245</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   3362  60557  69076\n",
       " 124379 197626 200410 200494 205837 218883 227283 229369 240735 240954\n",
       " 249778 255226]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>d6d7bcd45dfa2fb6487352a532359f3f64afe250dacb422898ed9854af8992866bff17dac83f36763b46f2db2e0442fdf23fafdd58628636ca3395b6ef019a16</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4538.96</td><td style=\"text-align: right;\">  0.210665</td><td style=\"text-align: right;\">      0.0757622</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   7253  32369  33820\n",
       "  88300  99401 100951 105511 127809 131543 131649 134219 137596 140394\n",
       " 141193 142373 145485 145729 153068 153992 155860 155919 158762 159310\n",
       " 160557 161212 165997 167110 167685 174858 176679 178410 179476 184686\n",
       " 190025]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>da23c7d6b5dd13228bb9b8e5d3287463ca7b12fbc8a5c068ce2cf4ca3e7e89ca6990a4abfc69dcedd538ee916f64a8d5d0440d1ad309c9604efc9ad4074a81ed</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4378.87</td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.077328 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284    746    822   1088\n",
       "   1149   5578   7253   8314   8323   8397   8425   8428   8593  18273\n",
       "  19204  26918  27068  27332  27919  27991  28156  28296  28380  28412\n",
       "  28952  29015  29041  29403  29405  98084  99873 100375 101619 102460\n",
       " 103277 107156 108692 110004 110158 112115 115060 116522 119369 120568\n",
       " 123239]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>980071f323752c9f7e987d2f657d244851b601c46ef50b2cd053d69ee9c3a7b413730fff5a68bea2dd9ada49d410f0c0f8165ad2a9096c2c419668df2b829de3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4222.18</td><td style=\"text-align: right;\">  0.523838</td><td style=\"text-align: right;\">      0.0740113</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 38 39 40 41 42 43 44 45 46 47 48\n",
       " 49 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   1780   6964   8267\n",
       "  13288  19547  67596  68543 106236 134459 138290 153693 162050 167036\n",
       " 178195 194296 198255 211624 213658 216527 218287 221815 222537 225699\n",
       " 242637 243896 244686 245816]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>e38e2712270ef1f79716537aa2816eaab104a20e17c94df57b49b787cda6f8e96794acf70b302c9708e9573dda18e402c7e996ea14e537e736001b12070d7542</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4279.72</td><td style=\"text-align: right;\">  0.679739</td><td style=\"text-align: right;\">      0.0711178</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284   3749   9036  34285\n",
       "  34469  48737  50620  51165  56786 138543 140698 147456 150909 152545\n",
       " 153462 157813 166319 167113 167404 171492 172849 175007 176099 181215\n",
       " 191663 197526 202991 203690 210273 210642 211331 213296 225240 232933\n",
       " 236100 236152 236967 238367 246778 249963 250489 253180 254626 259157\n",
       " 260686]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>26f328150124298822fc4a0be849251c3d3545dcb2495c71dc92a60d1629ea641ec4d24c7004a3d579df61f5ba7197ffe6e88e3efaee93d226270372ee87d4b2</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4375.28</td><td style=\"text-align: right;\">  0.386449</td><td style=\"text-align: right;\">      0.0745828</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[  213   214   215   216   217   218   219   220   221   222   223   224\n",
       "   225   226   227   271   272   273   274   275   276   279   280   281\n",
       "   282   283   284   746   822  1088  1149  1780  5036  5047  5048  5061\n",
       "  5072  5081 25558 26463 26526 26586 26779 26806 26872 27695 27696 27705\n",
       " 27946 28786 29147 29478 29515 30180 30227 80288 90884]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>2b8a2419e7f2c6fecb549146c3d66ab9cae9839005d8f848d39313e49b34d22c18c6eb7e20b3b0c5291d4ad0f7f2b329423816423f62a40a7dae70870c2b7f9f</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4396.63</td><td style=\"text-align: right;\">  0.430514</td><td style=\"text-align: right;\">      0.0760735</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284  37539  39230  48737\n",
       "  50317  50620  51165  54086  56786 136103 138338 146222 150118 155432\n",
       " 159786 168532 168885 173914 176279 181552 183110 184567 189142 203690\n",
       " 236100 236967 238367 246778 259157]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "<tr><td>67d469882a190b2d6262a34bcca389d43799a46e823c51da3c685150a32c5779132915cfd6cc965db7d7f92639dd725dad1e29d2f69598d63cdf1402d2fa66b3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4478.26</td><td style=\"text-align: right;\">  0.307116</td><td style=\"text-align: right;\">      0.073295 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 52 53 54 55 56 61 62 64 65]                          </td><td>[1. 2. 3. 4. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[   213    214    215    216    217    218    219    220    221    222\n",
       "    223    224    225    226    227    271    272    273    274    275\n",
       "    276    279    280    281    282    283    284  10989  15232  30288\n",
       "  35120  35398  35501  36039  36588  36629  36995  37039  38659  38832\n",
       "  38914  39203  40955  41119  41228  41930  45675  98646  99563 100217\n",
       " 100989 101877 104876 104964 106194 116195 122133 122201 123031 125489\n",
       " 125649 162602 223741]                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                             </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">         p0</th><th style=\"text-align: right;\">  p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.28385e-09</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.17784e-09</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.16349e-09</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.17814e-09</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.14767e-09</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.35222e-09</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.17426e-09</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.16114e-09</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.15443e-09</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">1.19768e-09</td><td style=\"text-align: right;\">   1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# If you need to generate predictions on a test set, you can make\n",
    "# predictions directly on the `\"H2OAutoML\"` object, or on the leader\n",
    "# model object directly\n",
    "\n",
    "#preds = aml.predict(test)\n",
    "# or:\n",
    "preds = aml.leader.predict(test)\n",
    "print(\"test\")\n",
    "print(test.head(10))\n",
    "print(\"prediction\")\n",
    "print(preds.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GBM_grid_1_AutoML_20190130_220356_model_2', 'GBM_grid_1_AutoML_20190130_220356_model_4', 'GBM_1_AutoML_20190130_220356', 'GBM_2_AutoML_20190130_220356', 'GBM_3_AutoML_20190130_220356', 'GBM_4_AutoML_20190130_220356', 'GBM_grid_1_AutoML_20190130_220356_model_3', 'GBM_5_AutoML_20190130_220356', 'XGBoost_grid_1_AutoML_20190130_220356_model_1', 'DeepLearning_grid_1_AutoML_20190130_220356_model_2', 'DeepLearning_grid_1_AutoML_20190130_220356_model_4', 'XGBoost_grid_1_AutoML_20190130_220356_model_2', 'DeepLearning_grid_1_AutoML_20190130_220356_model_1', 'DeepLearning_1_AutoML_20190130_220356', 'StackedEnsemble_AllModels_AutoML_20190130_220356', 'XGBoost_1_AutoML_20190130_220356', 'XGBoost_grid_1_AutoML_20190130_220356_model_6', 'GBM_grid_1_AutoML_20190130_220356_model_1', 'DeepLearning_grid_1_AutoML_20190130_220356_model_3', 'XGBoost_2_AutoML_20190130_220356', 'XGBoost_3_AutoML_20190130_220356', 'StackedEnsemble_BestOfFamily_AutoML_20190130_220356', 'XGBoost_grid_1_AutoML_20190130_220356_model_4', 'XGBoost_grid_1_AutoML_20190130_220356_model_7', 'XGBoost_grid_1_AutoML_20190130_220356_model_3', 'XGBoost_grid_1_AutoML_20190130_220356_model_5']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'H2OGradientBoostingEstimator' has no attribute 'metalearner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-91286988fdd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Get the Stacked Ensemble metalearner model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmetalearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetalearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmetalearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-5.1.0.1/lib/python3.6/site-packages/h2o/utils/backward_compatibility.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bcin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Make sure that we look up any names not found on the instance also in the class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-5.1.0.1/lib/python3.6/site-packages/h2o/utils/backward_compatibility.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# print(\"Warning: Method %s in class %s is deprecated.\" % (name, cls.__name__))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'H2OGradientBoostingEstimator' has no attribute 'metalearner'"
     ]
    }
   ],
   "source": [
    "# Get model ids for all models in the AutoML Leaderboard\n",
    "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
    "\n",
    "print(model_ids)\n",
    "# Get the \"All Models\" Stacked Ensemble model\n",
    "se = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])\n",
    "\n",
    "# Get the Stacked Ensemble metalearner model\n",
    "metalearner = h2o.get_model(aml.leader.metalearner()['name'])\n",
    "metalearner.coef_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metalearner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-5a4538925986>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetalearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd_coef_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metalearner' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "metalearner.std_coef_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/siemanalyst/projects/logs-archive-production/fraud-canada-tokenizedwords/product_model_bin/ngrams15_features85_vectors_m25/v5/mojo/GBM_grid_1_AutoML_20190130_220356_model_2.zip'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.download_mojo(path = \"./product_model_bin/ngrams15_features85_vectors_m25/v5/mojo\", get_genmodel_jar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>hash_message                                                                                                                    </th><th style=\"text-align: right;\">  fraud_label</th><th style=\"text-align: right;\">  kl_words</th><th style=\"text-align: right;\">  ks_words</th><th style=\"text-align: right;\">  entropy_words</th><th style=\"text-align: right;\">  features85_type</th><th style=\"text-align: right;\">  features85_size</th><th style=\"text-align: right;\">  ngramscounts15_type</th><th style=\"text-align: right;\">  ngramscounts15_size</th><th>features85_list_indices  </th><th>features85_list_values  </th><th>ngramscounts15_list_indices                                  </th><th>ngramscounts15_list_values                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>7ff628bb5dad0bc3bfaace8dcaf726381c929567fd826cab34bcb1105bf7163d46bd0fedff87bb7f862c65062c6f66d3e180bc017dd8bcb86b7f0f339cca7e49</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   2490.75</td><td style=\"text-align: right;\"> 0.821826 </td><td style=\"text-align: right;\">      0.072336 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n",
       " 26 27 28 29 30 31 32 33 34 36 40 41 42 43 44 45 46 55 57 60 63 64 73]                          </td><td>[2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1.]                         </td><td>[   178    179    415    416    417    418    526    527    760    761\n",
       "    763    764    766    767    768    769    770    771    773   4113\n",
       "   4125   4126   4737  28419  28512  29638 104230]                                                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1.]                                                              </td></tr>\n",
       "<tr><td>80f857718be06e2b40b853bca245aa2f837e3819078437c26f1d698066f3fb109b59a0c576124d19cf77ae4e84da945bf851a44ba51e1b7e5979f4b1743a269b</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   2775.72</td><td style=\"text-align: right;\"> 0.976169 </td><td style=\"text-align: right;\">      0.0603987</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
       " 48 49 51 52 53 54 56 59 61 62 64 65]                          </td><td>[2. 2. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[    0     2     3     4     5     6     7     8     9   400   401   402\n",
       "   403   404   408   409   410   411   412   413   414   947   952   959\n",
       "  1350  1353  1360  1362  3204  4593 16233 23858 23885 23953 24121 24286\n",
       " 24444 24618 24882 25389 25406 25534 25579 25714 25988 26215 30530 30603\n",
       " 30624 30642 30933 31189 31319 31396 31521 31563 31578 31806 31909 31935\n",
       " 31956 32603 33781 34002 34113 34320]                                                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                                                              </td></tr>\n",
       "<tr><td>8304b24b1f8c03a69df330a2aa87776e29410e861b0fe6341c9ad39a3aeffcbb60fc0512edf219f2d222a2674955b6e6fbf9db39596c8e1643739f41c0e2be8f</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   5737.85</td><td style=\"text-align: right;\"> 0.0550782</td><td style=\"text-align: right;\">      0.0656338</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 38 39 40 41 47 48 49 50 51 52 53 54 58\n",
       " 60 66 67 68 69 70 71 72 79 80]                          </td><td>[4. 2. 3. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[    27     28     29     30     31     32     36     37     38     39\n",
       "     40     41     42     43     50     51    106    107    108    111\n",
       "    112    113    114    115    116    117    118    119    120    121\n",
       "    122    123    264    265    266    364    365    366 136630 141088\n",
       " 142829 158344 182909]                                                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                                                              </td></tr>\n",
       "<tr><td>83ab14f4f479c67c6604658cca2ae22c4ddaad756aaff0dc31ee0b1d2c17760d4d1a987fc6b8a704c0a17e02b841955152eabfb2973c5c844072290462fa56d2</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   5135.05</td><td style=\"text-align: right;\"> 0.0752156</td><td style=\"text-align: right;\">      0.0678134</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 47 48 49 51 52 53\n",
       " 54 56 58 59 60 67 68 69 70 71 72 76 77 81 82 84]                          </td><td>[5. 2. 3. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[    49     52     53     54     66     67     68     69     70     71\n",
       "     72     73     74     75     77     78     79     80     81     82\n",
       "     83     84     85     86     87     88     89     90     91     92\n",
       "     93     94    102    103    135    136    137    152    153    154\n",
       "    155    156    157    158    159    160    161  51925  52939  53513\n",
       "  53764  56573 137337 190238]                                                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1.]                                                              </td></tr>\n",
       "<tr><td>8501af76c1df0f17b32813227e7efb1ff66690fcb8d2e4aeb410218e2bf677479a7a98d91a7c068ea33dc23d95b897a3491e73cde06b34ba6e1cf3f84d2fcbb1</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   5228.51</td><td style=\"text-align: right;\"> 0.116499 </td><td style=\"text-align: right;\">      0.0722532</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 47 48 49 51 52 53\n",
       " 54 56 59 60 63 65 67 68 69 70 71 72 76 77 79 81 82 84]                          </td><td>[4. 2. 3. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[    0    10    11    12    13    14    15    16    22    23    24    25\n",
       "    26    49    52    53    54    55    56    76   100   101   167   168\n",
       "   169   170   171   172   173   245   246   247   248   249   250   251\n",
       "   252   253   254   471  4931 12825 13263 13397 17631 17681 17743 18975\n",
       " 19124 19535 20107 21011]                                                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1.]                                                              </td></tr>\n",
       "<tr><td>87487ff3efc0e894b97b6fe6476242b9f9876790f7f6ff2071cfa9ad9b717bb6125ddbab279f8288c061eb6c4e343e45e960dd4a2cff34a819a9fb8c2a648b05</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   2058.8 </td><td style=\"text-align: right;\"> 0.0734484</td><td style=\"text-align: right;\">      0.0754564</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
       " 25 26 27 28 29 30 31 32 33 34 36 40 41 42 43 44 45 46 55 60]                          </td><td>[1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[  129   636   637   638   639   640   641   642  1005  1006  1008 35402\n",
       " 49247 50129 50963 54319 58161 58250 59364 59645]                                                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]</td></tr>\n",
       "<tr><td>88ada1a0c6826c40389a5688265c408cd01183cbd98f3c361be101b70099faf8049d048bbfe92b2b320bc48af45316091881f0797325b332551f7b1c8a0efce2</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   4404.35</td><td style=\"text-align: right;\"> 0.127265 </td><td style=\"text-align: right;\">      0.0581306</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
       " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 47 48 49 51 52 53 54\n",
       " 56 59 60 65 67 68 69 70 71 72 76 77 79 81 82 84]                          </td><td>[4. 2. 3. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                         </td><td>[    22     23     24     25     26     54    100    101    167    168\n",
       "    169    170    171    172    173    244    245    246    247    248\n",
       "    249    250    251    252    253    254    471    476    477    478\n",
       "    479    480    481    482    634    635    742    774    779   1033\n",
       "   4895   4910   4912   5788   5838   5877  11461  11591  11747  11798\n",
       "  11829  35812  40670 129276 136372 136509 141213 147527 147620 148039\n",
       " 156729]                                                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                                                              </td></tr>\n",
       "<tr><td>8b655e8b3181dc87aeb49e8ce9348ca9bb84929e172292c671ab32b5bce1852592ba980798acd89e52e0e41da3befdc6a1ef98bf98a1d92b01e239516b42829b</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   3615.41</td><td style=\"text-align: right;\"> 0.750373 </td><td style=\"text-align: right;\">      0.0469706</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
       " 51 52 53 54 55 56 57 60 63 64 66 78 80]                          </td><td>[3. 2. 2. 3. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2.\n",
       " 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1.]                         </td><td>[    1    19    20    21    33    34    35   912   914   915   916   919\n",
       "   920   921   922   923   924   925   926   928   929   930   931   932\n",
       "   933   935   936   937  1243  1402  2867  4124  4140  4163  4191 23762\n",
       " 29642 75199 75769 76361 76378 76785 76886 77966 79281 79538 81182 81439\n",
       " 82900 82927 85470 87115 88827 89265 90652 94749 95428 95692 96459 96672\n",
       " 97140 97617]                                                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                                                              </td></tr>\n",
       "<tr><td>8b691e13e7211ccb3e02c0df2a9022c45e6c639f60ca8ffb4354152ab0c6aab2891af8e06165b395b59271d45feddb2f601eef72d9a48439f251952db95cfd64</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   2240.16</td><td style=\"text-align: right;\"> 0.336851 </td><td style=\"text-align: right;\">      0.0525792</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
       " 24 25 26 27 28 29 30 31 32 33 34 36 38 39 40 41 42 43 44 45 46 47 48 49\n",
       " 50 51 52 53 54 55 56 57 63 65 83]                          </td><td>[2. 2. 2. 3. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1.]                         </td><td>[     0      1     19     20     21    146    228    229    230    231\n",
       "    232    233    234    235    236    437    438    439    440    441\n",
       "    442    443    444    445    446    447    448    470    472   1015\n",
       "   1156   1379   1892  10207  52215  53446  53926  58207  59293  60019\n",
       " 127377 128181 128985 145963 146751 151834 152044 166779 169030 175427\n",
       " 176620 177270 177881 182971 186826]                                                              </td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1.]                                                              </td></tr>\n",
       "<tr><td>8c80692a3319a417bef43be5d755db431cb10119339800b0dea6fff5d2342617e61c20b0e19009f090e8cac1df41247215c3394589d0f9b1bdb1c3f0b116f8e5</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   3042.87</td><td style=\"text-align: right;\"> 0.592092 </td><td style=\"text-align: right;\">      0.0675242</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td><td>[ 0  1  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
       " 25 26 27 28 29 30 31 32 33 34 36 42 43 44 45 46 50 61 62 66 73 75 78 80]                          </td><td>[1. 4. 3. 1. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 3. 1. 1. 1. 1. 3. 1. 1.]                         </td><td>[  61 1949 1952 1953 1955 1956 1958 1961 1962 3427 3437 3444]</td><td>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]                        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">  p0</th><th style=\"text-align: right;\">         p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">1.44665e-09</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">6.52822e-10</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">6.52819e-10</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">6.52738e-10</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">6.77597e-10</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">6.53135e-10</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">6.52821e-10</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">6.52298e-10</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">6.52803e-10</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">6.52129e-10</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# If you need to generate predictions on a test set, you can make\n",
    "# predictions directly on the `\"H2OAutoML\"` object, or on the leader\n",
    "# model object directly\n",
    "\n",
    "#preds = aml.predict(test)\n",
    "# or:\n",
    "preds = aml.leader.predict(test)\n",
    "print(\"test\")\n",
    "print(test.tail(10))\n",
    "print(\"prediction\")\n",
    "print(preds.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
