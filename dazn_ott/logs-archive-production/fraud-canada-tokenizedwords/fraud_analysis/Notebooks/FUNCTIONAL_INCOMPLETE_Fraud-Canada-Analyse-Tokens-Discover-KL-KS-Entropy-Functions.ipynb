{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- awsRegion: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- correlationId: string (nullable = true)\n",
      " |-- function_version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- hostname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- invoked_function_arn: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- level: long (nullable = true)\n",
      " |-- logGroup: string (nullable = true)\n",
      " |-- logStream: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messageType: string (nullable = true)\n",
      " |-- msg: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- owner: string (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- token: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- awsRegion: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- correlationId: string (nullable = true)\n",
      " |-- function_version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- hostname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- invoked_function_arn: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- level: long (nullable = true)\n",
      " |-- logGroup: string (nullable = true)\n",
      " |-- logStream: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messageType: string (nullable = true)\n",
      " |-- msg: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- owner: string (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- token: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- awsRegion: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- correlationId: string (nullable = true)\n",
      " |-- function_version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- hostname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- invoked_function_arn: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- level: long (nullable = true)\n",
      " |-- logGroup: string (nullable = true)\n",
      " |-- logStream: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messageType: string (nullable = true)\n",
      " |-- msg: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- owner: string (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- token: string (nullable = true)\n",
      " |-- messagecut: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messagecut: string (nullable = true)\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- message: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- @metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- @timestamp: string (nullable = true)\n",
      " |-- __logz_account_id: string (nullable = true)\n",
      " |-- __logz_received_timestamp: string (nullable = true)\n",
      " |-- __logzio_X-B3-Sampled: string (nullable = true)\n",
      " |-- __logzio_X-B3-SpanId: string (nullable = true)\n",
      " |-- __logzio_X-B3-TraceId: string (nullable = true)\n",
      " |-- __logzio_id: string (nullable = true)\n",
      " |-- beat: struct (nullable = true)\n",
      " |    |-- hostname: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |-- host: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- input_type: string (nullable = true)\n",
      " |-- it: string (nullable = true)\n",
      " |-- logzio_codec: string (nullable = true)\n",
      " |-- logzio_id: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- messagecut: string (nullable = true)\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- beat: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- message: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngrams_15: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- ngramscounts_15: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngrams_15: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- ngramscounts_15: vector (nullable = true)\n",
      " |-- features_85: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_15: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_15: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "Calculation of standard_fraud_ngram - Start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      "\n",
      "Value Print: standard_fraud_ngram=\n",
      "                                        hash_message\n",
      "0  deb7454c80749f06dc2cfc384c4b59fdb891965dbf1432...\n",
      "Calculation of standard_fraud_ngram - Done!\n",
      "Preparation of Data Done!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "#\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "#\n",
    "#import org.apache.spark.ml.feature.NGram\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from collections import Counter\n",
    "#\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from pyspark.ml.feature import NGram, CountVectorizer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "#\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "#\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "#\n",
    "#\n",
    "#\n",
    "# Ugly workarround to increase spark.kryoserializer.buffer.max\n",
    "# Only way in session to Run :\n",
    "#        - treeAggregate at RowMatrix.scala:122 \n",
    "#        - first at PCA.scala:43\n",
    "#\n",
    "sc = pyspark.SparkContext()\n",
    "#conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','2047mb'),('spark.driver.memory','23g'),('spark.driver.maxResultSize','21g')])\n",
    "conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','512mb')])\n",
    "sc.stop()\n",
    "sc = pyspark.SparkContext(conf=conf,appName=\"Notebook-FraudCanada-Model-NGrams-CountVectorizer-KL-KS-Entropy-Model-CleanData\")\n",
    "sqlContext = SQLContext(sc)\n",
    "#\n",
    "#\n",
    "# Arguments\n",
    "#\n",
    "#import argparse\n",
    "## Parse date_of execution\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"--datev1\", help=\"Execution Date\")\n",
    "#args = parser.parse_args()\n",
    "#if args.datev1:\n",
    "#    processdate = args.datev1\n",
    "# GENERAL PREPARATION SCRIPT\n",
    "#\n",
    "#  Date in format YYYYMMDD\n",
    "#process_date = processdate\n",
    "#if not process_date:\n",
    "#    process_date = \"20181231\"\n",
    "#\n",
    "process_date=\"20190122\"\n",
    "#\n",
    "input_file1_playback_fraud=\"hdfs:///data/staged/ott_dazn/fraud-canada-tokenizedwords/dt=*/*.json\"\n",
    "output_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-15-features-85/dt=\"+process_date\n",
    "#\n",
    "input_file2_playback_not_fraud=\"hdfs:///data/staged/ott_dazn/logs-archive-production/parquet/dt=\"+process_date+\"/*.parquet\"\n",
    "output_file2=\"hdfs:///data/staged/ott_dazn/advanced-model-data/not-fraud-canada-tokenizedwords/dt=\"+process_date\n",
    "input_file3=output_file2\n",
    "#\n",
    "input_file4=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-15-features-85/dt=\"+process_date+\"/*.*\"\n",
    "#\n",
    "output_most_frequent_df=\"hdfs:///data/staged/ott_dazn/advanced-model-data/the-most-frequent-fraud-hash_message/dt=\"+process_date\n",
    "#\n",
    "#  FILTER Non-Fraud AND LABEL\n",
    "from pyspark.sql import functions as F\n",
    "#\n",
    "#\n",
    "df2= sqlContext.read.parquet(input_file2_playback_not_fraud)\n",
    "df2.printSchema()\n",
    "#\n",
    "df3 = df2.filter(\" (message LIKE '%\\\"Url\\\":\\\"https://isl-ca.dazn.com/misl/v2/Playback%') AND (message LIKE '%,\\\"Response\\\":{\\\"StatusCode\\\":200,\\\"ReasonPhrase\\\":\\\"OK\\\",%') AND ( ( (message LIKE '%&Format=MPEG-DASH&%' OR message LIKE '%&Format=M3U&%') ) OR (message NOT LIKE '%\\\"User-Agent\\\":\\\"Mozilla/5.0,(Macintosh; Intel Mac OS X 10_12_6),AppleWebKit/605.1.75,(KHTML, like Gecko),Version/11.1.2,Safari/605.1.75\\\"},%')   )  \")\n",
    "df3.printSchema()\n",
    "df4 = df3.withColumn(\"messagecut\", expr(\"substring(message, locate('|Livesport.WebApi.Controllers.Playback.PlaybackV2Controller|',message)+60 , length(message)-1)\"))\n",
    "#\n",
    "# val regexTokenizer = new RegexTokenizer().setInputCol(\"messagecut\").setOutputCol(\"words\").setPattern(\"\\\\w+|\").setGaps(false)\n",
    "#\n",
    "regexTokenizer = RegexTokenizer(minTokenLength=1, gaps=False, pattern='\\\\w+|', inputCol=\"messagecut\", outputCol=\"words\", toLowercase=True)\n",
    "#\n",
    "tokenized = regexTokenizer.transform(df4)\n",
    "tokenized.printSchema()\n",
    "tokenized.coalesce(1).write.json(output_file2)\n",
    "# Tokenize NON-Fraud-LABEL\n",
    "# hash the message de-duplicate those records\n",
    "notfraud_file=sqlContext.read.json(input_file3)\n",
    "notfraud_file.printSchema()\n",
    "#\n",
    "notfraud_df=notfraud_file\\\n",
    ".filter(\"message IS NOT NULL\").filter(\"words IS NOT NULL\")\\\n",
    ".withColumn('fraud_label',lit(0).cast('int'))\\\n",
    ".withColumn('hash_message',F.sha2(col('message'),512)).groupby(col('hash_message'))\\\n",
    ".agg(F.first(col('fraud_label')).alias('fraud_label'),F.first(col('words')).alias('words'),F.first(col('message')).alias('message'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "notfraud_df.printSchema()\n",
    "#\n",
    "df_notfraud_words = notfraud_df.filter(\"message IS NOT NULL\").select(col('fraud_label'),col('hash_message'),col('words'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "df_notfraud_words.printSchema()\n",
    "#\n",
    "# FILTER FRAUD AND LABEL \n",
    "# Join with Internal Curation Data in urltopredict staged folder\n",
    "# hash the message de-duplicate those records\n",
    "fraud_file=sqlContext.read.json(input_file1_playback_fraud)\n",
    "fraud_file.printSchema()\n",
    "#\n",
    "fraud_df=fraud_file\\\n",
    ".filter(\"message IS NOT NULL\").filter(\"words IS NOT NULL\")\\\n",
    ".withColumn('fraud_label',lit(1).cast('int'))\\\n",
    ".withColumn('hash_message',F.sha2(col('message'),512)).groupby(col('hash_message'))\\\n",
    ".agg(F.first(col('fraud_label')).alias('fraud_label'),F.first(col('words')).alias('words'),F.first(col('message')).alias('message'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "fraud_df.printSchema()\n",
    "#\n",
    "df_words = fraud_df.filter(\"message IS NOT NULL\").select(col('fraud_label'),col('hash_message'),col('words'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "df_words.printSchema()\n",
    "#\n",
    "result_fraud_nofraud_words = df_words.union(df_notfraud_words)\n",
    "## Register Generic Functions\n",
    "# -----------------------------------------------------------------------------\n",
    "# Build ngrams 75 90 n=6 \n",
    "# support : https://stackoverflow.com/questions/51473703/pyspark-ml-ngrams-countvectorizer-sorted-based-on-count-weights\n",
    "# -----------------------------------------------------------------------------\n",
    "def build_ngrams_part(inputCol=\"words\", n=6):\n",
    "    ngrams = [ \n",
    "        NGram(n=i, inputCol=\"words\", outputCol=\"ngrams_{0}\".format(i)) \n",
    "        for i in range(75, n + 1) ]\n",
    "    vectorizers = [ \n",
    "        CountVectorizer(inputCol=\"ngrams_{0}\".format(i), outputCol=\"ngramscounts_{0}\".format(i)) \n",
    "        for i in range(75, n + 1) ]\n",
    "    return Pipeline(stages=ngrams + vectorizers)\n",
    "#    assembler = [VectorAssembler( inputCols=[\"ngramscounts_{0}\".format(i) for i in range(1, n + 1)], outputCol=\"features\" )]\n",
    "#    return Pipeline(stages=ngrams + DenseVector(SparseVector(vectorizers).toArray()))\n",
    "#\n",
    "# \n",
    "# -----------------------------------------------------------------------------\n",
    "#ngram = build_ngrams_part().fit(df_words)\n",
    "#ngramDataFrame = ngram.transform(df_words)\n",
    "#ngramDataFrame.coalesce(1).write.json(output_file1)\n",
    "#\n",
    "ngram = NGram(n=15, inputCol=\"words\", outputCol=\"ngrams_15\")\n",
    "countvector = CountVectorizer(inputCol=\"ngrams_15\", outputCol=\"ngramscounts_15\")\n",
    "# fit a CountVectorizerModel from the corpus.\n",
    "countvModel = CountVectorizer(inputCol=\"words\", outputCol=\"features_85\", vocabSize=85, minDF=2.0)\n",
    "# fit a PCA Dimensionality reduction into 75/15=5 components from ngramscounts_75 ## Too Heavy 1st PCA\n",
    "pcaNgrams = PCA(k=5, inputCol=\"ngramscounts_15\", outputCol=\"pcaweightngrams\")\n",
    "# fit a PCA Dimensionality reduction into 75/15=5 components from words\n",
    "pcaWords = PCA(k=5, inputCol=\"features_85\", outputCol=\"pcaweightwords\")  ## Too Heavy 2nd PCA\n",
    "#\n",
    "ngram_fraud_DF = ngram.transform(result_fraud_nofraud_words)\n",
    "ngram_vc_fraud_DF = countvector.fit(ngram_fraud_DF).transform(ngram_fraud_DF)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "ngram_vc_fraud_DF.printSchema()\n",
    "#\n",
    "#modelPCA_ngram_fraud_DF = pcaNgrams.fit(ngram_vc_fraud_DF).transform(ngram_vc_fraud_DF)\\\n",
    "#.persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "#modelPCA_ngram_fraud_DF.printSchema()\n",
    "#\n",
    "#result_ngrams_words_fraud_DF = countvModel.fit(modelPCA_ngram_fraud_DF).transform(modelPCA_ngram_fraud_DF)\\\n",
    "result_ngrams_words_fraud_DF = countvModel.fit(ngram_vc_fraud_DF).transform(ngram_vc_fraud_DF)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "result_ngrams_words_fraud_DF.printSchema()\n",
    "#\n",
    "result_ngrams_words_fraud_DF.coalesce(1).write.json(output_file1)\n",
    "#\n",
    "#  CALCULATE KL,KS COEF. Label Data\n",
    "ngram15_fraud=sqlContext.read.json(input_file4).filter(\"fraud_label=0\" )\n",
    "ngram15_fraud.printSchema()\n",
    "#\n",
    "print(\"Calculation of standard_fraud_ngram - Start!\")\n",
    "#\n",
    "# Obtain the most frequent word on each position \n",
    "# Compose the standard_fraud_ngram from the most common positions\n",
    "#Â Calculate the standard_fraud_ngram\n",
    "#\n",
    "# https://stackoverflow.com/questions/35218882/find-maximum-row-per-group-in-spark-dataframe \n",
    "# Using struct ordering:\n",
    "#from pyspark.sql.functions import struct\n",
    "#\n",
    "#(cnts\n",
    "#  .groupBy(\"id_sa\")\n",
    "#  .agg(F.max(struct(col(\"cnt\"), col(\"id_sb\"))).alias(\"max\"))\n",
    "#  .select(col(\"id_sa\"), col(\"max.id_sb\")))\n",
    "#\n",
    "#Py4JJavaError: An error occurred while calling o3400.select.\n",
    "#: org.apache.spark.sql.AnalysisException: cannot resolve '`ngrams`' given input columns: [mostfrequent];;\n",
    "#'Project ['ngrams, mostfrequent#8033.count AS count#8037L]\n",
    "#+- AnalysisBarrier\n",
    "#      +- Aggregate [max(named_struct(count, count#8029L)) AS mostfrequent#8033]\n",
    "#         +- Aggregate [ngrams#8016], [ngrams#8016, count(1) AS count#8029L]\n",
    "#            +- Relation[fraud_label#8013L,hash_message#8014,message#8075,ngrams#8016,words#8017] json\n",
    "#\n",
    "####### OLD  ######\n",
    "#.groupby(col('hash_message'))\\\n",
    "#.agg(F.first(col('features_75')).alias('features_75'),\\\n",
    "#     F.first(col('fraud_label')).alias('fraud_label'),\\\n",
    "#     F.first(col('ngrams_75')).alias('ngrams_75'),\\\n",
    "#     F.first(col('ngramscounts_75')).alias('ngramscounts_75'),F.first(col('words')).alias('words'))\n",
    "####################\n",
    "#\n",
    "most_frequent_df=ngram15_fraud\\\n",
    ".withColumn(\"value_sum\",F.explode(\"ngramscounts_15.values\"))\\\n",
    ".groupBy(\"hash_message\").agg(F.sum(\"value_sum\").alias('count'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "most_frequent_df.printSchema()\n",
    "#\n",
    "most_frequent_df.coalesce(1).write.json(output_most_frequent_df)\n",
    "#\n",
    "# The most Frequent would the the max\n",
    "standard_fraud_ngram=most_frequent_df.orderBy(col('count').desc()).select(col('hash_message')).limit(1).toPandas()\n",
    "#\n",
    "print(\"Value Print: standard_fraud_ngram=\")\n",
    "print(standard_fraud_ngram)\n",
    "#\n",
    "print(\"Calculation of standard_fraud_ngram - Done!\")\n",
    "#\n",
    "sc.stop()\n",
    "#\n",
    "print(\"Preparation of Data Done!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value UDF : standard_fraud_ngram=\n",
      "c9b49b5510dc0c1f48de5a2b9e2d94682902ea27525fec5d9c6cd176dd7bdb59e2ff6c21a6823ed83de3e19770eebb415589e71bdbc62ff7b1a7f1b69fbe5637\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_15: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_15: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_15: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_15: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- fraud_master_hash: string (nullable = false)\n",
      "\n",
      "Value UDF : standard_words=\n",
      "c9b49b5510dc0c1f48de5a2b9e2d94682902ea27525fec5d9c6cd176dd7bdb59e2ff6c21a6823ed83de3e19770eebb415589e71bdbc62ff7b1a7f1b69fbe5637\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngrams_15: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngramscounts_15: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- ngramscounts_15: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words_conc: string (nullable = false)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- entropy_words: double (nullable = true)\n",
      "\n",
      "Model Data KL,KS, Entropy Done! NGrams Vectors Data Done!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "#\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "#\n",
    "#import org.apache.spark.ml.feature.NGram\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from collections import Counter\n",
    "#\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from pyspark.ml.feature import NGram, CountVectorizer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "#\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "#\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "#\n",
    "#  FILTER with PySpark SQL Functions F.\n",
    "from pyspark.sql import functions as F\n",
    "# FUNCTIONS\n",
    "# \n",
    "##\n",
    "## Register Generic UDF Functions\n",
    "# -----------------------------------------------------------------------------\n",
    "# KL : Kullback-Leibler Divergence\n",
    "# KS : Kolmogorov-Smirnov ( Sample sizes can be different)\n",
    "# -----------------------------------------------------------------------------    \n",
    "## NGRAM hash_mesage KL from URL TO Default NGRAM KL\n",
    "def func_kl_ngram_msg(var1,var_match):\n",
    "    ##Making sure the analysis of has_message SHA_512 is linear.\n",
    "    ##Making sure the analysis is over the words list on same size\n",
    "    def KL(P,Q):\n",
    "        epsilon = 0.00001\n",
    "        P = P+epsilon\n",
    "        Q = Q+epsilon\n",
    "        divergence = np.sum(P*np.log(P/Q))\n",
    "        return np.asscalar(divergence)\n",
    "    ##Making sure the analysis ignore trash\n",
    "    cleanvar=var1.strip('http://').strip('https://').strip('www.')\n",
    "    len_var1=len(cleanvar)\n",
    "    idx_var1=cleanvar[:4]# Use \"root1\" as baseline #cleanvar.split(\"/\")[0]#cleanvar[:8]\n",
    "    list_values1 = list(cleanvar)\n",
    "    list_of_ord_values1 = [ord(char) for char in list_values1]\n",
    "    values1 = np.asarray(list_of_ord_values1)\n",
    "    # URLS with at least 4166 characters\n",
    "    ## TODO : Complete this list with common Malware/phishing sites used in internal webtraffic\n",
    "    list_values2 = var_match\n",
    "    list_values2 += var_match\n",
    "    ## Making sure the analysis start on the same webdomain name\n",
    "    idx_var2 = list_values2.find(idx_var1)\n",
    "    start_values2 = list_values2[idx_var2:(idx_var2+len_var1)]\n",
    "    list_values2 = list(start_values2+list_values2)\n",
    "    list_values2 = list_values2[:len_var1]\n",
    "    list_of_ord_values2 = [ord(char) for char in list_values2]\n",
    "    values2 = np.asarray(list_of_ord_values2)\n",
    "    return KL(values1,values2)\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "## NGRAM hash_message \"Kolmogorov-Smirnov test KS pvalue= ks_2samp function8.\n",
    "def func_ks_ngram_msg(var1,var_match):\n",
    "    ##Making sure the analysis of has_message SHA_512 is linear.\n",
    "    ##Making sure the analysis is over the words list on same size\n",
    "    cleanvar=var1.strip('http://').strip('https://').strip('www.')\n",
    "    len_var1=len(cleanvar)\n",
    "    idx_var1=cleanvar[:4]# Use \"root1\" as baseline #cleanvar.split(\"/\")[0]#cleanvar[:8]\n",
    "    list_values1 = list(cleanvar)\n",
    "    list_of_ord_values1 = [ord(char) for char in list_values1]\n",
    "    values1 = np.asarray(list_of_ord_values1)\n",
    "    values1= np.sort(values1)\n",
    "    # URLS with up to least 4166 characters\n",
    "    list_values2 = var_match\n",
    "    list_values2 += var_match\n",
    "    ## Making sure the analysis start on the same messgae\n",
    "    idx_var2 = list_values2.find(idx_var1)\n",
    "    start_values2 = list_values2[idx_var2:(idx_var2+len_var1)]\n",
    "    list_values2 = list(start_values2+list_values2)\n",
    "    list_values2 = list_values2[:len_var1]\n",
    "    list_of_ord_values2 = [ord(char) for char in list_values2]\n",
    "    values2 = np.asarray(list_of_ord_values2)\n",
    "    values2=np.sort(values2)\n",
    "    (Darray,pvalue)=stats.ks_2samp(values1, values2)\n",
    "    return np.asscalar(pvalue)\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "## Entropy TO hash_message function3.\n",
    "def func_entropy_ngram_msg(var1,var_match):\n",
    "    ##Making sure the analysis of has_message SHA_512 is linear.\n",
    "    ##Making sure the analysis is over the words list ignore size\n",
    "    #\n",
    "    cleanvar=var1.strip('http://').strip('https://').strip('www.')\n",
    "    len_var1=len(cleanvar)\n",
    "    idx_var1=cleanvar[:4]# Use \"root1\" as baseline #cleanvar.split(\"/\")[0]#cleanvar[:8]\n",
    "    list_values1 = list(cleanvar)\n",
    "    list_of_ord_values1 = [ord(char) for char in list_values1]\n",
    "    values1 = np.asarray(list_of_ord_values1)\n",
    "    # URLS with at least 4166 characters\n",
    "    ## TODO : Complete this list with an NGRAM search\n",
    "    list_values2 = var_match\n",
    "    list_values2 += var_match\n",
    "    ## Making sure the analysis start on point\n",
    "    idx_var2 = list_values2.find(idx_var1)\n",
    "    start_values2 = list_values2[idx_var2:(idx_var2+len_var1)]\n",
    "    list_values2 = list(start_values2+list_values2)\n",
    "    list_values2 = list_values2[:len_var1]\n",
    "    list_of_ord_values2 = [ord(char) for char in list_values2]\n",
    "    values2 = np.asarray(list_of_ord_values2)\n",
    "    pvalue=stats.entropy(values1, values2)\n",
    "    scalar_pvalue=np.asscalar(pvalue)\n",
    "    return scalar_pvalue\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "# -----------------------------------------------------------------------------\n",
    "func_kl_ngram_msg_udf = udf(func_kl_ngram_msg, FloatType())\n",
    "func_ks_ngram_msg_udf = udf(func_ks_ngram_msg, FloatType())\n",
    "func_entropy_ngram_msg_udf = udf(func_entropy_ngram_msg, FloatType())\n",
    "#\n",
    "# Arguments\n",
    "#\n",
    "import argparse\n",
    "## Parse date_of execution\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"--datev1\", help=\"Execution Date\")\n",
    "#args = parser.parse_args()\n",
    "#if args.datev1:\n",
    "#    processdate = args.datev1\n",
    "# GENERAL PREPARATION SCRIPT\n",
    "#\n",
    "#  Date in format YYYYMMDD\n",
    "#process_date = processdate\n",
    "#if not process_date:\n",
    "#    process_date = \"20181231\"\n",
    "#\n",
    "process_date=\"20190122\"\n",
    "#\n",
    "#\n",
    "sc = pyspark.SparkContext()\n",
    "#conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','2047mb'),('spark.driver.memory','23g'),('spark.driver.maxResultSize','21g')])\n",
    "conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','512mb')])\n",
    "sc.stop()\n",
    "sc.stop()\n",
    "sc = pyspark.SparkContext(conf=conf,appName=\"Notebook-FraudCanada-Model-NGrams-CountVectorizer-KL-KS-Entropy-Model-Labeling\")\n",
    "sqlContext = SQLContext(sc)\n",
    "# Clean up the cluster just in case\n",
    "h2o.remove_all()\n",
    "#\n",
    "input_most_frequent_df=\"hdfs:///data/staged/ott_dazn/advanced-model-data/the-most-frequent-fraud-hash_message/dt=\"+process_date\n",
    "input_fraud=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-15-features-85/dt=\"+process_date\n",
    "#\n",
    "input_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-15-features-85/dt=\"+process_date\n",
    "output_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/label-fraud-notfraud-data-model/dt=\"+process_date\n",
    "preserve_training_output_file=\"hdfs:///data/staged/ott_dazn/advanced-model-data/preserve-training-output-automl-clean/dt=\"+process_date\n",
    "#\n",
    "# The most Frequent would the ones with the max frequency of NGrams85 tokens\n",
    "pd.options.display.max_colwidth = 512\n",
    "#\n",
    "standard_fraud_ngram=sqlContext.read.json(input_most_frequent_df)\\\n",
    ".orderBy(col('count').desc()).select(col('hash_message')).limit(1).toPandas()['hash_message'][0]\n",
    "print(\"Value UDF : standard_fraud_ngram=\")\n",
    "print(standard_fraud_ngram)\n",
    "#\n",
    "# Select Tokens/words form the max frequency of NGrams85 tokens hash_message\n",
    "standard_fraud_ngram_words=sqlContext.read.json(input_fraud)\n",
    "standard_fraud_ngram_words.printSchema()\n",
    "#\n",
    "standard_words_search=standard_fraud_ngram_words\\\n",
    ".withColumn('fraud_master_hash',lit(standard_fraud_ngram).cast('string'))\\\n",
    ".filter(\" hash_message=fraud_master_hash \")\n",
    "standard_words_search.printSchema()\n",
    "#\n",
    "standard_words=standard_words_search\\\n",
    ".withColumn('words_conc',F.concat_ws('',col('words')).cast('string'))\\\n",
    ".select(col('words_conc')).limit(1).toPandas()['words_conc'][0] \n",
    "# Working now! \n",
    "# Needs to be bigger than message twice should be tested!\n",
    "#   Py4JJavaError: An error occurred while calling z:org.apache.spark.sql.functions.lit.\n",
    "#      : java.lang.RuntimeException: Unsupported literal type class java.util.HashMap \n",
    "# {0=root15c466c8e6e8f9d17adb73426cd55c70f72b9f18e39e3455c9043a18b86b122b6requestmethodgeturlhttpsislcadazncommislv2playbackassetidfg5oon8sl71n1nfwuegbo8npgeventidarticleidfg5oon8sl71n1nfwuegbo8npgformatmpegdashplayeriddaznf3874e050812a853securetruelanguagecodeenlatitudenulllongitudenullplatformandroidtvmanufacturernvidiamodelnullmtalanguagecodeenclientip50100225179headersuseragentmozilla50linuxandroid800shieldandroidtvbuildopr6170623010wvapplewebkit53736khtmllikegeckoversion40chrome710357899mobilesafari53736fev1420typeinresponsestatuscode200reasonphraseokduration47jwtvieweridc2ebc25d8085deviceid993bf365c72c4b0b9168c2ebc25d8085f3874e050812a853userstatusactivepaid}\n",
    "#\n",
    "print(\"Value UDF : standard_words=\")\n",
    "print(standard_fraud_ngram)\n",
    "#\n",
    "ngram15_fraud=sqlContext.read.json(input_file1)\n",
    "ngram15_fraud.printSchema()\n",
    "#\n",
    "drop_phish_cols=['words','ngrams_15']\n",
    "#\n",
    "fraud_label_read_df=ngram15_fraud.filter(\"hash_message is not NULL\")\\\n",
    ".withColumn('words_conc',F.concat_ws('',col('words')).cast('string'))\\\n",
    "    .drop(*drop_phish_cols)\\\n",
    "    .withColumn('kl_words',func_kl_ngram_msg_udf(col('words_conc'),lit(standard_words).cast('string')).cast('double'))\\\n",
    "    .withColumn('ks_words',func_ks_ngram_msg_udf(col('words_conc'),lit(standard_words).cast('string')).cast('double'))\\\n",
    "    .withColumn('entropy_words',func_entropy_ngram_msg_udf(col('words_conc'),lit(standard_words).cast('string')).cast('double'))\\\n",
    "    .persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "fraud_label_read_df.printSchema()\n",
    "#\n",
    "fraud_label_read_df.coalesce(1).write.json(output_file1)\n",
    "#\n",
    "fraud_label_read_df.unpersist()\n",
    "#\n",
    "sc.stop()\n",
    "#\n",
    "print(\"Model Data KL,KS, Entropy Done! NGrams Vectors Data Done!\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>7 days 7 hours 25 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.0.1</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>3 months and 4 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_siemanalyst_f03p4d</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>4.651 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.4 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         7 days 7 hours 25 mins\n",
       "H2O cluster timezone:       UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.0.1\n",
       "H2O cluster version age:    3 months and 4 days\n",
       "H2O cluster name:           H2O_from_python_siemanalyst_f03p4d\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    4.651 Gb\n",
       "H2O cluster total cores:    12\n",
       "H2O cluster allowed cores:  12\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.4 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training Model NGrams Vectors KS KL Entropty\n",
      "root\n",
      " |-- entropy_words: double (nullable = true)\n",
      " |-- features_85: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- fraud_label: long (nullable = true)\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- ngramscounts_15: struct (nullable = true)\n",
      " |    |-- indices: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- size: long (nullable = true)\n",
      " |    |-- type: long (nullable = true)\n",
      " |    |-- values: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- words_conc: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- entropy_words: double (nullable = true)\n",
      " |-- features85_type: long (nullable = true)\n",
      " |-- features85_size: long (nullable = true)\n",
      " |-- features85_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- features85_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- ngramscounts15_type: long (nullable = true)\n",
      " |-- ngramscounts15_size: long (nullable = true)\n",
      " |-- ngramscounts15_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- ngramscounts15_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- entropy_words: double (nullable = true)\n",
      " |-- features85_type: long (nullable = true)\n",
      " |-- features85_size: long (nullable = true)\n",
      " |-- features85_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- features85_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- ngramscounts15_type: long (nullable = true)\n",
      " |-- ngramscounts15_size: long (nullable = true)\n",
      " |-- ngramscounts15_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- ngramscounts15_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- entropy_words: double (nullable = true)\n",
      " |-- features85_type: long (nullable = true)\n",
      " |-- features85_size: long (nullable = true)\n",
      " |-- features85_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- features85_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- ngramscounts15_type: long (nullable = true)\n",
      " |-- ngramscounts15_size: long (nullable = true)\n",
      " |-- ngramscounts15_indices: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- ngramscounts15_values: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- entropy_words: double (nullable = true)\n",
      " |-- features85_type: long (nullable = true)\n",
      " |-- features85_size: long (nullable = true)\n",
      " |-- ngramscounts15_type: long (nullable = true)\n",
      " |-- ngramscounts15_size: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- hash_message: string (nullable = true)\n",
      " |-- fraud_label: integer (nullable = true)\n",
      " |-- kl_words: double (nullable = true)\n",
      " |-- ks_words: double (nullable = true)\n",
      " |-- entropy_words: double (nullable = true)\n",
      " |-- features85_type: long (nullable = true)\n",
      " |-- features85_size: long (nullable = true)\n",
      " |-- ngramscounts15_type: long (nullable = true)\n",
      " |-- ngramscounts15_size: long (nullable = true)\n",
      "\n",
      "Parse progress: |âââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 100%\n",
      "Parse progress: |âââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 100%\n",
      "Parse progress: |âââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 100%\n",
      "Parse progress: |âââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 100%\n",
      "train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>hash_message                                                                                                                    </th><th style=\"text-align: right;\">  fraud_label</th><th style=\"text-align: right;\">  kl_words</th><th style=\"text-align: right;\">  ks_words</th><th style=\"text-align: right;\">  entropy_words</th><th style=\"text-align: right;\">  features85_type</th><th style=\"text-align: right;\">  features85_size</th><th style=\"text-align: right;\">  ngramscounts15_type</th><th style=\"text-align: right;\">  ngramscounts15_size</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>589ff83a30fa5d82563f0051bbd9f638d3dc7f102f8c78ab137c17b859e740de35348417e0deb2037cd0188c243c674100eb57f97450c4b942c9d3a1ef86a07b</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4446.55</td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.0719711</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>865fc00f8a94dd1c467c39753bfb2b18626f2827db85a05654caf048e657b6856afad3fef87873197e7f92e0ff760c8f04cd5484c910a037476643addfdb5c31</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   3287.65</td><td style=\"text-align: right;\">  0.947901</td><td style=\"text-align: right;\">      0.0696592</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>a659ae2c8efbde6eb990b90acae3e02f644e44cd1a3a9aa6490632209641eb5714bb4b740ddcbe95e50b5cd319a8725634ffea38ae633fd6ab1f7114ad8c17bd</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4169.68</td><td style=\"text-align: right;\">  0.52636 </td><td style=\"text-align: right;\">      0.0708245</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>d6d7bcd45dfa2fb6487352a532359f3f64afe250dacb422898ed9854af8992866bff17dac83f36763b46f2db2e0442fdf23fafdd58628636ca3395b6ef019a16</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4538.96</td><td style=\"text-align: right;\">  0.210665</td><td style=\"text-align: right;\">      0.0757622</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>da23c7d6b5dd13228bb9b8e5d3287463ca7b12fbc8a5c068ce2cf4ca3e7e89ca6990a4abfc69dcedd538ee916f64a8d5d0440d1ad309c9604efc9ad4074a81ed</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4378.87</td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.077328 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>980071f323752c9f7e987d2f657d244851b601c46ef50b2cd053d69ee9c3a7b413730fff5a68bea2dd9ada49d410f0c0f8165ad2a9096c2c419668df2b829de3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4222.18</td><td style=\"text-align: right;\">  0.523838</td><td style=\"text-align: right;\">      0.0740113</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>e38e2712270ef1f79716537aa2816eaab104a20e17c94df57b49b787cda6f8e96794acf70b302c9708e9573dda18e402c7e996ea14e537e736001b12070d7542</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4279.72</td><td style=\"text-align: right;\">  0.679739</td><td style=\"text-align: right;\">      0.0711178</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>26f328150124298822fc4a0be849251c3d3545dcb2495c71dc92a60d1629ea641ec4d24c7004a3d579df61f5ba7197ffe6e88e3efaee93d226270372ee87d4b2</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4375.28</td><td style=\"text-align: right;\">  0.386449</td><td style=\"text-align: right;\">      0.0745828</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>2b8a2419e7f2c6fecb549146c3d66ab9cae9839005d8f848d39313e49b34d22c18c6eb7e20b3b0c5291d4ad0f7f2b329423816423f62a40a7dae70870c2b7f9f</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4396.63</td><td style=\"text-align: right;\">  0.430514</td><td style=\"text-align: right;\">      0.0760735</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>67d469882a190b2d6262a34bcca389d43799a46e823c51da3c685150a32c5779132915cfd6cc965db7d7f92639dd725dad1e29d2f69598d63cdf1402d2fa66b3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4478.26</td><td style=\"text-align: right;\">  0.307116</td><td style=\"text-align: right;\">      0.073295 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>hash_message                                                                                                                    </th><th style=\"text-align: right;\">  fraud_label</th><th style=\"text-align: right;\">  kl_words</th><th style=\"text-align: right;\">  ks_words</th><th style=\"text-align: right;\">  entropy_words</th><th style=\"text-align: right;\">  features85_type</th><th style=\"text-align: right;\">  features85_size</th><th style=\"text-align: right;\">  ngramscounts15_type</th><th style=\"text-align: right;\">  ngramscounts15_size</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>589ff83a30fa5d82563f0051bbd9f638d3dc7f102f8c78ab137c17b859e740de35348417e0deb2037cd0188c243c674100eb57f97450c4b942c9d3a1ef86a07b</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4446.55</td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.0719711</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>865fc00f8a94dd1c467c39753bfb2b18626f2827db85a05654caf048e657b6856afad3fef87873197e7f92e0ff760c8f04cd5484c910a037476643addfdb5c31</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   3287.65</td><td style=\"text-align: right;\">  0.947901</td><td style=\"text-align: right;\">      0.0696592</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>a659ae2c8efbde6eb990b90acae3e02f644e44cd1a3a9aa6490632209641eb5714bb4b740ddcbe95e50b5cd319a8725634ffea38ae633fd6ab1f7114ad8c17bd</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4169.68</td><td style=\"text-align: right;\">  0.52636 </td><td style=\"text-align: right;\">      0.0708245</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>d6d7bcd45dfa2fb6487352a532359f3f64afe250dacb422898ed9854af8992866bff17dac83f36763b46f2db2e0442fdf23fafdd58628636ca3395b6ef019a16</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4538.96</td><td style=\"text-align: right;\">  0.210665</td><td style=\"text-align: right;\">      0.0757622</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>da23c7d6b5dd13228bb9b8e5d3287463ca7b12fbc8a5c068ce2cf4ca3e7e89ca6990a4abfc69dcedd538ee916f64a8d5d0440d1ad309c9604efc9ad4074a81ed</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4378.87</td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.077328 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>980071f323752c9f7e987d2f657d244851b601c46ef50b2cd053d69ee9c3a7b413730fff5a68bea2dd9ada49d410f0c0f8165ad2a9096c2c419668df2b829de3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4222.18</td><td style=\"text-align: right;\">  0.523838</td><td style=\"text-align: right;\">      0.0740113</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>e38e2712270ef1f79716537aa2816eaab104a20e17c94df57b49b787cda6f8e96794acf70b302c9708e9573dda18e402c7e996ea14e537e736001b12070d7542</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4279.72</td><td style=\"text-align: right;\">  0.679739</td><td style=\"text-align: right;\">      0.0711178</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>26f328150124298822fc4a0be849251c3d3545dcb2495c71dc92a60d1629ea641ec4d24c7004a3d579df61f5ba7197ffe6e88e3efaee93d226270372ee87d4b2</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4375.28</td><td style=\"text-align: right;\">  0.386449</td><td style=\"text-align: right;\">      0.0745828</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>2b8a2419e7f2c6fecb549146c3d66ab9cae9839005d8f848d39313e49b34d22c18c6eb7e20b3b0c5291d4ad0f7f2b329423816423f62a40a7dae70870c2b7f9f</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4396.63</td><td style=\"text-align: right;\">  0.430514</td><td style=\"text-align: right;\">      0.0760735</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>67d469882a190b2d6262a34bcca389d43799a46e823c51da3c685150a32c5779132915cfd6cc965db7d7f92639dd725dad1e29d2f69598d63cdf1402d2fa66b3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4478.26</td><td style=\"text-align: right;\">  0.307116</td><td style=\"text-align: right;\">      0.073295 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AutoML progress: |ââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 100%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preserve_training_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-af9e181faa61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0maml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m \u001b[0mpreserve_training_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreserve_training_output_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AutoML Modeling Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preserve_training_output' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "import findspark\n",
    "findspark.init()\n",
    "#\n",
    "import pyspark\n",
    "from pyspark.sql import functions as pfunc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Window, types\n",
    "#\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import *\n",
    "from scipy.stats import kstest\n",
    "from scipy import stats\n",
    "#\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "#\n",
    "#import org.apache.spark.ml.feature.NGram\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from collections import Counter\n",
    "#\n",
    "from pyspark.ml.feature import NGram\n",
    "#\n",
    "from pyspark.ml.feature import NGram, CountVectorizer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "#\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "#\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors\n",
    "#\n",
    "#  FILTER with PySpark SQL Functions F.\n",
    "#\n",
    "# Arguments\n",
    "#\n",
    "import argparse\n",
    "## Parse date_of execution\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"--datev1\", help=\"Execution Date\")\n",
    "#args = parser.parse_args()\n",
    "#if args.datev1:\n",
    "#    processdate = args.datev1\n",
    "# GENERAL PREPARATION SCRIPT\n",
    "#\n",
    "#  Date in format YYYYMMDD\n",
    "#process_date = processdate\n",
    "#if not process_date:\n",
    "#    process_date = \"20181231\"\n",
    "#\n",
    "process_date=\"20190122\"\n",
    "#\n",
    "#\n",
    "sc = pyspark.SparkContext()\n",
    "#conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','2047mb'),('spark.driver.memory','23g'),('spark.driver.maxResultSize','21g')])\n",
    "conf = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max','512mb'),('spark.driver.memory','16g'),('spark.driver.maxResultSize','12g')])\n",
    "sc.stop()\n",
    "sc.stop()\n",
    "sc = pyspark.SparkContext(conf=conf,appName=\"Notebook-FraudCanada-AUTOML-Model-NGrams-CountVectorizer-KL-KS-Entropy\")\n",
    "sqlContext = SQLContext(sc)\n",
    "# Clean up the cluster just in case\n",
    "#h2o.remove_all()\n",
    "#\n",
    "input_most_frequent_df=\"hdfs:///data/staged/ott_dazn/advanced-model-data/the-most-frequent-fraud-hash_message/dt=\"+process_date\n",
    "input_fraud=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-15-features-85/dt=\"+process_date\n",
    "#\n",
    "input_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/fraud-notfraud-canada-tokenizedwords-ngrams-15-features-85/dt=\"+process_date\n",
    "output_file1=\"hdfs:///data/staged/ott_dazn/advanced-model-data/label-fraud-notfraud-data-model/dt=\"+process_date\n",
    "preserve_training_input_file=\"hdfs:///data/staged/ott_dazn/advanced-model-data/preserve-training-output-automl-clean/dt=\"+process_date\n",
    "#\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "#\n",
    "import subprocess\n",
    "subprocess.run('unset http_proxy', shell=True)\n",
    "#\n",
    "# Start an H2O virtual cluster that uses 6 gigs of RAM and 6 cores\n",
    "h2o.init(ip=\"localhost\",port=54321,max_mem_size = \"6g\", nthreads = 6) \n",
    "#\n",
    "#  TRAINING PROCESS\n",
    "#\n",
    "print(\"Start Training Model NGrams Vectors KS KL Entropty\")\n",
    "#\n",
    "# Horrible code :: close your eyes, is ugly\n",
    "#\n",
    "fraud_label_read_file=sqlContext.read.json(output_file1)\n",
    "fraud_label_read_file.printSchema()\n",
    "#\n",
    "fraud_label_read_df=fraud_label_read_file\\\n",
    ".select(col('hash_message').cast('string'),col('fraud_label').cast('int'),\\\n",
    "        col('kl_words').cast('double'), col('ks_words').cast('double'),col('entropy_words').cast('double'),\\\n",
    "        col('features_85.type').alias('features85_type').cast('long'),\\\n",
    "        col('features_85.size').alias('features85_size').cast('long'),\\\n",
    "        col('features_85.indices').alias('features85_indices'),\\\n",
    "        col('features_85.values').alias('features85_values'),\\\n",
    "        col('ngramscounts_15.type').alias('ngramscounts15_type').cast('long'),\\\n",
    "        col('ngramscounts_15.size').alias('ngramscounts15_size').cast('long'),\\\n",
    "        col('ngramscounts_15.indices').alias('ngramscounts15_indices'),\\\n",
    "        col('ngramscounts_15.values').alias('ngramscounts15_values'))\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "fraud_label_read_df.printSchema()\n",
    "#\n",
    "# ABOVE ARE CASE ISSUES on struct Struct of features_85 and ngramscounts_15 \n",
    "# Both cares conversion to DF valide type list\n",
    "# Flat vars for each, individually and seperately from the original struct\n",
    "#\n",
    "# https://stackoverflow.com/questions/47401418/pyspark-conversion-to-array-types?rq=1 \n",
    "#\n",
    "#\n",
    "fraud_fraud_label_read_df=fraud_label_read_df.filter(\"fraud_label=1\")\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "notfraud_fraud_label_read_df=fraud_label_read_df.filter(\"fraud_label=0\")\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "#\n",
    "fraud_fraud_label_read_df.printSchema()\n",
    "notfraud_fraud_label_read_df.printSchema()\n",
    "#\n",
    "drop_list_cols=['features85_indices','features85_values','ngramscounts15_indices','ngramscounts15_values']\n",
    "#\n",
    "fraud_label_read_list_df=fraud_fraud_label_read_df\\\n",
    ".drop(*drop_list_cols)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "\n",
    "#.withColumn('features85_list_indices',F.explode(fraud_fraud_label_read_df['features85_indices']))\\\n",
    "#.withColumn('features85_list_values',F.explode(fraud_fraud_label_read_df['features85_values']))\\\n",
    "#.withColumn('ngramscounts15_list_indices',F.explode(fraud_fraud_label_read_df['ngramscounts15_indices']))\\\n",
    "#.withColumn('ngramscounts15_list_values',F.explode(fraud_fraud_label_read_df['ngramscounts15_values']))\\\n",
    "\n",
    "fraud_label_read_list_df.printSchema()\n",
    "#\n",
    "notfraud_label_read_list_df=notfraud_fraud_label_read_df\\\n",
    ".drop(*drop_list_cols)\\\n",
    ".persist(pyspark.StorageLevel.MEMORY_AND_DISK_2)\n",
    "\n",
    "#.withColumn('features85_list_indices',F.explode(notfraud_fraud_label_read_df['features85_indices']))\\\n",
    "#.withColumn('features85_list_values',F.explode(notfraud_fraud_label_read_df['features85_values']))\\\n",
    "#.withColumn('ngramscounts15_list_indices',F.explode(notfraud_fraud_label_read_df['ngramscounts15_indices']))\\\n",
    "#.withColumn('ngramscounts15_list_values',F.explode(notfraud_fraud_label_read_df['ngramscounts15_values']))\\\n",
    "\n",
    "notfraud_label_read_list_df.printSchema()\n",
    "#\n",
    "fraud_label_train_pd=fraud_label_read_list_df.toPandas().head(1200)\n",
    "fraud_label_test_pd=fraud_label_read_list_df.toPandas().head(200)\n",
    "#\n",
    "not_fraud_label_train_pd=notfraud_label_read_list_df.toPandas().head(5000)\n",
    "not_fraud_label_test_pd=notfraud_label_read_list_df.toPandas().head(800)\n",
    "#\n",
    "fraud_label_train=h2o.H2OFrame(fraud_label_train_pd)\n",
    "fraud_label_test=h2o.H2OFrame(fraud_label_test_pd)\n",
    "not_fraud_label_train=h2o.H2OFrame(not_fraud_label_train_pd)\n",
    "not_fraud_label_test=h2o.H2OFrame(not_fraud_label_test_pd)\n",
    "#\n",
    "#\n",
    "###### TRAINING PROCESS ############\n",
    "# RBIND \"Merge\" all of 3 internal ccrawl and phishtank with rbind .\n",
    "# function merge() doesn't work if both H2O/dataframes have same variables\n",
    "#\n",
    "train = fraud_label_train.rbind(not_fraud_label_train)\n",
    "test = fraud_label_test.rbind(not_fraud_label_test)\n",
    "#\n",
    "#\n",
    "print(\"train\")\n",
    "print(train.head(10))\n",
    "print(\"test\")\n",
    "print(test.head(10))\n",
    "#\n",
    "# Identify predictors and response\n",
    "x = train.columns\n",
    "#\n",
    "#Â Fraud Label to be learned in the model from the atrributes of the ngram85 learned words\n",
    "#\n",
    "y= 'fraud_label'\n",
    "x.remove(y)\n",
    "#\n",
    "# For binary classification, response should be a factor\n",
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()\n",
    "#\n",
    "# http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html\n",
    "#Â Balance Classes to compensate unbalanced data\n",
    "# Run AutoML for 25 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=25, seed=19, exclude_algos=[\"DRF\",\"GLM\"])\n",
    "aml.train(x=x, y=y, training_frame=train)\n",
    "#\n",
    "preserve_training_output.write.json(preserve_training_output_file)\n",
    "#\n",
    "print(\"AutoML Modeling Done!\")\n",
    "#\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190130_213207_model_2      </td><td style=\"text-align: right;\">0.994524</td><td style=\"text-align: right;\">0.0731637</td><td style=\"text-align: right;\">             0.0434139</td><td style=\"text-align: right;\">0.142152</td><td style=\"text-align: right;\">0.0202072</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20190130_213207   </td><td style=\"text-align: right;\">0.994294</td><td style=\"text-align: right;\">0.0682131</td><td style=\"text-align: right;\">             0.034423 </td><td style=\"text-align: right;\">0.132719</td><td style=\"text-align: right;\">0.0176144</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190130_213207_model_1      </td><td style=\"text-align: right;\">0.994235</td><td style=\"text-align: right;\">0.0750265</td><td style=\"text-align: right;\">             0.0340106</td><td style=\"text-align: right;\">0.144406</td><td style=\"text-align: right;\">0.020853 </td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190130_213207_model_1          </td><td style=\"text-align: right;\">0.994129</td><td style=\"text-align: right;\">0.0779176</td><td style=\"text-align: right;\">             0.0376953</td><td style=\"text-align: right;\">0.142167</td><td style=\"text-align: right;\">0.0202115</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190130_213207_model_6      </td><td style=\"text-align: right;\">0.993964</td><td style=\"text-align: right;\">0.0772932</td><td style=\"text-align: right;\">             0.042875 </td><td style=\"text-align: right;\">0.14824 </td><td style=\"text-align: right;\">0.021975 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20190130_213207</td><td style=\"text-align: right;\">0.993638</td><td style=\"text-align: right;\">0.0750295</td><td style=\"text-align: right;\">             0.0345494</td><td style=\"text-align: right;\">0.139629</td><td style=\"text-align: right;\">0.0194962</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20190130_213207                       </td><td style=\"text-align: right;\">0.993635</td><td style=\"text-align: right;\">0.0802924</td><td style=\"text-align: right;\">             0.0354673</td><td style=\"text-align: right;\">0.151995</td><td style=\"text-align: right;\">0.0231026</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20190130_213207                       </td><td style=\"text-align: right;\">0.993574</td><td style=\"text-align: right;\">0.0799796</td><td style=\"text-align: right;\">             0.0416138</td><td style=\"text-align: right;\">0.151812</td><td style=\"text-align: right;\">0.0230468</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20190130_213207                       </td><td style=\"text-align: right;\">0.993503</td><td style=\"text-align: right;\">0.0801933</td><td style=\"text-align: right;\">             0.0449278</td><td style=\"text-align: right;\">0.151601</td><td style=\"text-align: right;\">0.0229828</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20190130_213207                       </td><td style=\"text-align: right;\">0.993485</td><td style=\"text-align: right;\">0.0801716</td><td style=\"text-align: right;\">             0.0393929</td><td style=\"text-align: right;\">0.15122 </td><td style=\"text-align: right;\">0.0228675</td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_20190130_213207                   </td><td style=\"text-align: right;\">0.993141</td><td style=\"text-align: right;\">0.0834322</td><td style=\"text-align: right;\">             0.0402989</td><td style=\"text-align: right;\">0.154444</td><td style=\"text-align: right;\">0.0238529</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190130_213207_model_3          </td><td style=\"text-align: right;\">0.992966</td><td style=\"text-align: right;\">0.0840037</td><td style=\"text-align: right;\">             0.0422217</td><td style=\"text-align: right;\">0.15564 </td><td style=\"text-align: right;\">0.0242237</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190130_213207_model_2          </td><td style=\"text-align: right;\">0.992865</td><td style=\"text-align: right;\">0.0909371</td><td style=\"text-align: right;\">             0.0417973</td><td style=\"text-align: right;\">0.158593</td><td style=\"text-align: right;\">0.0251518</td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_20190130_213207                   </td><td style=\"text-align: right;\">0.991797</td><td style=\"text-align: right;\">0.0927554</td><td style=\"text-align: right;\">             0.0550082</td><td style=\"text-align: right;\">0.16456 </td><td style=\"text-align: right;\">0.0270799</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20190130_213207                       </td><td style=\"text-align: right;\">0.990513</td><td style=\"text-align: right;\">0.0984945</td><td style=\"text-align: right;\">             0.0584641</td><td style=\"text-align: right;\">0.171795</td><td style=\"text-align: right;\">0.0295136</td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_20190130_213207                   </td><td style=\"text-align: right;\">0.990064</td><td style=\"text-align: right;\">0.103385 </td><td style=\"text-align: right;\">             0.0546684</td><td style=\"text-align: right;\">0.174108</td><td style=\"text-align: right;\">0.0303136</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190130_213207_model_4      </td><td style=\"text-align: right;\">0.989465</td><td style=\"text-align: right;\">0.104594 </td><td style=\"text-align: right;\">             0.0606277</td><td style=\"text-align: right;\">0.17591 </td><td style=\"text-align: right;\">0.0309442</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190130_213207_model_3 </td><td style=\"text-align: right;\">0.98859 </td><td style=\"text-align: right;\">0.119245 </td><td style=\"text-align: right;\">             0.0639191</td><td style=\"text-align: right;\">0.191686</td><td style=\"text-align: right;\">0.0367436</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190130_213207_model_4          </td><td style=\"text-align: right;\">0.98782 </td><td style=\"text-align: right;\">0.125012 </td><td style=\"text-align: right;\">             0.0607886</td><td style=\"text-align: right;\">0.188757</td><td style=\"text-align: right;\">0.0356292</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190130_213207_model_1 </td><td style=\"text-align: right;\">0.983877</td><td style=\"text-align: right;\">0.131299 </td><td style=\"text-align: right;\">             0.0855748</td><td style=\"text-align: right;\">0.205893</td><td style=\"text-align: right;\">0.0423921</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190130_213207_model_4 </td><td style=\"text-align: right;\">0.983819</td><td style=\"text-align: right;\">0.130815 </td><td style=\"text-align: right;\">             0.0622799</td><td style=\"text-align: right;\">0.199547</td><td style=\"text-align: right;\">0.0398191</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20190130_213207_model_2 </td><td style=\"text-align: right;\">0.981062</td><td style=\"text-align: right;\">0.164801 </td><td style=\"text-align: right;\">             0.0594702</td><td style=\"text-align: right;\">0.203567</td><td style=\"text-align: right;\">0.0414397</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20190130_213207              </td><td style=\"text-align: right;\">0.966937</td><td style=\"text-align: right;\">0.183419 </td><td style=\"text-align: right;\">             0.0819793</td><td style=\"text-align: right;\">0.243896</td><td style=\"text-align: right;\">0.0594853</td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190130_213207_model_5      </td><td style=\"text-align: right;\">0.908279</td><td style=\"text-align: right;\">0.523145 </td><td style=\"text-align: right;\">             0.0595144</td><td style=\"text-align: right;\">0.42712 </td><td style=\"text-align: right;\">0.182431 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190130_213207_model_3      </td><td style=\"text-align: right;\">0.882696</td><td style=\"text-align: right;\">0.346877 </td><td style=\"text-align: right;\">             0.241302 </td><td style=\"text-align: right;\">0.345589</td><td style=\"text-align: right;\">0.119432 </td></tr>\n",
       "<tr><td>XGBoost_grid_1_AutoML_20190130_213207_model_7      </td><td style=\"text-align: right;\">0.851549</td><td style=\"text-align: right;\">0.353504 </td><td style=\"text-align: right;\">             0.220315 </td><td style=\"text-align: right;\">0.352058</td><td style=\"text-align: right;\">0.123945 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OXGBoostEstimator :  XGBoost\n",
      "Model Key:  XGBoost_grid_1_AutoML_20190130_213207_model_2\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0008243455633779004\n",
      "RMSE: 0.028711418693229015\n",
      "LogLoss: 0.009242062816916361\n",
      "Mean Per-Class Error: 0.0\n",
      "AUC: 1.0\n",
      "pr_auc: 0.9981498612395929\n",
      "Gini: 1.0\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6749682426452637: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>4510.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/4510.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.0</td>\n",
       "<td>1081.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/1081.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>4510.0</td>\n",
       "<td>1081.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/5591.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ------------\n",
       "0      4510  0     0        (0.0/4510.0)\n",
       "1      0     1081  0        (0.0/1081.0)\n",
       "Total  4510  1081  0        (0.0/5591.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.6749682</td>\n",
       "<td>1.0</td>\n",
       "<td>196.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.6749682</td>\n",
       "<td>1.0</td>\n",
       "<td>196.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6749682</td>\n",
       "<td>1.0</td>\n",
       "<td>196.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6749682</td>\n",
       "<td>1.0</td>\n",
       "<td>196.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9991949</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.6749682</td>\n",
       "<td>1.0</td>\n",
       "<td>196.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9991949</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6749682</td>\n",
       "<td>1.0</td>\n",
       "<td>196.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.6749682</td>\n",
       "<td>1.0</td>\n",
       "<td>196.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.6749682</td>\n",
       "<td>1.0</td>\n",
       "<td>196.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value    idx\n",
       "---------------------------  -----------  -------  -----\n",
       "max f1                       0.674968     1        196\n",
       "max f2                       0.674968     1        196\n",
       "max f0point5                 0.674968     1        196\n",
       "max accuracy                 0.674968     1        196\n",
       "max precision                0.999195     1        0\n",
       "max recall                   0.674968     1        196\n",
       "max specificity              0.999195     1        0\n",
       "max absolute_mcc             0.674968     1        196\n",
       "max min_per_class_accuracy   0.674968     1        196\n",
       "max mean_per_class_accuracy  0.674968     1        196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 19.33 %, avg score: 19.35 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100161</td>\n",
       "<td>0.9985351</td>\n",
       "<td>5.1720629</td>\n",
       "<td>5.1720629</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9987812</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9987812</td>\n",
       "<td>0.0518039</td>\n",
       "<td>0.0518039</td>\n",
       "<td>417.2062905</td>\n",
       "<td>417.2062905</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200322</td>\n",
       "<td>0.9982302</td>\n",
       "<td>5.1720629</td>\n",
       "<td>5.1720629</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9983817</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9985814</td>\n",
       "<td>0.0518039</td>\n",
       "<td>0.1036078</td>\n",
       "<td>417.2062905</td>\n",
       "<td>417.2062905</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300483</td>\n",
       "<td>0.9979416</td>\n",
       "<td>5.1720629</td>\n",
       "<td>5.1720629</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980920</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984183</td>\n",
       "<td>0.0518039</td>\n",
       "<td>0.1554117</td>\n",
       "<td>417.2062905</td>\n",
       "<td>417.2062905</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400644</td>\n",
       "<td>0.9975765</td>\n",
       "<td>5.1720629</td>\n",
       "<td>5.1720629</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9977678</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9982557</td>\n",
       "<td>0.0518039</td>\n",
       "<td>0.2072155</td>\n",
       "<td>417.2062905</td>\n",
       "<td>417.2062905</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500805</td>\n",
       "<td>0.9971342</td>\n",
       "<td>5.1720629</td>\n",
       "<td>5.1720629</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9973613</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980768</td>\n",
       "<td>0.0518039</td>\n",
       "<td>0.2590194</td>\n",
       "<td>417.2062905</td>\n",
       "<td>417.2062905</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1001610</td>\n",
       "<td>0.9926304</td>\n",
       "<td>5.1720629</td>\n",
       "<td>5.1720629</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9953727</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9967247</td>\n",
       "<td>0.2590194</td>\n",
       "<td>0.5180389</td>\n",
       "<td>417.2062905</td>\n",
       "<td>417.2062905</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500626</td>\n",
       "<td>0.9734324</td>\n",
       "<td>5.1720629</td>\n",
       "<td>5.1720629</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9851326</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928699</td>\n",
       "<td>0.2580944</td>\n",
       "<td>0.7761332</td>\n",
       "<td>417.2062905</td>\n",
       "<td>417.2062905</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2001431</td>\n",
       "<td>0.1195716</td>\n",
       "<td>4.4701401</td>\n",
       "<td>4.9964254</td>\n",
       "<td>0.8642857</td>\n",
       "<td>0.8256791</td>\n",
       "<td>0.9660411</td>\n",
       "<td>0.9510348</td>\n",
       "<td>0.2238668</td>\n",
       "<td>1.0</td>\n",
       "<td>347.0140082</td>\n",
       "<td>399.6425380</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3001252</td>\n",
       "<td>0.0056429</td>\n",
       "<td>0.0</td>\n",
       "<td>3.3319428</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0266149</td>\n",
       "<td>0.6442193</td>\n",
       "<td>0.6430785</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>233.1942789</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4001073</td>\n",
       "<td>0.0010925</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4993295</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0026712</td>\n",
       "<td>0.4832365</td>\n",
       "<td>0.4830482</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>149.9329459</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000894</td>\n",
       "<td>0.0003735</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9996423</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0006233</td>\n",
       "<td>0.3866237</td>\n",
       "<td>0.3865977</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.9642346</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000715</td>\n",
       "<td>0.0002902</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6664680</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003083</td>\n",
       "<td>0.3222057</td>\n",
       "<td>0.3222354</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6467958</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7041674</td>\n",
       "<td>0.0002331</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4201168</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002660</td>\n",
       "<td>0.2745745</td>\n",
       "<td>0.2746392</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.0116840</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8002146</td>\n",
       "<td>0.0002186</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2496647</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002215</td>\n",
       "<td>0.2416182</td>\n",
       "<td>0.2417017</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.9664730</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9028796</td>\n",
       "<td>0.0001914</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1075674</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002016</td>\n",
       "<td>0.2141442</td>\n",
       "<td>0.2142411</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>10.7567353</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001587</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001696</td>\n",
       "<td>0.1933464</td>\n",
       "<td>0.1934504</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain\n",
       "--  -------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------\n",
       "    1        0.0100161                   0.998535           5.17206  5.17206            1                0.998781     1                           0.998781            0.0518039       0.0518039                  417.206  417.206\n",
       "    2        0.0200322                   0.99823            5.17206  5.17206            1                0.998382     1                           0.998581            0.0518039       0.103608                   417.206  417.206\n",
       "    3        0.0300483                   0.997942           5.17206  5.17206            1                0.998092     1                           0.998418            0.0518039       0.155412                   417.206  417.206\n",
       "    4        0.0400644                   0.997576           5.17206  5.17206            1                0.997768     1                           0.998256            0.0518039       0.207216                   417.206  417.206\n",
       "    5        0.0500805                   0.997134           5.17206  5.17206            1                0.997361     1                           0.998077            0.0518039       0.259019                   417.206  417.206\n",
       "    6        0.100161                    0.99263            5.17206  5.17206            1                0.995373     1                           0.996725            0.259019        0.518039                   417.206  417.206\n",
       "    7        0.150063                    0.973432           5.17206  5.17206            1                0.985133     1                           0.99287             0.258094        0.776133                   417.206  417.206\n",
       "    8        0.200143                    0.119572           4.47014  4.99643            0.864286         0.825679     0.966041                    0.951035            0.223867        1                          347.014  399.643\n",
       "    9        0.300125                    0.00564288         0        3.33194            0                0.0266149    0.644219                    0.643078            0               1                          -100     233.194\n",
       "    10       0.400107                    0.00109253         0        2.49933            0                0.00267115   0.483236                    0.483048            0               1                          -100     149.933\n",
       "    11       0.500089                    0.000373537        0        1.99964            0                0.000623299  0.386624                    0.386598            0               1                          -100     99.9642\n",
       "    12       0.600072                    0.000290154        0        1.66647            0                0.000308287  0.322206                    0.322235            0               1                          -100     66.6468\n",
       "    13       0.704167                    0.000233133        0        1.42012            0                0.00026601   0.274575                    0.274639            0               1                          -100     42.0117\n",
       "    14       0.800215                    0.000218629        0        1.24966            0                0.00022149   0.241618                    0.241702            0               1                          -100     24.9665\n",
       "    15       0.90288                     0.000191445        0        1.10757            0                0.0002016    0.214144                    0.214241            0               1                          -100     10.7567\n",
       "    16       1                           0.000158701        0        1                  0                0.000169609  0.193346                    0.19345             0               1                          -100     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.022277082821276543\n",
      "RMSE: 0.14925509311670587\n",
      "LogLoss: 0.07638424677886102\n",
      "Mean Per-Class Error: 0.037454981992797176\n",
      "AUC: 0.9947521865889213\n",
      "pr_auc: 0.9721301879096006\n",
      "Gini: 0.9895043731778426\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5711635947227478: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>482.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0163</td>\n",
       "<td> (8.0/490.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>8.0</td>\n",
       "<td>111.0</td>\n",
       "<td>0.0672</td>\n",
       "<td> (8.0/119.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>490.0</td>\n",
       "<td>119.0</td>\n",
       "<td>0.0263</td>\n",
       "<td> (16.0/609.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      482  8    0.0163   (8.0/490.0)\n",
       "1      8    111  0.0672   (8.0/119.0)\n",
       "Total  490  119  0.0263   (16.0/609.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.5711636</td>\n",
       "<td>0.9327731</td>\n",
       "<td>118.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0572520</td>\n",
       "<td>0.9405145</td>\n",
       "<td>145.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7254370</td>\n",
       "<td>0.9481216</td>\n",
       "<td>109.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5711636</td>\n",
       "<td>0.9737274</td>\n",
       "<td>118.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9988762</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0174077</td>\n",
       "<td>1.0</td>\n",
       "<td>168.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9988762</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5711636</td>\n",
       "<td>0.9164466</td>\n",
       "<td>118.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2779505</td>\n",
       "<td>0.9495798</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2779505</td>\n",
       "<td>0.9625450</td>\n",
       "<td>124.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.571164     0.932773  118\n",
       "max f2                       0.057252     0.940514  145\n",
       "max f0point5                 0.725437     0.948122  109\n",
       "max accuracy                 0.571164     0.973727  118\n",
       "max precision                0.998876     1         0\n",
       "max recall                   0.0174077    1         168\n",
       "max specificity              0.998876     1         0\n",
       "max absolute_mcc             0.571164     0.916447  118\n",
       "max min_per_class_accuracy   0.27795      0.94958   124\n",
       "max mean_per_class_accuracy  0.27795      0.962545  124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 19.54 %, avg score: 19.47 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0114943</td>\n",
       "<td>0.9985659</td>\n",
       "<td>5.1176471</td>\n",
       "<td>5.1176471</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9987538</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9987538</td>\n",
       "<td>0.0588235</td>\n",
       "<td>0.0588235</td>\n",
       "<td>411.7647059</td>\n",
       "<td>411.7647059</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0213465</td>\n",
       "<td>0.9981817</td>\n",
       "<td>5.1176471</td>\n",
       "<td>5.1176471</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9983903</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9985860</td>\n",
       "<td>0.0504202</td>\n",
       "<td>0.1092437</td>\n",
       "<td>411.7647059</td>\n",
       "<td>411.7647059</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0311987</td>\n",
       "<td>0.9976356</td>\n",
       "<td>5.1176471</td>\n",
       "<td>5.1176471</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978982</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9983688</td>\n",
       "<td>0.0504202</td>\n",
       "<td>0.1596639</td>\n",
       "<td>411.7647059</td>\n",
       "<td>411.7647059</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0410509</td>\n",
       "<td>0.9971099</td>\n",
       "<td>5.1176471</td>\n",
       "<td>5.1176471</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9973590</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981265</td>\n",
       "<td>0.0504202</td>\n",
       "<td>0.2100840</td>\n",
       "<td>411.7647059</td>\n",
       "<td>411.7647059</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0509031</td>\n",
       "<td>0.9960490</td>\n",
       "<td>5.1176471</td>\n",
       "<td>5.1176471</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966716</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978449</td>\n",
       "<td>0.0504202</td>\n",
       "<td>0.2605042</td>\n",
       "<td>411.7647059</td>\n",
       "<td>411.7647059</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1001642</td>\n",
       "<td>0.9903280</td>\n",
       "<td>5.1176471</td>\n",
       "<td>5.1176471</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9942189</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9960616</td>\n",
       "<td>0.2521008</td>\n",
       "<td>0.5126050</td>\n",
       "<td>411.7647059</td>\n",
       "<td>411.7647059</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1510673</td>\n",
       "<td>0.9464600</td>\n",
       "<td>4.9525617</td>\n",
       "<td>5.0620205</td>\n",
       "<td>0.9677419</td>\n",
       "<td>0.9777995</td>\n",
       "<td>0.9891304</td>\n",
       "<td>0.9899081</td>\n",
       "<td>0.2521008</td>\n",
       "<td>0.7647059</td>\n",
       "<td>395.2561670</td>\n",
       "<td>406.2020460</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2003284</td>\n",
       "<td>0.3632163</td>\n",
       "<td>3.5823529</td>\n",
       "<td>4.6981678</td>\n",
       "<td>0.7</td>\n",
       "<td>0.7463670</td>\n",
       "<td>0.9180328</td>\n",
       "<td>0.9300209</td>\n",
       "<td>0.1764706</td>\n",
       "<td>0.9411765</td>\n",
       "<td>258.2352941</td>\n",
       "<td>369.8167792</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3004926</td>\n",
       "<td>0.0069237</td>\n",
       "<td>0.5872710</td>\n",
       "<td>3.3278689</td>\n",
       "<td>0.1147541</td>\n",
       "<td>0.0789508</td>\n",
       "<td>0.6502732</td>\n",
       "<td>0.6463309</td>\n",
       "<td>0.0588235</td>\n",
       "<td>1.0</td>\n",
       "<td>-41.2729026</td>\n",
       "<td>232.7868852</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4006568</td>\n",
       "<td>0.0009090</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4959016</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0026550</td>\n",
       "<td>0.4877049</td>\n",
       "<td>0.4854119</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>149.5901639</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5008210</td>\n",
       "<td>0.0003084</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9967213</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005322</td>\n",
       "<td>0.3901639</td>\n",
       "<td>0.3884359</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.6721311</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6141215</td>\n",
       "<td>0.0002764</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6283422</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002924</td>\n",
       "<td>0.3181818</td>\n",
       "<td>0.3168266</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>62.8342246</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6995074</td>\n",
       "<td>0.0002302</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4295775</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002548</td>\n",
       "<td>0.2793427</td>\n",
       "<td>0.2781840</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.9577465</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7996716</td>\n",
       "<td>0.0002130</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2505133</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002199</td>\n",
       "<td>0.2443532</td>\n",
       "<td>0.2433672</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0513347</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8998358</td>\n",
       "<td>0.0001914</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1113139</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001990</td>\n",
       "<td>0.2171533</td>\n",
       "<td>0.2162992</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1313869</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001586</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001701</td>\n",
       "<td>0.1954023</td>\n",
       "<td>0.1946508</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0114943                   0.998566           5.11765   5.11765            1                0.998754     1                           0.998754            0.0588235       0.0588235                  411.765   411.765\n",
       "    2        0.0213465                   0.998182           5.11765   5.11765            1                0.99839      1                           0.998586            0.0504202       0.109244                   411.765   411.765\n",
       "    3        0.0311987                   0.997636           5.11765   5.11765            1                0.997898     1                           0.998369            0.0504202       0.159664                   411.765   411.765\n",
       "    4        0.0410509                   0.99711            5.11765   5.11765            1                0.997359     1                           0.998126            0.0504202       0.210084                   411.765   411.765\n",
       "    5        0.0509031                   0.996049           5.11765   5.11765            1                0.996672     1                           0.997845            0.0504202       0.260504                   411.765   411.765\n",
       "    6        0.100164                    0.990328           5.11765   5.11765            1                0.994219     1                           0.996062            0.252101        0.512605                   411.765   411.765\n",
       "    7        0.151067                    0.94646            4.95256   5.06202            0.967742         0.9778       0.98913                     0.989908            0.252101        0.764706                   395.256   406.202\n",
       "    8        0.200328                    0.363216           3.58235   4.69817            0.7              0.746367     0.918033                    0.930021            0.176471        0.941176                   258.235   369.817\n",
       "    9        0.300493                    0.00692372         0.587271  3.32787            0.114754         0.0789508    0.650273                    0.646331            0.0588235       1                          -41.2729  232.787\n",
       "    10       0.400657                    0.00090898         0         2.4959             0                0.00265495   0.487705                    0.485412            0               1                          -100      149.59\n",
       "    11       0.500821                    0.000308378        0         1.99672            0                0.000532171  0.390164                    0.388436            0               1                          -100      99.6721\n",
       "    12       0.614122                    0.000276417        0         1.62834            0                0.000292416  0.318182                    0.316827            0               1                          -100      62.8342\n",
       "    13       0.699507                    0.000230215        0         1.42958            0                0.000254831  0.279343                    0.278184            0               1                          -100      42.9577\n",
       "    14       0.799672                    0.000212999        0         1.25051            0                0.000219947  0.244353                    0.243367            0               1                          -100      25.0513\n",
       "    15       0.899836                    0.000191422        0         1.11131            0                0.000199007  0.217153                    0.216299            0               1                          -100      11.1314\n",
       "    16       1                           0.000158602        0         1                  0                0.000170076  0.195402                    0.194651            0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.020207192839992567\n",
      "RMSE: 0.14215200610611364\n",
      "LogLoss: 0.07316374388289915\n",
      "Mean Per-Class Error: 0.03141174612486175\n",
      "AUC: 0.9945237328498086\n",
      "pr_auc: 0.946644426246515\n",
      "Gini: 0.9890474656996171\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5050590634346008: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>4448.0</td>\n",
       "<td>62.0</td>\n",
       "<td>0.0137</td>\n",
       "<td> (62.0/4510.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>79.0</td>\n",
       "<td>1002.0</td>\n",
       "<td>0.0731</td>\n",
       "<td> (79.0/1081.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>4527.0</td>\n",
       "<td>1064.0</td>\n",
       "<td>0.0252</td>\n",
       "<td> (141.0/5591.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  --------------\n",
       "0      4448  62    0.0137   (62.0/4510.0)\n",
       "1      79    1002  0.0731   (79.0/1081.0)\n",
       "Total  4527  1064  0.0252   (141.0/5591.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.5050591</td>\n",
       "<td>0.9342657</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1560417</td>\n",
       "<td>0.9497106</td>\n",
       "<td>275.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7568246</td>\n",
       "<td>0.9450549</td>\n",
       "<td>131.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5050591</td>\n",
       "<td>0.9747809</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9988982</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0027669</td>\n",
       "<td>1.0</td>\n",
       "<td>383.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9988982</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5050591</td>\n",
       "<td>0.9187086</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1665947</td>\n",
       "<td>0.9669623</td>\n",
       "<td>270.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1560417</td>\n",
       "<td>0.9685883</td>\n",
       "<td>275.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.505059     0.934266  186\n",
       "max f2                       0.156042     0.949711  275\n",
       "max f0point5                 0.756825     0.945055  131\n",
       "max accuracy                 0.505059     0.974781  186\n",
       "max precision                0.998898     1         0\n",
       "max recall                   0.00276692   1         383\n",
       "max specificity              0.998898     1         0\n",
       "max absolute_mcc             0.505059     0.918709  186\n",
       "max min_per_class_accuracy   0.166595     0.966962  270\n",
       "max mean_per_class_accuracy  0.156042     0.968588  275"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 19.33 %, avg score: 19.17 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100161</td>\n",
       "<td>0.9984821</td>\n",
       "<td>5.1720629</td>\n",
       "<td>5.1720629</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9987587</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9987587</td>\n",
       "<td>0.0518039</td>\n",
       "<td>0.0518039</td>\n",
       "<td>417.2062905</td>\n",
       "<td>417.2062905</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200322</td>\n",
       "<td>0.9980184</td>\n",
       "<td>5.0797046</td>\n",
       "<td>5.1258838</td>\n",
       "<td>0.9821429</td>\n",
       "<td>0.9982440</td>\n",
       "<td>0.9910714</td>\n",
       "<td>0.9985013</td>\n",
       "<td>0.0508788</td>\n",
       "<td>0.1026827</td>\n",
       "<td>407.9704639</td>\n",
       "<td>412.5883772</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300483</td>\n",
       "<td>0.9975069</td>\n",
       "<td>5.0797046</td>\n",
       "<td>5.1104907</td>\n",
       "<td>0.9821429</td>\n",
       "<td>0.9977565</td>\n",
       "<td>0.9880952</td>\n",
       "<td>0.9982531</td>\n",
       "<td>0.0508788</td>\n",
       "<td>0.1535615</td>\n",
       "<td>407.9704639</td>\n",
       "<td>411.0490727</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400644</td>\n",
       "<td>0.9970144</td>\n",
       "<td>5.1720629</td>\n",
       "<td>5.1258838</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9972592</td>\n",
       "<td>0.9910714</td>\n",
       "<td>0.9980046</td>\n",
       "<td>0.0518039</td>\n",
       "<td>0.2053654</td>\n",
       "<td>417.2062905</td>\n",
       "<td>412.5883772</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500805</td>\n",
       "<td>0.9964964</td>\n",
       "<td>5.0797046</td>\n",
       "<td>5.1166479</td>\n",
       "<td>0.9821429</td>\n",
       "<td>0.9967604</td>\n",
       "<td>0.9892857</td>\n",
       "<td>0.9977557</td>\n",
       "<td>0.0508788</td>\n",
       "<td>0.2562442</td>\n",
       "<td>407.9704639</td>\n",
       "<td>411.6647945</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1001610</td>\n",
       "<td>0.9897760</td>\n",
       "<td>5.0981763</td>\n",
       "<td>5.1074121</td>\n",
       "<td>0.9857143</td>\n",
       "<td>0.9939676</td>\n",
       "<td>0.9875</td>\n",
       "<td>0.9958616</td>\n",
       "<td>0.2553191</td>\n",
       "<td>0.5115634</td>\n",
       "<td>409.8176292</td>\n",
       "<td>410.7412118</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500626</td>\n",
       "<td>0.9259956</td>\n",
       "<td>4.9866843</td>\n",
       "<td>5.0672654</td>\n",
       "<td>0.9641577</td>\n",
       "<td>0.9692725</td>\n",
       "<td>0.9797378</td>\n",
       "<td>0.9870197</td>\n",
       "<td>0.2488437</td>\n",
       "<td>0.7604070</td>\n",
       "<td>398.6684306</td>\n",
       "<td>406.7265444</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2001431</td>\n",
       "<td>0.3358747</td>\n",
       "<td>3.7312740</td>\n",
       "<td>4.7329691</td>\n",
       "<td>0.7214286</td>\n",
       "<td>0.7099727</td>\n",
       "<td>0.9151028</td>\n",
       "<td>0.9176961</td>\n",
       "<td>0.1868640</td>\n",
       "<td>0.9472710</td>\n",
       "<td>273.1273953</td>\n",
       "<td>373.2969092</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3001252</td>\n",
       "<td>0.0101090</td>\n",
       "<td>0.4811221</td>\n",
       "<td>3.3165314</td>\n",
       "<td>0.0930233</td>\n",
       "<td>0.0739278</td>\n",
       "<td>0.6412396</td>\n",
       "<td>0.6366076</td>\n",
       "<td>0.0481036</td>\n",
       "<td>0.9953747</td>\n",
       "<td>-51.8877869</td>\n",
       "<td>231.6531398</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4001073</td>\n",
       "<td>0.0015031</td>\n",
       "<td>0.0462617</td>\n",
       "<td>2.4993295</td>\n",
       "<td>0.0089445</td>\n",
       "<td>0.0040831</td>\n",
       "<td>0.4832365</td>\n",
       "<td>0.4785472</td>\n",
       "<td>0.0046253</td>\n",
       "<td>1.0</td>\n",
       "<td>-95.3738257</td>\n",
       "<td>149.9329459</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5002683</td>\n",
       "<td>0.0005177</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9989274</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0008417</td>\n",
       "<td>0.3864855</td>\n",
       "<td>0.3829036</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>99.8927422</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000715</td>\n",
       "<td>0.0004260</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6664680</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004586</td>\n",
       "<td>0.3222057</td>\n",
       "<td>0.3192957</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.6467958</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7005902</td>\n",
       "<td>0.0003209</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4273679</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003643</td>\n",
       "<td>0.2759765</td>\n",
       "<td>0.2735364</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.7367884</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8020032</td>\n",
       "<td>0.0002514</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2468778</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002806</td>\n",
       "<td>0.2410794</td>\n",
       "<td>0.2389833</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.6877788</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9059202</td>\n",
       "<td>0.0001792</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1038500</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002147</td>\n",
       "<td>0.2134255</td>\n",
       "<td>0.2115944</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>10.3849951</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000835</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001248</td>\n",
       "<td>0.1933464</td>\n",
       "<td>0.1916994</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100161                   0.998482           5.17206    5.17206            1                0.998759     1                           0.998759            0.0518039       0.0518039                  417.206   417.206\n",
       "    2        0.0200322                   0.998018           5.0797     5.12588            0.982143         0.998244     0.991071                    0.998501            0.0508788       0.102683                   407.97    412.588\n",
       "    3        0.0300483                   0.997507           5.0797     5.11049            0.982143         0.997757     0.988095                    0.998253            0.0508788       0.153562                   407.97    411.049\n",
       "    4        0.0400644                   0.997014           5.17206    5.12588            1                0.997259     0.991071                    0.998005            0.0518039       0.205365                   417.206   412.588\n",
       "    5        0.0500805                   0.996496           5.0797     5.11665            0.982143         0.99676      0.989286                    0.997756            0.0508788       0.256244                   407.97    411.665\n",
       "    6        0.100161                    0.989776           5.09818    5.10741            0.985714         0.993968     0.9875                      0.995862            0.255319        0.511563                   409.818   410.741\n",
       "    7        0.150063                    0.925996           4.98668    5.06727            0.964158         0.969272     0.979738                    0.98702             0.248844        0.760407                   398.668   406.727\n",
       "    8        0.200143                    0.335875           3.73127    4.73297            0.721429         0.709973     0.915103                    0.917696            0.186864        0.947271                   273.127   373.297\n",
       "    9        0.300125                    0.010109           0.481122   3.31653            0.0930233        0.0739278    0.64124                     0.636608            0.0481036       0.995375                   -51.8878  231.653\n",
       "    10       0.400107                    0.00150312         0.0462617  2.49933            0.00894454       0.00408305   0.483236                    0.478547            0.00462535      1                          -95.3738  149.933\n",
       "    11       0.500268                    0.000517677        0          1.99893            0                0.000841676  0.386486                    0.382904            0               1                          -100      99.8927\n",
       "    12       0.600072                    0.000426041        0          1.66647            0                0.000458623  0.322206                    0.319296            0               1                          -100      66.6468\n",
       "    13       0.70059                     0.000320949        0          1.42737            0                0.000364349  0.275977                    0.273536            0               1                          -100      42.7368\n",
       "    14       0.802003                    0.000251381        0          1.24688            0                0.000280647  0.241079                    0.238983            0               1                          -100      24.6878\n",
       "    15       0.90592                     0.00017919         0          1.10385            0                0.000214668  0.213425                    0.211594            0               1                          -100      10.385\n",
       "    16       1                           8.35424e-05        0          1                  0                0.000124821  0.193346                    0.191699            0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9758545</td>\n",
       "<td>0.0010523</td>\n",
       "<td>0.9731904</td>\n",
       "<td>0.9758497</td>\n",
       "<td>0.9758497</td>\n",
       "<td>0.9776387</td>\n",
       "<td>0.9767442</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.994463</td>\n",
       "<td>0.0011919</td>\n",
       "<td>0.9921015</td>\n",
       "<td>0.9947442</td>\n",
       "<td>0.9929837</td>\n",
       "<td>0.9961274</td>\n",
       "<td>0.9963584</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0241455</td>\n",
       "<td>0.0010523</td>\n",
       "<td>0.0268097</td>\n",
       "<td>0.0241503</td>\n",
       "<td>0.0241503</td>\n",
       "<td>0.0223614</td>\n",
       "<td>0.0232558</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>27.0</td>\n",
       "<td>1.183216</td>\n",
       "<td>30.0</td>\n",
       "<td>27.0</td>\n",
       "<td>27.0</td>\n",
       "<td>25.0</td>\n",
       "<td>26.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9370925</td>\n",
       "<td>0.0071115</td>\n",
       "<td>0.92</td>\n",
       "<td>0.9340659</td>\n",
       "<td>0.9410112</td>\n",
       "<td>0.9505703</td>\n",
       "<td>0.9398148</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9376835</td>\n",
       "<td>0.0021157</td>\n",
       "<td>0.9324324</td>\n",
       "<td>0.9379311</td>\n",
       "<td>0.9370629</td>\n",
       "<td>0.9411765</td>\n",
       "<td>0.9398148</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9383925</td>\n",
       "<td>0.0035923</td>\n",
       "<td>0.9452055</td>\n",
       "<td>0.9418283</td>\n",
       "<td>0.9331476</td>\n",
       "<td>0.9319664</td>\n",
       "<td>0.9398148</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>5.172077</td>\n",
       "<td>0.0054430</td>\n",
       "<td>5.156682</td>\n",
       "<td>5.1759257</td>\n",
       "<td>5.1759257</td>\n",
       "<td>5.1759257</td>\n",
       "<td>5.1759257</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0731618</td>\n",
       "<td>0.0063384</td>\n",
       "<td>0.0841366</td>\n",
       "<td>0.0739924</td>\n",
       "<td>0.0816593</td>\n",
       "<td>0.0619372</td>\n",
       "<td>0.0640834</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.0610684</td>\n",
       "<td>0.0070359</td>\n",
       "<td>0.0460829</td>\n",
       "<td>0.0555556</td>\n",
       "<td>0.0694445</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.0601852</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9228367</td>\n",
       "<td>0.0027400</td>\n",
       "<td>0.9160821</td>\n",
       "<td>0.9229741</td>\n",
       "<td>0.9221565</td>\n",
       "<td>0.9275684</td>\n",
       "<td>0.9254024</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9618161</td>\n",
       "<td>0.0021575</td>\n",
       "<td>0.9658720</td>\n",
       "<td>0.9639074</td>\n",
       "<td>0.9586259</td>\n",
       "<td>0.9579741</td>\n",
       "<td>0.9627012</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0381839</td>\n",
       "<td>0.0021575</td>\n",
       "<td>0.0341279</td>\n",
       "<td>0.0360926</td>\n",
       "<td>0.0413741</td>\n",
       "<td>0.0420259</td>\n",
       "<td>0.0372988</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0202069</td>\n",
       "<td>0.0010952</td>\n",
       "<td>0.0216843</td>\n",
       "<td>0.0207783</td>\n",
       "<td>0.0216306</td>\n",
       "<td>0.0176248</td>\n",
       "<td>0.0193168</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9367632</td>\n",
       "<td>0.0105357</td>\n",
       "<td>0.9118943</td>\n",
       "<td>0.9315069</td>\n",
       "<td>0.943662</td>\n",
       "<td>0.9569378</td>\n",
       "<td>0.9398148</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8704432</td>\n",
       "<td>0.0069741</td>\n",
       "<td>0.8612801</td>\n",
       "<td>0.866699</td>\n",
       "<td>0.8612315</td>\n",
       "<td>0.8869302</td>\n",
       "<td>0.8760754</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9389316</td>\n",
       "<td>0.0070359</td>\n",
       "<td>0.953917</td>\n",
       "<td>0.9444444</td>\n",
       "<td>0.9305556</td>\n",
       "<td>0.9259259</td>\n",
       "<td>0.9398148</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1420438</td>\n",
       "<td>0.0039046</td>\n",
       "<td>0.1472558</td>\n",
       "<td>0.1441468</td>\n",
       "<td>0.1470733</td>\n",
       "<td>0.1327583</td>\n",
       "<td>0.1389847</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9847007</td>\n",
       "<td>0.0028654</td>\n",
       "<td>0.9778271</td>\n",
       "<td>0.9833703</td>\n",
       "<td>0.9866962</td>\n",
       "<td>0.9900222</td>\n",
       "<td>0.9855876</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd          cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  ----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.975854   0.00105226  0.97319       0.97585       0.97585       0.977639      0.976744\n",
       "auc                      0.994463   0.00119192  0.992102      0.994744      0.992984      0.996127      0.996358\n",
       "err                      0.0241455  0.00105226  0.0268097     0.0241503     0.0241503     0.0223614     0.0232558\n",
       "err_count                27         1.18322     30            27            27            25            26\n",
       "f0point5                 0.937092   0.00711149  0.92          0.934066      0.941011      0.95057       0.939815\n",
       "f1                       0.937684   0.00211574  0.932432      0.937931      0.937063      0.941176      0.939815\n",
       "f2                       0.938392   0.00359231  0.945205      0.941828      0.933148      0.931966      0.939815\n",
       "lift_top_group           5.17208    0.005443    5.15668       5.17593       5.17593       5.17593       5.17593\n",
       "logloss                  0.0731618  0.00633841  0.0841366     0.0739924     0.0816593     0.0619372     0.0640834\n",
       "max_per_class_error      0.0610684  0.00703591  0.0460829     0.0555556     0.0694445     0.0740741     0.0601852\n",
       "mcc                      0.922837   0.00274001  0.916082      0.922974      0.922156      0.927568      0.925402\n",
       "mean_per_class_accuracy  0.961816   0.00215746  0.965872      0.963907      0.958626      0.957974      0.962701\n",
       "mean_per_class_error     0.0381839  0.00215746  0.0341279     0.0360926     0.0413741     0.0420259     0.0372988\n",
       "mse                      0.0202069  0.00109525  0.0216843     0.0207783     0.0216306     0.0176248     0.0193168\n",
       "precision                0.936763   0.0105357   0.911894      0.931507      0.943662      0.956938      0.939815\n",
       "r2                       0.870443   0.00697408  0.86128       0.866699      0.861232      0.88693       0.876075\n",
       "recall                   0.938932   0.00703591  0.953917      0.944444      0.930556      0.925926      0.939815\n",
       "rmse                     0.142044   0.00390463  0.147256      0.144147      0.147073      0.132758      0.138985\n",
       "specificity              0.984701   0.00286538  0.977827      0.98337       0.986696      0.990022      0.985588"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_pr_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 21:34:17</td>\n",
       "<td>40.788 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6931472</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8066536</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6931472</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8045977</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 21:34:17</td>\n",
       "<td>40.897 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.3957806</td>\n",
       "<td>0.5035645</td>\n",
       "<td>0.9997729</td>\n",
       "<td>0.9953345</td>\n",
       "<td>5.1720629</td>\n",
       "<td>0.0048292</td>\n",
       "<td>0.4026709</td>\n",
       "<td>0.5147187</td>\n",
       "<td>0.9862631</td>\n",
       "<td>0.9641006</td>\n",
       "<td>5.1176471</td>\n",
       "<td>0.0295567</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 21:34:17</td>\n",
       "<td>41.009 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.3155319</td>\n",
       "<td>0.3778538</td>\n",
       "<td>0.9998580</td>\n",
       "<td>0.9975435</td>\n",
       "<td>5.1720629</td>\n",
       "<td>0.0037560</td>\n",
       "<td>0.3300650</td>\n",
       "<td>0.3974075</td>\n",
       "<td>0.9928829</td>\n",
       "<td>0.9683347</td>\n",
       "<td>5.1176471</td>\n",
       "<td>0.0279146</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 21:34:17</td>\n",
       "<td>41.107 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.2536609</td>\n",
       "<td>0.2896799</td>\n",
       "<td>0.9998973</td>\n",
       "<td>0.9977127</td>\n",
       "<td>5.1720629</td>\n",
       "<td>0.0028617</td>\n",
       "<td>0.2765256</td>\n",
       "<td>0.3157276</td>\n",
       "<td>0.9935517</td>\n",
       "<td>0.9696403</td>\n",
       "<td>5.1176471</td>\n",
       "<td>0.0295567</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 21:34:18</td>\n",
       "<td>41.208 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.2063640</td>\n",
       "<td>0.2260345</td>\n",
       "<td>0.9999143</td>\n",
       "<td>0.9968608</td>\n",
       "<td>5.1720629</td>\n",
       "<td>0.0021463</td>\n",
       "<td>0.2387437</td>\n",
       "<td>0.2580170</td>\n",
       "<td>0.9931230</td>\n",
       "<td>0.9679879</td>\n",
       "<td>5.1176471</td>\n",
       "<td>0.0311987</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 21:34:21</td>\n",
       "<td>44.408 sec</td>\n",
       "<td>140.0</td>\n",
       "<td>0.0314666</td>\n",
       "<td>0.0107465</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9898242</td>\n",
       "<td>5.1720629</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1485331</td>\n",
       "<td>0.0751262</td>\n",
       "<td>0.9948894</td>\n",
       "<td>0.9727244</td>\n",
       "<td>5.1176471</td>\n",
       "<td>0.0262726</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 21:34:21</td>\n",
       "<td>44.549 sec</td>\n",
       "<td>145.0</td>\n",
       "<td>0.0307291</td>\n",
       "<td>0.0103226</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9953747</td>\n",
       "<td>5.1720629</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1490024</td>\n",
       "<td>0.0756898</td>\n",
       "<td>0.9948036</td>\n",
       "<td>0.9723500</td>\n",
       "<td>5.1176471</td>\n",
       "<td>0.0262726</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 21:34:21</td>\n",
       "<td>44.686 sec</td>\n",
       "<td>150.0</td>\n",
       "<td>0.0299379</td>\n",
       "<td>0.0099248</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9944496</td>\n",
       "<td>5.1720629</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1493051</td>\n",
       "<td>0.0760527</td>\n",
       "<td>0.9947865</td>\n",
       "<td>0.9722451</td>\n",
       "<td>5.1176471</td>\n",
       "<td>0.0279146</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 21:34:21</td>\n",
       "<td>44.850 sec</td>\n",
       "<td>155.0</td>\n",
       "<td>0.0293252</td>\n",
       "<td>0.0096053</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9870490</td>\n",
       "<td>5.1720629</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1491696</td>\n",
       "<td>0.0762441</td>\n",
       "<td>0.9948208</td>\n",
       "<td>0.9724259</td>\n",
       "<td>5.1176471</td>\n",
       "<td>0.0262726</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-01-30 21:34:21</td>\n",
       "<td>45.022 sec</td>\n",
       "<td>160.0</td>\n",
       "<td>0.0287114</td>\n",
       "<td>0.0092421</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981499</td>\n",
       "<td>5.1720629</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1492551</td>\n",
       "<td>0.0763842</td>\n",
       "<td>0.9947522</td>\n",
       "<td>0.9721302</td>\n",
       "<td>5.1176471</td>\n",
       "<td>0.0262726</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse         training_logloss      training_auc        training_pr_auc     training_lift      training_classification_error    validation_rmse      validation_logloss    validation_auc      validation_pr_auc    validation_lift    validation_classification_error\n",
       "---  -------------------  ----------  -----------------  --------------------  --------------------  ------------------  ------------------  -----------------  -------------------------------  -------------------  --------------------  ------------------  -------------------  -----------------  ---------------------------------\n",
       "     2019-01-30 21:34:17  40.788 sec  0.0                0.5                   0.6931471805599352    0.5                 0.0                 1.0                0.8066535503487748               0.5                  0.6931471805599467    0.5                 0.0                  1.0                0.8045977011494253\n",
       "     2019-01-30 21:34:17  40.897 sec  5.0                0.39578055411106033   0.5035644800121584    0.9997729375157682  0.995334530452311   5.172062904717854  0.004829189769272045             0.40267089854749405  0.5147186885929462    0.9862630766592351  0.964100567675351    5.117647058823529  0.029556650246305417\n",
       "     2019-01-30 21:34:17  41.009 sec  10.0               0.31553191477270615   0.3778538472084196    0.999857957750379   0.9975434507895335  5.172062904717854  0.00375603648721159              0.33006496291829623  0.3974075228147144    0.9928828674326873  0.9683347058106203   5.117647058823529  0.027914614121510674\n",
       "     2019-01-30 21:34:17  41.107 sec  15.0               0.25366086992205866   0.2896799148546036    0.9998973398614651  0.9977126689581408  5.172062904717854  0.0028617420854945446            0.27652560880462024  0.31572760034643943   0.9935517063968444  0.9696402679286544   5.117647058823529  0.029556650246305417\n",
       "     2019-01-30 21:34:18  41.208 sec  20.0               0.20636402545135527   0.22603448032315532   0.9999142618623226  0.9968607921984981  5.172062904717854  0.0021463065641209086            0.2387437212119398   0.2580169835466898    0.9931229634711027  0.9679878976371812   5.117647058823529  0.031198686371100164\n",
       "---  ---                  ---         ---                ---                   ---                   ---                 ---                 ---                ---                              ---                  ---                   ---                 ---                  ---                ---\n",
       "     2019-01-30 21:34:21  44.408 sec  140.0              0.031466614458498035  0.010746486366396291  1.0                 0.9898242368177613  5.172062904717854  0.0                              0.14853312288659462  0.07512622407109469   0.9948893843251586  0.9727243548398312   5.117647058823529  0.026272577996715927\n",
       "     2019-01-30 21:34:21  44.549 sec  145.0              0.030729083252298763  0.010322596497007742  1.0                 0.9953746530989824  5.172062904717854  0.0                              0.1490024016992286   0.07568984348996834   0.9948036357400103  0.9723499820658554   5.117647058823529  0.026272577996715927\n",
       "     2019-01-30 21:34:21  44.686 sec  150.0              0.029937868892413316  0.009924797441381968  1.0                 0.9944495837187789  5.172062904717854  0.0                              0.14930509905745723  0.07605265140673277   0.9947864860229806  0.972245086849294    5.117647058823529  0.027914614121510674\n",
       "     2019-01-30 21:34:21  44.850 sec  155.0              0.029325232596487356  0.009605252953336077  1.0                 0.9870490286771507  5.172062904717854  0.0                              0.14916961145055332  0.07624407110213564   0.99482078545704    0.9724258827748783   5.117647058823529  0.026272577996715927\n",
       "     2019-01-30 21:34:21  45.022 sec  160.0              0.028711418693229015  0.009242062816916361  1.0                 0.9981498612395929  5.172062904717854  0.0                              0.14925509311670587  0.07638424677886102   0.9947521865889213  0.9721301879096006   5.117647058823529  0.026272577996715927"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>ks_words</td>\n",
       "<td>5856.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4081690</td></tr>\n",
       "<tr><td>kl_words</td>\n",
       "<td>4513.0</td>\n",
       "<td>0.7706626</td>\n",
       "<td>0.3145605</td></tr>\n",
       "<tr><td>entropy_words</td>\n",
       "<td>3978.0</td>\n",
       "<td>0.6793033</td>\n",
       "<td>0.2772705</td></tr></table></div>"
      ],
      "text/plain": [
       "variable       relative_importance    scaled_importance    percentage\n",
       "-------------  ---------------------  -------------------  ------------\n",
       "ks_words       5856                   1                    0.408169\n",
       "kl_words       4513                   0.770663             0.314561\n",
       "entropy_words  3978                   0.679303             0.277271"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The leader model is stored here\n",
    "aml.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |ââââââââââââââââââââââââââââââââââââââââââââ| 100%\n",
      "test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>hash_message                                                                                                                    </th><th style=\"text-align: right;\">  fraud_label</th><th style=\"text-align: right;\">  kl_words</th><th style=\"text-align: right;\">  ks_words</th><th style=\"text-align: right;\">  entropy_words</th><th style=\"text-align: right;\">  features85_type</th><th style=\"text-align: right;\">  features85_size</th><th style=\"text-align: right;\">  ngramscounts15_type</th><th style=\"text-align: right;\">  ngramscounts15_size</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>589ff83a30fa5d82563f0051bbd9f638d3dc7f102f8c78ab137c17b859e740de35348417e0deb2037cd0188c243c674100eb57f97450c4b942c9d3a1ef86a07b</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4446.55</td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.0719711</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>865fc00f8a94dd1c467c39753bfb2b18626f2827db85a05654caf048e657b6856afad3fef87873197e7f92e0ff760c8f04cd5484c910a037476643addfdb5c31</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   3287.65</td><td style=\"text-align: right;\">  0.947901</td><td style=\"text-align: right;\">      0.0696592</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>a659ae2c8efbde6eb990b90acae3e02f644e44cd1a3a9aa6490632209641eb5714bb4b740ddcbe95e50b5cd319a8725634ffea38ae633fd6ab1f7114ad8c17bd</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4169.68</td><td style=\"text-align: right;\">  0.52636 </td><td style=\"text-align: right;\">      0.0708245</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>d6d7bcd45dfa2fb6487352a532359f3f64afe250dacb422898ed9854af8992866bff17dac83f36763b46f2db2e0442fdf23fafdd58628636ca3395b6ef019a16</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4538.96</td><td style=\"text-align: right;\">  0.210665</td><td style=\"text-align: right;\">      0.0757622</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>da23c7d6b5dd13228bb9b8e5d3287463ca7b12fbc8a5c068ce2cf4ca3e7e89ca6990a4abfc69dcedd538ee916f64a8d5d0440d1ad309c9604efc9ad4074a81ed</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4378.87</td><td style=\"text-align: right;\">  0.477263</td><td style=\"text-align: right;\">      0.077328 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>980071f323752c9f7e987d2f657d244851b601c46ef50b2cd053d69ee9c3a7b413730fff5a68bea2dd9ada49d410f0c0f8165ad2a9096c2c419668df2b829de3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4222.18</td><td style=\"text-align: right;\">  0.523838</td><td style=\"text-align: right;\">      0.0740113</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>e38e2712270ef1f79716537aa2816eaab104a20e17c94df57b49b787cda6f8e96794acf70b302c9708e9573dda18e402c7e996ea14e537e736001b12070d7542</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4279.72</td><td style=\"text-align: right;\">  0.679739</td><td style=\"text-align: right;\">      0.0711178</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>26f328150124298822fc4a0be849251c3d3545dcb2495c71dc92a60d1629ea641ec4d24c7004a3d579df61f5ba7197ffe6e88e3efaee93d226270372ee87d4b2</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4375.28</td><td style=\"text-align: right;\">  0.386449</td><td style=\"text-align: right;\">      0.0745828</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>2b8a2419e7f2c6fecb549146c3d66ab9cae9839005d8f848d39313e49b34d22c18c6eb7e20b3b0c5291d4ad0f7f2b329423816423f62a40a7dae70870c2b7f9f</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4396.63</td><td style=\"text-align: right;\">  0.430514</td><td style=\"text-align: right;\">      0.0760735</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>67d469882a190b2d6262a34bcca389d43799a46e823c51da3c685150a32c5779132915cfd6cc965db7d7f92639dd725dad1e29d2f69598d63cdf1402d2fa66b3</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">   4478.26</td><td style=\"text-align: right;\">  0.307116</td><td style=\"text-align: right;\">      0.073295 </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">        p0</th><th style=\"text-align: right;\">      p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00146627</td><td style=\"text-align: right;\">0.998534</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0102712 </td><td style=\"text-align: right;\">0.989729</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0184821 </td><td style=\"text-align: right;\">0.981518</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00165677</td><td style=\"text-align: right;\">0.998343</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0017544 </td><td style=\"text-align: right;\">0.998246</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00627947</td><td style=\"text-align: right;\">0.993721</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00781858</td><td style=\"text-align: right;\">0.992181</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00190717</td><td style=\"text-align: right;\">0.998093</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00121289</td><td style=\"text-align: right;\">0.998787</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.00841522</td><td style=\"text-align: right;\">0.991585</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# If you need to generate predictions on a test set, you can make\n",
    "# predictions directly on the `\"H2OAutoML\"` object, or on the leader\n",
    "# model object directly\n",
    "\n",
    "#preds = aml.predict(test)\n",
    "# or:\n",
    "preds = aml.leader.predict(test)\n",
    "print(\"test\")\n",
    "print(test.head(10))\n",
    "print(\"prediction\")\n",
    "print(preds.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XGBoost_grid_1_AutoML_20190130_213207_model_2', 'StackedEnsemble_AllModels_AutoML_20190130_213207', 'XGBoost_grid_1_AutoML_20190130_213207_model_1', 'GBM_grid_1_AutoML_20190130_213207_model_1', 'XGBoost_grid_1_AutoML_20190130_213207_model_6', 'StackedEnsemble_BestOfFamily_AutoML_20190130_213207', 'GBM_4_AutoML_20190130_213207', 'GBM_2_AutoML_20190130_213207', 'GBM_1_AutoML_20190130_213207', 'GBM_3_AutoML_20190130_213207', 'XGBoost_1_AutoML_20190130_213207', 'GBM_grid_1_AutoML_20190130_213207_model_3', 'GBM_grid_1_AutoML_20190130_213207_model_2', 'XGBoost_2_AutoML_20190130_213207', 'GBM_5_AutoML_20190130_213207', 'XGBoost_3_AutoML_20190130_213207', 'XGBoost_grid_1_AutoML_20190130_213207_model_4', 'DeepLearning_grid_1_AutoML_20190130_213207_model_3', 'GBM_grid_1_AutoML_20190130_213207_model_4', 'DeepLearning_grid_1_AutoML_20190130_213207_model_1', 'DeepLearning_grid_1_AutoML_20190130_213207_model_4', 'DeepLearning_grid_1_AutoML_20190130_213207_model_2', 'DeepLearning_1_AutoML_20190130_213207', 'XGBoost_grid_1_AutoML_20190130_213207_model_5', 'XGBoost_grid_1_AutoML_20190130_213207_model_3', 'XGBoost_grid_1_AutoML_20190130_213207_model_7']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'H2OXGBoostEstimator' has no attribute 'metalearner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-91286988fdd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Get the Stacked Ensemble metalearner model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmetalearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetalearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmetalearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-5.1.0.1/lib/python3.6/site-packages/h2o/utils/backward_compatibility.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bcin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Make sure that we look up any names not found on the instance also in the class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/cloudera/parcels/Anaconda-5.1.0.1/lib/python3.6/site-packages/h2o/utils/backward_compatibility.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# print(\"Warning: Method %s in class %s is deprecated.\" % (name, cls.__name__))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'H2OXGBoostEstimator' has no attribute 'metalearner'"
     ]
    }
   ],
   "source": [
    "# Get model ids for all models in the AutoML Leaderboard\n",
    "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
    "\n",
    "print(model_ids)\n",
    "# Get the \"All Models\" Stacked Ensemble model\n",
    "se = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])\n",
    "\n",
    "# Get the Stacked Ensemble metalearner model\n",
    "metalearner = h2o.get_model(aml.leader.metalearner()['name'])\n",
    "metalearner.coef_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metalearner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5a4538925986>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetalearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd_coef_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metalearner' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "metalearner.std_coef_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/siemanalyst/projects/logs-archive-production/fraud-canada-tokenizedwords/product_model_bin/ngrams15_features85_m25/v2/mojo/XGBoost_grid_1_AutoML_20190130_213207_model_2.zip'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.download_mojo(path = \"./product_model_bin/ngrams15_features85_m25/v2/mojo\", get_genmodel_jar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |ââââââââââââââââââââââââââââââââââââââââââââ| 100%\n",
      "test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>hash_message                                                                                                                    </th><th style=\"text-align: right;\">  fraud_label</th><th style=\"text-align: right;\">  kl_words</th><th style=\"text-align: right;\">  ks_words</th><th style=\"text-align: right;\">  entropy_words</th><th style=\"text-align: right;\">  features85_type</th><th style=\"text-align: right;\">  features85_size</th><th style=\"text-align: right;\">  ngramscounts15_type</th><th style=\"text-align: right;\">  ngramscounts15_size</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>28eb4e7f40b2576348154859edd355cd5d4c0f751bae54055dc3654b0a2df966e1274f09b5e9c09292ff4395df798ce9a02b5cfbf9071c9bc6765bf2812e9a35</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   5690.25</td><td style=\"text-align: right;\"> 0.036261 </td><td style=\"text-align: right;\">      0.0647111</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>29c6c59805df1ca6a084f2f9f7f81b89958f8a5caf9299595ea9604ef72fa766efeff77e58e098f6a3778f1b11e0362f22d7ad79269e92b2f2a035127f761e2f</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   2752.83</td><td style=\"text-align: right;\"> 0.363565 </td><td style=\"text-align: right;\">      0.0654095</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>29f957bbd4d764a06c90397f3b80784933af5fe29188b74ddb64290d19063e343af746e26e792b89c67fa6f5346d82339a21aa447e2f6e72aea37e8c815d9c72</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   4230.17</td><td style=\"text-align: right;\"> 0.986841 </td><td style=\"text-align: right;\">      0.0646723</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>2a3f4b85be3eedb8be47c3f0ecd48ebca0a6936b663b90716795ae35184bacc9db2aa2620db40850bbb63224f8308e0b133932e88e9dce64377bce35631dd5d4</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   2027.88</td><td style=\"text-align: right;\"> 0.142873 </td><td style=\"text-align: right;\">      0.0659066</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>2c9539bc4587613bbb2fd11aad658f5c59e605399e276294c15bdfc134419f7c354f8a3167768ec7dd07427e93366752f68f337473a34243c6f6f7124ca2d52f</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   5296.48</td><td style=\"text-align: right;\"> 0.0642194</td><td style=\"text-align: right;\">      0.0678356</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>2d98ad89fcf7dd6f8c06823eb6489bf01d5a68ef1b258d06cf3c437dd5b316b36e162fd384a0225d6426b8a0679bb26d76142b293e5f61aa42c83d04e062bafd</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   5443.37</td><td style=\"text-align: right;\"> 0.0546268</td><td style=\"text-align: right;\">      0.06557  </td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>2ded0a1badca5d2d9e2ceb1602d4f8b4c69503eaf351d3b26752eb671b1bb8e8d8a76b618826aa89bbfdd9e74360a0027f208fb2a500e255bc56c3eeb5d43c16</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   5168.13</td><td style=\"text-align: right;\"> 0.0909001</td><td style=\"text-align: right;\">      0.0628464</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>2df4c859f56269c915e963f386fb39754a8a8f550edfaef0e747c11ecdf8e456c9b5cdd909841c742711af59ce56a98fa32b1b6be46d87d133d50ff6d0bfdb6b</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   2643.15</td><td style=\"text-align: right;\"> 0.280157 </td><td style=\"text-align: right;\">      0.0692871</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>370111fdd74149bef859c82a950aa357f6b03984c81a348e01874a5fe63156dd2eff2d83dd83350b175a5ab2a61606f9619625173fea69eb60b1b44cbbd654fa</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   1999.02</td><td style=\"text-align: right;\"> 0.163965 </td><td style=\"text-align: right;\">      0.0644722</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "<tr><td>3947f05845930b1c0438a3dbcdce4c9133ff4c61e8b05f04a32f55d88bc412f8828cef778f938ce73312ad381e8852619a162569ea86c89268daf2ce1262b791</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">   5885.44</td><td style=\"text-align: right;\"> 0.0382891</td><td style=\"text-align: right;\">      0.0659859</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">               85</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">               262144</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "prediction\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">         p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999724</td><td style=\"text-align: right;\">0.000276417</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999779</td><td style=\"text-align: right;\">0.000221217</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.998581</td><td style=\"text-align: right;\">0.0014189  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999793</td><td style=\"text-align: right;\">0.000206783</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999701</td><td style=\"text-align: right;\">0.000298861</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999708</td><td style=\"text-align: right;\">0.000291914</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999714</td><td style=\"text-align: right;\">0.000286399</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999641</td><td style=\"text-align: right;\">0.000359046</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999784</td><td style=\"text-align: right;\">0.000216216</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.999701</td><td style=\"text-align: right;\">0.000299408</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# If you need to generate predictions on a test set, you can make\n",
    "# predictions directly on the `\"H2OAutoML\"` object, or on the leader\n",
    "# model object directly\n",
    "\n",
    "#preds = aml.predict(test)\n",
    "# or:\n",
    "preds = aml.leader.predict(test)\n",
    "print(\"test\")\n",
    "print(test.tail(10))\n",
    "print(\"prediction\")\n",
    "print(preds.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
