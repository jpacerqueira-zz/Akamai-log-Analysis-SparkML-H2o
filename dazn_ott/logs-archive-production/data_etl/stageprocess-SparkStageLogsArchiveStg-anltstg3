#!/usr/bin/env bash

DATE_V1=$1
if [ -z "$DATE_V1" ]
then
 DATE_V1=20180214
fi

KERBEROS_ENABLED=true
if [ -f ~/.keytabs/$(whoami).keytab ]; then
  # for any:any credentials
  export KRB5CCNAME=/tmp/krb5cc_$(id -u)

  kinit -kt ~/.keytabs/$(whoami).keytab $(whoami)/ixpbda@BDA.PERFORMGROUP.COM -c /tmp/krb5cc_$(id -u)
  klist /tmp/krb5cc_$(id -u)
else
  KERBEROS_ENABLED=false
  echo "No Kerberos here"
fi

echo "RAW d=${DATE_V1} FILES COUNT : "
hdfs dfs -ls /data/raw/ott_dazn/docomo_investigations/logs-archive-production/gzip/dt=${DATE_V1}/*.gz | wc -l

hdfs dfs -mkdir -p /data/staged/ott_dazn/docomo_investigations/logs-archive-production/parquet

echo "Clean Stage to Avoid Duplicates of dt=${DATE_V1}"
hdfs dfs -rm -r -f -skipTrash  /data/staged/ott_dazn/docomo_investigations/logs-archive-production/parquet/dt=${DATE_V1}/*.parquet 

echo "TOTAL STAGED FILES COUNT : "
hdfs dfs -ls -R /data/staged/ott_dazn/docomo_investigations/logs-archive-production/parquet/dt=*/*.parquet | wc -l

echo "STAGE RAW DATA AS PARQUET FOR DATE ${DATE_V1} with SPARK"

# Spark Job Operations
MAIN_CLASS1=ptv.content.akamailogs.staged.parquetindexer.SparkStageLogsArchiveProd
APP_JAR=/home/oracle/projects/dazn_ott/logs-archive-production/data_etl/parquetindexer-1.0-TPOC-jar-with-dependencies.jar
EXTRA_JAR=/home/oracle/projects/dazn_ott/logs-archive-production/data_etl/spark-csv_2.11-1.5.0.jar

# Additional for Spark container 

MASTER_URL=yarn
DEPLOY_MODE=client

NUM_EXECUTORS=136
DRIVER_MEMORY=4g
EXECUTOR_MEMORY=2G
EXECUTOR_CORES=4

# Additional Logic workarround for new null token DI
#
IN_PATH="/data/raw/ott_dazn/docomo_investigations/logs-archive-production/gzip/"
OUT_PATH="/data/staged/ott_dazn/docomo_investigations/logs-archive-production/parquet/"
#

if [ "$KERBEROS_ENABLED" = "true" ]
then
spark2-submit  --class ${MAIN_CLASS1} --master ${MASTER_URL} --deploy-mode ${DEPLOY_MODE}  --principal $(whoami)/ixpbda@BDA.PERFORMGROUP.COM --keytab ~/.keytabs/$(whoami).keytab  --jars ${APP_JAR} ${EXTRA_JAR} --processdate ${DATE_V1} --inputpath ${IN_PATH} --outputpath ${OUT_PATH}  >>  /home/oracle/projects/dazn_ott/logs-archive-production/data_etl/logs/SparkStageLogsArchiveProd-1-${DATE_V1}.log

else
spark2-submit  --class ${MAIN_CLASS1} --master ${MASTER_URL} --deploy-mode ${DEPLOY_MODE} --jars ${APP_JAR} ${EXTRA_JAR} --processdate ${DATE_V1} --inputpath ${IN_PATH} --outputpath ${OUT_PATH}  >>  /home/oracle/projects/dazn_ott/logs-archive-production/data_etl/logs/SparkStageLogsArchiveProd-1-${DATE_V1}.log

fi
#

echo 1
